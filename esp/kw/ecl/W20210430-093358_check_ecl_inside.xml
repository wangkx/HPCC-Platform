<?xml version="1.0" encoding="UTF-8"?><?xml-stylesheet href="../esp/xslt/xmlformatter.xsl" type="text/xsl"?><W20210430-093358 agentSession='334310138145'
                  buildVersion='internal_7.6.70-1'
                  cloneable='1'
                  clusterName='hthor'
                  codeVersion='651'
                  eclVersion='7.6.70'
                  hash='2395336404'
                  isClone='0'
                  jobName='test_data_scoring'
                  scope='jskaggs'
                  state='completed'
                  submitID='jskaggs'
                  totalThorTime='        0:00:13.385'
                  wuidVersion='2'
                  xmlns:xsi='http://www.w3.org/1999/XMLSchema-instance'> <Action>run</Action>
 <Application>
  <QueryBuilder>
   <Debug_/>
   <QualifiedLabel>data_scoring.test_data_scoring</QualifiedLabel>
   <Version>community_7.10.18-1</Version>
  </QueryBuilder>
 </Application>
 <Debug>
  <applyinstantecltransformations>1</applyinstantecltransformations>
  <applyinstantecltransformationslimit>100</applyinstantecltransformationslimit>
  <created_by>ws_workunits</created_by>
  <created_for>jskaggs</created_for>
  <eclcc_compiler_version>7.12.38</eclcc_compiler_version>
  <expandpersistinputdependencies>1</expandpersistinputdependencies>
  <targetclustertype>hthor</targetclustertype>
 </Debug>
 <FilesRead>
  <File cluster="thor40_83"
        name="thor::red::dm::dim_data_scoring_contributor"
        super="1"
        useCount="1">
   <Subfile name="thor::red::dm::20210430::dim_data_scoring_contributor_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::dm::20210430::dim_data_scoring_contributor_w20210430-010030" useCount="1"/>
  <File cluster="thor40_83"
        name="thor::red::dm::dim_data_scoring_field_definition"
        super="1"
        useCount="1">
   <Subfile name="thor::red::dm::20210430::dim_data_scoring_field_definition_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::dm::20210430::dim_data_scoring_field_definition_w20210430-010030" useCount="1"/>
  <File cluster="thor40_83"
        name="thor::red::dm::fact_data_scoring_file_stat"
        super="1"
        useCount="4">
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_file_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_file_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_file_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_file_stat_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::dm::20210430::fact_data_scoring_file_stat_w20210430-010030" useCount="4"/>
  <File cluster="thor40_83"
        name="thor::red::dm::fact_data_scoring_field_stat"
        super="1"
        useCount="4">
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_field_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_field_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_field_stat_w20210430-010030"/>
   <Subfile name="thor::red::dm::20210430::fact_data_scoring_field_stat_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::dm::20210430::fact_data_scoring_field_stat_w20210430-010030" useCount="4"/>
  <File cluster="thor40_83"
        name="thor::red::dm::dim_data_scoring_application"
        super="1"
        useCount="1">
   <Subfile name="thor::red::dm::20210430::dim_data_scoring_application_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::dm::20210430::dim_data_scoring_application_w20210430-010030" useCount="1"/>
  <File cluster="thor40_83"
        name="thor::red::stg::data_scoring::fielddef"
        super="1"
        useCount="2">
   <Subfile name="thor::red::stg::data_scoring::20210430::fielddef_w20210430-010030"/>
   <Subfile name="thor::red::stg::data_scoring::20210430::fielddef_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::stg::data_scoring::20210430::fielddef_w20210430-010030" useCount="2"/>
  <File cluster="thor40_83"
        name="thor::red::stg::data_scoring::filestat"
        super="1"
        useCount="2">
   <Subfile name="thor::red::stg::data_scoring::20210430::filestat_w20210430-010030"/>
   <Subfile name="thor::red::stg::data_scoring::20210430::filestat_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::stg::data_scoring::20210430::filestat_w20210430-010030" useCount="2"/>
  <File cluster="thor40_83"
        name="thor::red::stg::data_scoring::fieldstat"
        super="1"
        useCount="2">
   <Subfile name="thor::red::stg::data_scoring::20210430::fieldstat_w20210430-010030"/>
   <Subfile name="thor::red::stg::data_scoring::20210430::fieldstat_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::stg::data_scoring::20210430::fieldstat_w20210430-010030" useCount="2"/>
  <File cluster="thor40_83"
        name="thor::red::stg::data_scoring::applicationdetails"
        super="1"
        useCount="2">
   <Subfile name="thor::red::stg::data_scoring::20210430::applicationdetails_w20210430-010030"/>
   <Subfile name="thor::red::stg::data_scoring::20210430::applicationdetails_w20210430-010030"/>
  </File>
  <File cluster="thor40_83" name="thor::red::stg::data_scoring::20210430::applicationdetails_w20210430-010030" useCount="2"/>
 </FilesRead>
 <Graphs>
  <Graph name="graph1" type="activities" wfid="1">
   <xgmml>
    <graph wfid="1">
     <edge id="7_27" source="1" target="21">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="7"/>
      <att name="_targetActivity" value="27"/>
     </edge>
     <edge id="14_27" source="8" target="21">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="14"/>
      <att name="_targetActivity" value="27"/>
     </edge>
     <edge id="17_27" source="15" target="21">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="17"/>
      <att name="_targetActivity" value="27"/>
     </edge>
     <edge id="20_27" source="18" target="21">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="20"/>
      <att name="_targetActivity" value="27"/>
     </edge>
     <edge id="30_39" source="28" target="37">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="30"/>
      <att name="_targetActivity" value="39"/>
     </edge>
     <edge id="33_39" source="31" target="37">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="33"/>
      <att name="_targetActivity" value="39"/>
     </edge>
     <edge id="36_39" source="34" target="37">
      <att name="_dependsOn" value="1"/>
      <att name="_sourceActivity" value="36"/>
      <att name="_targetActivity" value="39"/>
     </edge>
     <edge id="25_41" source="21" target="40">
      <att name="_sourceActivity" value="25"/>
      <att name="_targetActivity" value="41"/>
     </edge>
     <edge id="5_45" source="1" target="44">
      <att name="_sourceActivity" value="5"/>
      <att name="_targetActivity" value="45"/>
     </edge>
     <edge id="12_49" source="8" target="48">
      <att name="_sourceActivity" value="12"/>
      <att name="_targetActivity" value="49"/>
     </edge>
     <node id="1">
      <att>
       <graph>
        <edge id="2_0"
              label="True"
              source="2"
              target="4"/>
        <edge id="3_0"
              label="False"
              source="3"
              target="4">
         <att name="_targetIndex" value="1"/>
        </edge>
        <edge id="4_0" source="4" target="5"/>
        <edge id="5_0" source="5" target="6"/>
        <edge id="6_0" source="6" target="7"/>
        <node id="2" label="Disk Read&#10;&apos;...::dim_data_scoring_contributor&apos;">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl(19,21)"/>
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::dim_data_scoring_contributor&apos;, layout, THOR);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~thor::red::dm::dim_data_scoring_contributor"/>
        </node>
        <node id="3" label="Inline Dataset">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl(20,21)"/>
         <att name="_kind" value="133"/>
         <att name="ecl" value="DATASET([{-1,&apos;UA        &apos;,&apos;Unassigned                                        &apos;,&apos;                                                                               ...&apos;,&apos;          &apos;},...], layout);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="2"/>
        </node>
        <node id="4" label="If">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl(18,3)"/>
         <att name="name" value="file"/>
         <att name="_kind" value="28"/>
         <att name="ecl" value="IF(INTERNAL(&apos;gl4&apos;), ..., ...);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_graphIndependent" value="1"/>
        </node>
        <node id="5" label="Spill">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl(18,18)"/>
         <att name="_kind" value="43"/>
         <att name="ecl" value="SPILL(&apos;~spill::8&apos;, __compressed__);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~spill::8"/>
         <att name="_isSpill" value="1"/>
        </node>
        <node id="6" label="Count">
         <att name="_kind" value="125"/>
         <att name="ecl" value="TABLE({ integer8 value := COUNT(group) });&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
        </node>
        <node id="7" label="Output&#10;Internal(&apos;spill1&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill1&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="8">
      <att>
       <graph>
        <edge id="9_0"
              label="True"
              source="9"
              target="11"/>
        <edge id="10_0"
              label="False"
              source="10"
              target="11">
         <att name="_targetIndex" value="1"/>
        </edge>
        <edge id="11_0" source="11" target="12"/>
        <edge id="12_0" source="12" target="13"/>
        <edge id="13_0" source="13" target="14"/>
        <node id="9" label="Disk Read&#10;&apos;...::dim_data_scoring_field_definition&apos;">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl(24,21)"/>
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::dim_data_scoring_field_definition&apos;, layout, THOR);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~thor::red::dm::dim_data_scoring_field_definition"/>
        </node>
        <node id="10" label="Inline Dataset">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl(25,21)"/>
         <att name="_kind" value="133"/>
         <att name="ecl" value="DATASET([{-1,&apos;UA                                                                             ...&apos;,&apos;UA   &apos;,&apos;Unassigned                    &apos;,&apos;                                                                               ...&apos;,0,&apos;            &apos;,&apos;       &apos;,&apos;    &apos;,&apos;          &apos;},...], layout);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="2"/>
        </node>
        <node id="11" label="If">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl(23,3)"/>
         <att name="name" value="file"/>
         <att name="_kind" value="28"/>
         <att name="ecl" value="IF(INTERNAL(&apos;gl6&apos;), ..., ...);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_graphIndependent" value="1"/>
        </node>
        <node id="12" label="Spill">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl(23,18)"/>
         <att name="_kind" value="43"/>
         <att name="ecl" value="SPILL(&apos;~spill::9&apos;, __compressed__);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~spill::9"/>
         <att name="_isSpill" value="1"/>
        </node>
        <node id="13" label="Count">
         <att name="_kind" value="125"/>
         <att name="ecl" value="TABLE({ integer8 value := COUNT(group) });&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
        </node>
        <node id="14" label="Output&#10;Internal(&apos;spill2&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill2&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="15">
      <att>
       <graph>
        <edge id="16_0" source="16" target="17"/>
        <node id="16" label="Disk Count&#10;&apos;...::fact_data_scoring_file_stat&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_file_stat&apos;, layout, THOR, opt);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_file_stat.ecl(22,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_file_stat"/>
        </node>
        <node id="17" label="Output&#10;Internal(&apos;spill3&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill3&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="18">
      <att>
       <graph>
        <edge id="19_0" source="19" target="20"/>
        <node id="19" label="Disk Count&#10;&apos;...::fact_data_scoring_field_stat&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_field_stat&apos;, layout, THOR, opt);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_field_stat.ecl(26,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_field_stat"/>
        </node>
        <node id="20" label="Output&#10;Internal(&apos;spill4&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill4&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="21">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="22_0"
              label="True"
              source="22"
              target="24"/>
        <edge id="23_0"
              label="False"
              source="23"
              target="24">
         <att name="_targetIndex" value="1"/>
        </edge>
        <edge id="24_0" source="24" target="25"/>
        <edge id="25_0" source="25" target="26"/>
        <edge id="26_0" source="26" target="27"/>
        <node id="22" label="Disk Read&#10;&apos;...::dim_data_scoring_application&apos;">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl(18,21)"/>
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::dim_data_scoring_application&apos;, layout, THOR);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~thor::red::dm::dim_data_scoring_application"/>
        </node>
        <node id="23" label="Inline Dataset">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl(19,21)"/>
         <att name="_kind" value="133"/>
         <att name="ecl" value="DATASET([{-1,&apos;UA  &apos;,&apos;Unassigned               &apos;,&apos;          &apos;},...], layout);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="2"/>
        </node>
        <node id="24" label="If">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl(17,3)"/>
         <att name="name" value="file"/>
         <att name="_kind" value="28"/>
         <att name="ecl" value="IF(INTERNAL(&apos;gl2&apos;), ..., ...);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_graphIndependent" value="1"/>
        </node>
        <node id="25" label="Spill">
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl(17,18)"/>
         <att name="_kind" value="43"/>
         <att name="ecl" value="SPILL(&apos;~spill::A&apos;, __compressed__);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="0..?[disk]"/>
         <att name="_fileName" value="~spill::A"/>
         <att name="_isSpill" value="1"/>
        </node>
        <node id="26" label="Count">
         <att name="_kind" value="125"/>
         <att name="ecl" value="TABLE({ integer8 value := COUNT(group) });&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
        </node>
        <node id="27" label="Store&#10;&apos;dim_fact_counts&apos;">
         <att name="_kind" value="22"/>
         <att name="ecl" value="extractresult(&apos;dim app: &apos; + value + &apos;\ndim contrib: &apos; + &lt;...&gt;.value + &apos;\ndim field def: &apos; + &lt;...&gt;.value + ..., named(&apos;dim_fact_counts&apos;), output);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="28">
      <att>
       <graph>
        <edge id="29_0" source="29" target="30"/>
        <node id="29" label="Disk Count&#10;&apos;...::fielddef&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::stg::data_scoring::fielddef&apos;, field_def, THOR);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\source\data_scoring\files.ecl(34,3)"/>
         <att name="name" value="fieldDef"/>
         <att name="_fileName" value="~thor::red::stg::data_scoring::fielddef"/>
        </node>
        <node id="30" label="Output&#10;Internal(&apos;spill5&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill5&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="31">
      <att>
       <graph>
        <edge id="32_0" source="32" target="33"/>
        <node id="32" label="Disk Count&#10;&apos;...::filestat&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::stg::data_scoring::filestat&apos;, file_stat, THOR);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\source\data_scoring\files.ecl(32,3)"/>
         <att name="name" value="fileStat"/>
         <att name="_fileName" value="~thor::red::stg::data_scoring::filestat"/>
        </node>
        <node id="33" label="Output&#10;Internal(&apos;spill6&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill6&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="34">
      <att>
       <graph>
        <edge id="35_0" source="35" target="36"/>
        <node id="35" label="Disk Count&#10;&apos;...::fieldstat&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::stg::data_scoring::fieldstat&apos;, field_stat, THOR);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\source\data_scoring\files.ecl(33,3)"/>
         <att name="name" value="fieldStat"/>
         <att name="_fileName" value="~thor::red::stg::data_scoring::fieldstat"/>
        </node>
        <node id="36" label="Output&#10;Internal(&apos;spill7&apos;)">
         <att name="_kind" value="16"/>
         <att name="_internal" value="1"/>
         <att name="ecl" value="OUTPUT(..., named(&apos;spill7&apos;), __compressed__);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="37">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="38_0" source="38" target="39"/>
        <node id="38" label="Disk Count&#10;&apos;...::applicationdetails&apos;">
         <att name="_kind" value="74"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::stg::data_scoring::applicationdetails&apos;, app_details, THOR);&#10;"/>
         <att name="recordSize" value="8"/>
         <att name="predictedCount" value="1"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\source\data_scoring\files.ecl(35,3)"/>
         <att name="name" value="appDetails"/>
         <att name="_fileName" value="~thor::red::stg::data_scoring::applicationdetails"/>
        </node>
        <node id="39" label="Store&#10;&apos;stg_counts&apos;">
         <att name="_kind" value="22"/>
         <att name="ecl" value="extractresult(&apos;stg app: &apos; + value + &apos;\nstg field def: &apos; + &lt;...&gt;.value + &apos;\nstg file: &apos; + &lt;...&gt;.value + ..., named(&apos;stg_counts&apos;), output);&#10;"/>
         <att name="recordSize" value="8"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="40">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="41_0" source="41" target="42"/>
        <edge id="42_0" source="42" target="43"/>
        <node id="41" label="Filtered&#10;Spill Read">
         <att name="_kind" value="195"/>
         <att name="ecl" value="DATASET(&apos;~spill::A&apos;, RECORD&#10;  integer4 application_sk;&#10;  string4 application_id;&#10;  string25 application_name;&#10;... END, THOR, __compressed__);&#10;FILTER(application_id = &apos;    &apos;);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(35,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl(17,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~spill::A"/>
         <att name="_isSpill" value="1"/>
         <att name="signedBy" value="hpcc"/>
        </node>
        <node id="42" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="43"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="43" label="Output&#10;&apos;dim_app_empty&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(35,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;dim_app_empty&apos;), workunit);&#10;"/>
         <att name="recordSize" value="43"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="44">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="45_0" source="45" target="46"/>
        <edge id="46_0" source="46" target="47"/>
        <node id="45" label="Filtered&#10;Spill Read">
         <att name="_kind" value="195"/>
         <att name="ecl" value="DATASET(&apos;~spill::8&apos;, RECORD&#10;  integer4 contributor_sk;&#10;  string10 contributorid;&#10;  string50 contributorname;&#10;... END, THOR, __compressed__);&#10;FILTER(contributorid = &apos;          &apos;);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(36,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl(18,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~spill::8"/>
         <att name="_isSpill" value="1"/>
         <att name="signedBy" value="hpcc"/>
        </node>
        <node id="46" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="274"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="47" label="Output&#10;&apos;dim_contrib_empty&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(36,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;dim_contrib_empty&apos;), workunit);&#10;"/>
         <att name="recordSize" value="274"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="48">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="49_0" source="49" target="50"/>
        <edge id="50_0" source="50" target="51"/>
        <node id="49" label="Filtered&#10;Spill Read">
         <att name="_kind" value="195"/>
         <att name="ecl" value="DATASET(&apos;~spill::9&apos;, RECORD&#10;  integer4 field_def_sk;&#10;  string100 field_name;&#10;  string5 batchversion;&#10;  string30 field_category;&#10;... END, THOR, __compressed__);&#10;FILTER(application_id = &apos;    &apos; OR batchversion = &apos;     &apos; OR field_name = &apos;                                                                               ...&apos; OR ...);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(37,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl(23,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~spill::9"/>
         <att name="_isSpill" value="1"/>
         <att name="signedBy" value="hpcc"/>
        </node>
        <node id="50" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="676"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="51" label="Output&#10;&apos;dim_field_def_empty&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(37,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;dim_field_def_empty&apos;), workunit);&#10;"/>
         <att name="recordSize" value="676"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="52">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="53_0" source="53" target="54"/>
        <edge id="54_0" source="54" target="55"/>
        <node id="53" label="Filtered&#10;Disk Read&#10;&apos;...::fact_data_scoring_file_stat&apos;">
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_file_stat&apos;, layout, THOR, opt);&#10;FILTER(wuid = &apos;                   &apos; OR batchnumber = &apos;              &apos; OR batchversion = &apos;     &apos;);&#10;"/>
         <att name="recordSize" value="94"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(38,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_file_stat.ecl(22,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_file_stat"/>
        </node>
        <node id="54" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="94"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="55" label="Output&#10;&apos;fact_file_empty&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(38,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;fact_file_empty&apos;), workunit);&#10;"/>
         <att name="recordSize" value="94"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="56">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="57_0" source="57" target="58"/>
        <edge id="58_0" source="58" target="59"/>
        <node id="57" label="Filtered&#10;Disk Read&#10;&apos;...::fact_data_scoring_field_stat&apos;">
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_field_stat&apos;, layout, THOR, opt);&#10;FILTER(wuid = &apos;                   &apos; OR batchnumber = &apos;              &apos; OR batchversion = &apos;     &apos;);&#10;"/>
         <att name="recordSize" value="123"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(39,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_field_stat.ecl(26,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_field_stat"/>
        </node>
        <node id="58" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="123"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="59" label="Output&#10;&apos;fact_field_empty&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(39,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;fact_field_empty&apos;), workunit);&#10;"/>
         <att name="recordSize" value="123"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="60">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="61_0" source="61" target="62"/>
        <edge id="62_0" source="62" target="63"/>
        <node id="61" label="Filtered&#10;Disk Read&#10;&apos;...::fact_data_scoring_file_stat&apos;">
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_file_stat&apos;, layout, THOR, opt);&#10;FILTER(application_sk = -1 OR contributor_sk = -1);&#10;"/>
         <att name="recordSize" value="94"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(42,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_file_stat.ecl(22,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_file_stat"/>
        </node>
        <node id="62" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="94"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="63" label="Output&#10;&apos;fact_file_neg1&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(42,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;fact_file_neg1&apos;), workunit);&#10;"/>
         <att name="recordSize" value="94"/>
        </node>
       </graph>
      </att>
     </node>
     <node id="64">
      <att>
       <graph>
        <att name="rootGraph" value="1"/>
        <edge id="65_0" source="65" target="66"/>
        <edge id="66_0" source="66" target="67"/>
        <node id="65" label="Filtered&#10;Disk Read&#10;&apos;...::fact_data_scoring_field_stat&apos;">
         <att name="_kind" value="71"/>
         <att name="ecl" value="DATASET(&apos;~thor::red::dm::fact_data_scoring_field_stat&apos;, layout, THOR, opt);&#10;FILTER(application_sk = -1 OR field_def_sk = -1);&#10;"/>
         <att name="recordSize" value="123"/>
         <att name="predictedCount" value="0..500000[memory]"/>
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(43,8)"/>
         <att name="definition" value="C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_field_stat.ecl(26,3)"/>
         <att name="name" value="file"/>
         <att name="_fileName" value="~thor::red::dm::fact_data_scoring_field_stat"/>
        </node>
        <node id="66" label="Firstn">
         <att name="_kind" value="12"/>
         <att name="ecl" value="CHOOSEN(100);&#10;"/>
         <att name="recordSize" value="123"/>
         <att name="predictedCount" value="0..100[group]"/>
        </node>
        <node id="67" label="Output&#10;&apos;fact_field_neg1&apos;">
         <att name="definition" value="C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl(43,1)"/>
         <att name="_kind" value="16"/>
         <att name="ecl" value="OUTPUT(..., , named(&apos;fact_field_neg1&apos;), workunit);&#10;"/>
         <att name="recordSize" value="123"/>
        </node>
       </graph>
      </att>
     </node>
    </graph>
   </xgmml>
  </Graph>
 </Graphs>
 <Plugins>
  <Plugin dllname="libfileservices.so" version="FILESERVICES 2.1.4"/>
 </Plugins>
 <Process>
  <EclAgent>
   <eclagent log="//10.194.93.2/mnt/disk1/var/log/HPCCSystems/eclagent/eclagent.2021_04_30.log" pid="287788"/>
  </EclAgent>
 </Process>
 <Query fetchEntire="1" hasArchive="1" isArchive="1">
  <Associated>
   <File desc="Compiler log"
         filename="/mnt/disk1/var/lib/HPCCSystems/eclccserver/W20210430-093358.eclcc.log"
         ip="10.194.93.5"
         type="log"/>
   <File crc="-835312051"
         desc="Workunit DLL"
         filename="/mnt/disk1/var/lib/HPCCSystems/eclccserver/libW20210430-093358.so"
         ip="10.194.93.5"
         type="dll"/>
  </Associated>
  <ShortText>import red.dm;
import red.source.data_scoring as d;

dimApp      := dm.dim_data_scoring_application.file;
dimContrib  := dm.dim_data_scoring_contributor.file;
dimFieldDef := dm.dim_data_scoring_field_definition.file;
factFile    := dm.fact_data_scoring_file_stat.file;
factField   := dm.fact_data_scoring_field_stat.file;

dimAppLayout      := dm.dim_data_scoring_application.layout;
dimContribLayout  := dm.dim_data_scoring_contributor.layout;
dimFieldDefLayout := dm.dim_data_scoring_field_definition.layout;
factFileLayout    := dm.fact_data_scoring_file_stat.layout;
factFieldLayout   := dm.fact_data_scoring_field_stat.layout;

// Get counts of dims and facts, useful to run before and after build to compare 
output(&apos;dim app: &apos;         + count(dimApp) +
       &apos;\ndim contrib: &apos;   + count(dimContrib) +
       &apos;\ndim field def: &apos; + count(dimFieldDef) +
       &apos;\nfact file: &apos;     + count(factFile) +
       &apos;\nfact field: &apos;    + count(factField), named(&apos;dim_fact_counts&apos;));

stgApp      := d.files.appDetails;
stgFieldDef := d.files.fieldDef;
stgFile     := d.files.fileStat;
stgField    := d.files.fieldStat;

// Get counts of stg files, useful to see if dim and fact after counts the before count plus the stg
output(&apos;stg app: &apos;         + count(stgApp) +
       &apos;\nstg field def: &apos; + count(stgFieldDef) +
       &apos;\nstg file: &apos;      + count(stgFile) +
       &apos;\nstg field: &apos;     + count(stgField), named(&apos;stg_counts&apos;));

// Output any empty records in the dims or facts
output(dimApp(application_id = &apos;&apos;),    named(&apos;dim_app_empty&apos;));
output(dimContrib(contributorid = &apos;&apos;), named(&apos;dim_contrib_empty&apos;));
output(dimFieldDef(application_id = &apos;&apos; or batchversion = &apos;&apos; or field_name = &apos;&apos; or field_category = &apos;&apos;),   named(&apos;dim_field_def_empty&apos;));
output(factFile(wuid = &apos;&apos; or batchnumber = &apos;&apos; or batchversion = &apos;&apos;),  named(&apos;fact_file_empty&apos;));
output(factField(wuid = &apos;&apos; or batchnumber = &apos;&apos; or batchversion = &apos;&apos;), named(&apos;fact_field_empty&apos;));

// Output any -1 sk records in the facts
output(factFile(application_sk = -1 or contributor_sk = -1), named(&apos;fact_file_neg1&apos;));
output(factField(application_sk = -1 or field_def_sk = -1),  named(&apos;fact_field_neg1&apos;));&#13;&#10;</ShortText>
  <Text>&lt;Archive build=&quot;community_7.12.38-1&quot;
         eclVersion=&quot;7.12.38&quot;
         legacyImport=&quot;0&quot;
         legacyWhen=&quot;0&quot;&gt;
 &lt;Query attributePath=&quot;data_scoring.test_data_scoring&quot;/&gt;
 &lt;Module key=&quot;data_scoring&quot; name=&quot;data_scoring&quot;&gt;
  &lt;Attribute key=&quot;test_data_scoring&quot;
             name=&quot;test_data_scoring&quot;
             sourcePath=&quot;C:\Users\slushejx\OneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\Documents\Work\ECL Local Files\data_scoring\test_data_scoring.ecl&quot;
             ts=&quot;1619469991380572&quot;&gt;
   import red.dm;
import red.source.data_scoring as d;

dimApp      := dm.dim_data_scoring_application.file;
dimContrib  := dm.dim_data_scoring_contributor.file;
dimFieldDef := dm.dim_data_scoring_field_definition.file;
factFile    := dm.fact_data_scoring_file_stat.file;
factField   := dm.fact_data_scoring_field_stat.file;

dimAppLayout      := dm.dim_data_scoring_application.layout;
dimContribLayout  := dm.dim_data_scoring_contributor.layout;
dimFieldDefLayout := dm.dim_data_scoring_field_definition.layout;
factFileLayout    := dm.fact_data_scoring_file_stat.layout;
factFieldLayout   := dm.fact_data_scoring_field_stat.layout;

// Get counts of dims and facts, useful to run before and after build to compare 
output(&amp;apos;dim app: &amp;apos;         + count(dimApp) +
       &amp;apos;\ndim contrib: &amp;apos;   + count(dimContrib) +
       &amp;apos;\ndim field def: &amp;apos; + count(dimFieldDef) +
       &amp;apos;\nfact file: &amp;apos;     + count(factFile) +
       &amp;apos;\nfact field: &amp;apos;    + count(factField), named(&amp;apos;dim_fact_counts&amp;apos;));

stgApp      := d.files.appDetails;
stgFieldDef := d.files.fieldDef;
stgFile     := d.files.fileStat;
stgField    := d.files.fieldStat;

// Get counts of stg files, useful to see if dim and fact after counts the before count plus the stg
output(&amp;apos;stg app: &amp;apos;         + count(stgApp) +
       &amp;apos;\nstg field def: &amp;apos; + count(stgFieldDef) +
       &amp;apos;\nstg file: &amp;apos;      + count(stgFile) +
       &amp;apos;\nstg field: &amp;apos;     + count(stgField), named(&amp;apos;stg_counts&amp;apos;));

// Output any empty records in the dims or facts
output(dimApp(application_id = &amp;apos;&amp;apos;),    named(&amp;apos;dim_app_empty&amp;apos;));
output(dimContrib(contributorid = &amp;apos;&amp;apos;), named(&amp;apos;dim_contrib_empty&amp;apos;));
output(dimFieldDef(application_id = &amp;apos;&amp;apos; or batchversion = &amp;apos;&amp;apos; or field_name = &amp;apos;&amp;apos; or field_category = &amp;apos;&amp;apos;),   named(&amp;apos;dim_field_def_empty&amp;apos;));
output(factFile(wuid = &amp;apos;&amp;apos; or batchnumber = &amp;apos;&amp;apos; or batchversion = &amp;apos;&amp;apos;),  named(&amp;apos;fact_file_empty&amp;apos;));
output(factField(wuid = &amp;apos;&amp;apos; or batchnumber = &amp;apos;&amp;apos; or batchversion = &amp;apos;&amp;apos;), named(&amp;apos;fact_field_empty&amp;apos;));

// Output any -1 sk records in the facts
output(factFile(application_sk = -1 or contributor_sk = -1), named(&amp;apos;fact_file_neg1&amp;apos;));
output(factField(application_sk = -1 or field_def_sk = -1),  named(&amp;apos;fact_field_neg1&amp;apos;));&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red&quot; name=&quot;red&quot;/&gt;
 &lt;Module key=&quot;red.dm&quot; name=&quot;red.dm&quot;&gt;
  &lt;Attribute key=&quot;dim_data_scoring_application&quot;
             name=&quot;dim_data_scoring_application&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_application.ecl&quot;
             ts=&quot;1615993080581567&quot;&gt;
   import std;
import red.dm;
import red.common;
import red.common.util;

export dim_data_scoring_application := module

  export layout := record 
    integer4  application_sk;
    string4   application_id;
    string25  application_name;
    string10  environment;
  end;

  shared string file_name := &amp;apos;dim_data_scoring_application&amp;apos;;

  export file := if(nothor(std.file.superfileexists(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name)),
                    dataset(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name, layout, thor),
									           dataset([ {-1, &amp;apos;UA&amp;apos;, &amp;apos;Unassigned&amp;apos;,     &amp;apos;&amp;apos;},
                                       {-2, &amp;apos;NA&amp;apos;, &amp;apos;Not Applicable&amp;apos;, &amp;apos;&amp;apos;} ], layout ) );

  export add (dataset(layout) input) := function
     
    // Join the existing dim with the new input; use the existing sk if present,
    // if the application is not in the new input OR it is in the input but
    // the application name is empty, keep the existing record, else overwrite
    // the application name with the new value from the input
    layout mergeThem(layout L, layout R)  := transform
      self.application_sk := L.application_sk;
      self := if(R.application_name = &amp;apos;&amp;apos;, L, R); 
    end; 

    merged := join(file, input,
                   left.application_id = right.application_id and
                   left.environment    = right.environment,
                   mergeThem(left, right),
                   full outer);

    maxID := max(file, application_sk);
    
    // Assign a new sk value to any new records
    layout assign_sk(layout L, layout R) := transform
      self.application_sk := max(maxID, L.application_sk) + 1;
      self := R;
    end;
    
    withID := iterate(merged(application_sk = 0), assign_sk(left, right));
    
    final := merged(application_sk != 0) + withID;
    
    dim_dup_chk := common.validate.mac_dup_sk_validate(final, application_sk);

    promote := util.fn_promote_ds(final, $.dim_file_prefix, file_name, true);
    
    return sequential(dim_dup_chk, promote);
  end;
				
  export despray := dm.fn_despray(file_name); 

end;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;dim_file_prefix&quot;
             name=&quot;dim_file_prefix&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\dim_file_prefix.ecl&quot;
             ts=&quot;1615993080678308&quot;&gt;
   EXPORT string dim_file_prefix := &amp;apos;~thor::red::dm&amp;apos;;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;dim_despray_prefix&quot;
             name=&quot;dim_despray_prefix&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\dim_despray_prefix.ecl&quot;
             ts=&quot;1615993080596528&quot;&gt;
   EXPORT dim_despray_prefix := &amp;apos;~thor::red::despray&amp;apos;;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;fact_file_prefix&quot;
             name=&quot;fact_file_prefix&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\fact_file_prefix.ecl&quot;
             ts=&quot;1615993081739469&quot;&gt;
   EXPORT string fact_file_prefix := &amp;apos;~thor::red::dm&amp;apos;;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;fn_despray&quot;
             name=&quot;fn_despray&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\fn_despray.ecl&quot;
             ts=&quot;1615995476141350&quot;&gt;
   import red;
import std.file;
import red.common.spray;

EXPORT fn_despray(string filename) := function
	
	adhoc_despray_folder := if (red.common.stored_adhoc_despray_folder &amp;lt;&amp;gt; &amp;apos;&amp;apos;, red.common.stored_adhoc_despray_folder + &amp;apos;\\&amp;apos;, &amp;apos;&amp;apos;);
	remote_file 	:= TRIM(red.common.stored_outbound_drive) + &amp;apos;:\\red\\data\\outbound\\sql\\dm\\&amp;apos; + adhoc_despray_folder + filename;
	thor_filename := $.dim_despray_prefix + &amp;apos;::&amp;apos; + filename;
	
	dspray :=	file.despray(thor_filename, 
												 spray.Spray_Constants().landingzone_despray,
												 remote_file + &amp;apos;.tsv&amp;apos;
												 ,,,,true);
								 
	fileexists := File.FileExists(thor_filename);
		
	return if(fileexists, dspray, output(&amp;apos;MISSING &amp;apos; + thor_filename));

end;&amp;#13;&amp;#10;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;dim_data_scoring_contributor&quot;
             name=&quot;dim_data_scoring_contributor&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_contributor.ecl&quot;
             ts=&quot;1615993080583561&quot;&gt;
   import std;
import red.dm;
import red.common;
import red.common.util;

export dim_data_scoring_contributor := module

  export layout := record 
    integer4  contributor_sk;
    string10  contributorid;
    string50  contributorname;
    string200 contributor_frequency;
    string10  environment;
  end;

  shared string file_name := &amp;apos;dim_data_scoring_contributor&amp;apos;;

  export file := if(nothor(std.file.superfileexists(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name)),
                    dataset(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name, layout, thor),
									           dataset([ {-1, &amp;apos;UA&amp;apos;, &amp;apos;Unassigned&amp;apos;,     &amp;apos;&amp;apos;, &amp;apos;&amp;apos;},
                                       {-2, &amp;apos;NA&amp;apos;, &amp;apos;Not Applicable&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;} ], layout ) );

  export add (dataset(layout) input) := function
     
    // Join the existing dim with the new input; use the existing sk if present, 
    // overwrite the other fields with the new values if present in both files
    layout mergeThem(layout L, layout R)  := transform
      self.contributor_sk := L.contributor_sk;
      self := if(R.contributorid != &amp;apos;&amp;apos;, R, L); 
    end; 

    merged := join(file, input,
                   left.contributorid = right.contributorid and
                   left.environment   = right.environment,
                   mergeThem(left, right),
                   full outer);

    maxID := max(file, contributor_sk);
    
    // Assign a new sk value to any new records
    layout assign_sk(layout L, layout R) := transform
      self.contributor_sk := max(maxID, L.contributor_sk) + 1;
      self := R;
    end;
    
    withID := iterate(merged(contributor_sk = 0), assign_sk(left, right));
    
    final := merged(contributor_sk != 0) + withID;
    
    dim_dup_chk := common.validate.mac_dup_sk_validate(final, contributor_sk);

    promote := util.fn_promote_ds(final, $.dim_file_prefix, file_name, true);
    
    return sequential(dim_dup_chk, promote);
  end;
				
  export despray := dm.fn_despray(file_name); 

end;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;dim_data_scoring_field_definition&quot;
             name=&quot;dim_data_scoring_field_definition&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\dim_data_scoring_field_definition.ecl&quot;
             ts=&quot;1615993080587552&quot;&gt;
   import std;
import red.dm;
import red.common;
import red.common.util;

export dim_data_scoring_field_definition := module

  export layout := record 
    integer4  field_def_sk;
    string100 field_name;
    string5   batchversion;
    string30  field_category;
    string500 field_desc;
    integer4  field_weight;
    string12  field_type;
    string7   field_group;
    string4   application_id;
    string10  environment;
  end;

  shared string file_name := &amp;apos;dim_data_scoring_field_definition&amp;apos;;

  export file := if(nothor(std.file.superfileexists(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name)),
                    dataset(dm.dim_file_prefix + &amp;apos;::&amp;apos; + file_name, layout, thor),
									           dataset([ {-1,  &amp;apos;UA&amp;apos;, &amp;apos;UA&amp;apos;, &amp;apos;Unassigned&amp;apos;,     &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;},
                                       {-2,  &amp;apos;NA&amp;apos;, &amp;apos;NA&amp;apos;, &amp;apos;Not Applicable&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;, &amp;apos;&amp;apos;} ], layout ) );

  export add (dataset(layout) input) := function
     
    // Join the existing dim with the new input; use the existing sk if present, 
    // if the field is not in the new input OR the field is in the input but
    // has empty information, keep the existing record, else overwrite the fields
    // with the new values from the input
    layout mergeThem(layout L, layout R)  := transform
      self.field_def_sk := L.field_def_sk;
      self              := if(R.field_desc = &amp;apos;&amp;apos; and 
                                R.field_weight = 0 and 
                                R.field_type = &amp;apos;&amp;apos; and 
                                R.field_group = &amp;apos;&amp;apos;, 
                              L, R);
    end; 

    merged := join(file, input,
                   left.field_name     = right.field_name and
                   left.batchversion   = right.batchversion and 
                   left.field_category = right.field_category and
                   left.application_id = right.application_id and
                   left.environment    = right.environment,
                   mergeThem(left, right),
                   full outer);

    maxID := max(file, field_def_sk);
    
    // Assign a new sk value to any new records
    layout assign_sk(layout L, layout R) := transform
      self.field_def_sk := max(maxID, L.field_def_sk) + 1;
      self := R;
    end;
    
    withID := iterate(merged(field_def_sk = 0), assign_sk(left, right));
    
    final := merged(field_def_sk != 0) + withID;
    
    dim_dup_chk := common.validate.mac_dup_sk_validate(final, field_def_sk);

    promote := util.fn_promote_ds(final, $.dim_file_prefix, file_name, true);
    
    return sequential(dim_dup_chk, promote);
  end;
				
  export despray := dm.fn_despray(file_name); 

end;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;fact_data_scoring_file_stat&quot;
             name=&quot;fact_data_scoring_file_stat&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_file_stat.ecl&quot;
             ts=&quot;1616174285749417&quot;&gt;
   import red.dm;
import red.common.util;

export fact_data_scoring_file_stat := module

  export layout := record
    string19   wuid;
    string14   batchnumber;
    string5    batchversion;
    string10   environment;
    string10   batchstate;
    integer4   date_sk;
    integer4   application_sk;
    integer4   contributor_sk;
    integer8   score;
    integer8   records;
    integer8   composite_hash; 
  end;

  shared file_name := &amp;apos;fact_data_scoring_file_stat&amp;apos;;

  export file := dataset(dm.fact_file_prefix + &amp;apos;::&amp;apos; + file_name, layout, thor, opt);

  export add (dataset(layout) input) := function

    // If a record exists in the existing fact and the input, update with the 
    // details from the input
    final := 
      join(file, input,
           left.application_sk = right.application_sk and
           left.batchnumber    = right.batchnumber and
           left.batchversion   = right.batchversion,
           transform(layout,
                     self := if(right.batchnumber = &amp;apos;&amp;apos;, left, right)), 
           full outer, hash, limit(1)); // limit(1) so it fails if there are multiple matches

    // Promote the fact
    return util.fn_promote_ds(final, dm.fact_file_prefix, file_name, true);
  end;

  export despray := dm.fn_despray(file_name);

end;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;fact_data_scoring_field_stat&quot;
             name=&quot;fact_data_scoring_field_stat&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\dm\fact_data_scoring_field_stat.ecl&quot;
             ts=&quot;1615993081715533&quot;&gt;
   import red.dm;
import red.common.util;

export fact_data_scoring_field_stat := module

  export layout := record
    string19    wuid;
    string14    batchnumber;
    string5     batchversion;
    string10    environment;
    integer4    date_sk;
    integer4    application_sk;
    integer4    field_def_sk;
    integer8    score_max;
    integer8    score_avg;
    integer8    score_min;
    integer8    score_sum;
    decimal12_2 score_var;
    integer8    rec_empty;
    integer8    rec_populated;
    integer8    composite_hash;
  end;

  shared file_name := &amp;apos;fact_data_scoring_field_stat&amp;apos;;

  export file := dataset(dm.fact_file_prefix + &amp;apos;::&amp;apos; + file_name, layout, thor, opt);

  export add (dataset(layout) input) := function

    // If a record exists in the existing fact and the input, update with the 
    // details from the input
    final := 
      join(file, input,
           left.application_sk = right.application_sk and  
           left.batchnumber    = right.batchnumber and
           left.batchversion   = right.batchversion and
           left.field_def_sk   = right.field_def_sk,
           transform(layout,
                     self := if(right.batchnumber = &amp;apos;&amp;apos;, left, right)), 
           full outer, hash, limit(1)); // limit(1) so it fails if there are multiple matches

    // Promote the fact
    return util.fn_promote_ds(final, dm.fact_file_prefix, file_name, true);
  end;

  export despray := dm.fn_despray(file_name);

end;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red.source&quot; name=&quot;red.source&quot;/&gt;
 &lt;Module key=&quot;red.source.data_scoring&quot; name=&quot;red.source.data_scoring&quot;&gt;
  &lt;Attribute key=&quot;files&quot;
             name=&quot;files&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\source\data_scoring\files.ecl&quot;
             ts=&quot;1615993091076275&quot;&gt;
   export files := module

  // Filename prefix values
  export srcPrefix := &amp;apos;thor::fido::descore&amp;apos;;
  export stgPrefix := &amp;apos;~thor::red::stg::data_scoring&amp;apos;;

  // Filename suffix values
  export fileStatSuffix     := &amp;apos;filestat&amp;apos;;
  export fieldStatSuffix    := &amp;apos;fieldstat&amp;apos;;
  export fieldDefSuffix     := &amp;apos;fielddef&amp;apos;;
  export appDetailsSuffix   := &amp;apos;applicationdetails&amp;apos;;

  // Source base filenames, source files are read from foreign prod
  export srcFileStatName   := $.constants.foreignPrefix + srcPrefix + &amp;apos;::&amp;apos; + $.constants.file_date + &amp;apos;::&amp;apos; + fileStatSuffix;
  export srcFieldStatName  := $.constants.foreignPrefix + srcPrefix + &amp;apos;::&amp;apos; + $.constants.file_date + &amp;apos;::&amp;apos; + fieldStatSuffix;
  export srcFieldDefName   := $.constants.foreignPrefix + srcPrefix + &amp;apos;::&amp;apos; + fieldDefSuffix;
  export srcAppDetailsName := $.constants.foreignPrefix + srcPrefix + &amp;apos;::&amp;apos; + appDetailsSuffix;

  // Source base datasets
  export srcFileStat   := dataset(srcFileStatName,   $.layouts.file_stat,   thor, opt);
  export srcFieldStat  := dataset(srcFieldStatName,  $.layouts.field_stat,  thor, opt);
  export srcFieldDef   := dataset(srcFieldDefName,   $.layouts.field_def,   thor, opt);
  export srcAppDetails := dataset(srcAppDetailsName, $.layouts.app_details, thor, opt);

  // Stage filenames
  export stgFileStatName   := stgPrefix + &amp;apos;::&amp;apos; + fileStatSuffix;
  export stgFieldStatName  := stgPrefix + &amp;apos;::&amp;apos; + fieldStatSuffix;
  export stgFieldDefName   := stgPrefix + &amp;apos;::&amp;apos; + fieldDefSuffix;
  export stgAppDetailsName := stgPrefix + &amp;apos;::&amp;apos; + appDetailsSuffix;

  // Stage datasets
  export fileStat   := dataset(stgFileStatName,   $.layouts.file_stat,   thor);
  export fieldStat  := dataset(stgFieldStatName,  $.layouts.field_stat,  thor);
  export fieldDef   := dataset(stgFieldDefName,   $.layouts.field_def,   thor);
  export appDetails := dataset(stgAppDetailsName, $.layouts.app_details, thor);

end;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;constants&quot;
             name=&quot;constants&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\source\data_scoring\constants.ecl&quot;
             ts=&quot;1615993091070289&quot;&gt;
   import std;
import red.common.constants as c;

export constants := module

  shared yesterday := std.date.adjustDate(std.date.today(), 0, 0, -1);

  export file_date := yesterday    : stored(&amp;apos;file_date&amp;apos;); // Default to yesterday, build will run after midnight
  export env       := &amp;apos;UKInsProd&amp;apos;  : stored(&amp;apos;environment&amp;apos;);

  shared alpha_prod := c.foreign + &amp;apos;::&amp;apos; + c.ins_dali_dnsname + &amp;apos;::&amp;apos;;
  shared alpha_dev  := c.foreign + &amp;apos;::&amp;apos; + c.ins_dev_dali     + &amp;apos;::&amp;apos;;
  shared uk_prod    := c.foreign + &amp;apos;::&amp;apos; + c.uk_prod_dali     + &amp;apos;::&amp;apos;;
  shared uk_dev     := c.foreign + &amp;apos;::&amp;apos; + c.uk_dev_dali      + &amp;apos;::&amp;apos;;

  export foreignPrefix  := map(env = &amp;apos;USInsProd&amp;apos; =&amp;gt; alpha_prod,
                               env = &amp;apos;UKInsProd&amp;apos; =&amp;gt; uk_prod,
                               env = &amp;apos;USInsDev&amp;apos;  =&amp;gt; alpha_dev,
                               env = &amp;apos;UKInsDev&amp;apos;  =&amp;gt; uk_dev,
                               alpha_prod);		
end;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;layouts&quot;
             name=&quot;layouts&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\source\data_scoring\layouts.ecl&quot;
             ts=&quot;1619537925273995&quot;&gt;
   export layouts := module

  export file_stat := record
    string4    application_id;
    string50   datasetid_key;
    string10   contributor_id;
    string200  contributor_name;
    string200  contributor_frequency;
    string14   batch_number;
    string5    batch_version;
    string10   batch_state;
    string8    date; 
    integer8   score;
    integer8   records; 
  end;
	
  export field_stat := record
    string4     application_id;
    string50    datasetid_key;
    string30    field_category;
    string14    batch_number;
    string5     batch_version;
    string100   field_name;
    integer8    score_max; 
    integer8    score_avg;
    integer8    score_min;
    integer8    score_sum;
    decimal12_2 score_var;
    integer8    rec_empty; 
    integer8    rec_populated;
  end;

  export field_def := record 
    string4   application_id;
    string5   batch_version;
    string100 field_name;
    string500 field_desc;
    integer4  field_weight;
    string12  field_type;
    string30  field_category;
    string7   field_group;
  end;

  export app_details := record
    string4   application_id;
    string25  application_name;
  end;

end;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;std&quot; name=&quot;std&quot;&gt;
  &lt;Attribute key=&quot;file&quot;
             name=&quot;file&quot;
             sourcePath=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\share\ecllibrary\std\File.ecl&quot;
             ts=&quot;1616674832000000&quot;&gt;
   /*##############################################################################
## HPCC SYSTEMS software Copyright (C) 2012 HPCC Systems.  All rights reserved.
############################################################################## */

EXPORT File := MODULE

IMPORT lib_fileservices;

/*------------------------------------- Various types and constants -----------------------------------------------*/
/**
 * A record containing information about filename.  Includes name, size and when last modified.
 * export FsFilenameRecord := RECORD
 *     string name;
 *     integer8 size;
 *     string19 modified;
 * END;
 */

EXPORT FsFilenameRecord := lib_fileservices.FsFilenameRecord;

/**
 * An alias for a logical filename that is stored in a row.
 */

EXPORT FsLogicalFileName := lib_fileservices.FsLogicalFileName;

/**
 * A record containing a logical filename. It contains the following fields:
 *
 * @field name          The logical name of the file;
 */

EXPORT FsLogicalFileNameRecord := lib_fileservices.FsLogicalFileNameRecord;

/**
 * A record containing information about a logical file.
 *
 * @inherits            Contains all the fields in FsLogicalFileNameRecord)
 * @field superfile     Is this a superfile?
 * @field size          Number of bytes in the file (before compression)
 * @field rowcount      Number of rows in the file.
 * @modified            Timestamp when the file was last modified;
 * @owner               The username of the owner who ran the job to create this file.
 * @cluster             The cluster that this file was created on.
 */

EXPORT FsLogicalFileInfoRecord := lib_fileservices.FsLogicalFileInfoRecord;

/**
 * A record containing information about a superfile and its contents.
 *
 * @field supername     The name of the superfile
 * @field subname       The name of the sub-file
 */

EXPORT FsLogicalSuperSubRecord := lib_fileservices.FsLogicalSuperSubRecord;

/**
 * A record containing information about the relationship between two files.
 *
 * @field primaryfile   The logical filename of the primary file
 * @field secondaryfile The logical filename of the secondary file.
 * @field primaryflds   The name of the primary key field for the primary file. The value &amp;quot;__fileposition__&amp;quot;
 *                      indicates the secondary is an INDEX that must use FETCH to access non-keyed fields.
 * @field secondaryflds The name of the foreign key field relating to the primary file.
 * @field kind          The type of relationship between the primary and secondary files.
 *                      Containing either &amp;apos;link&amp;apos; or &amp;apos;view&amp;apos;.
 * @field cardinality   The cardinality of the relationship.  The format is &amp;lt;primary&amp;gt;:&amp;lt;secondary&amp;gt;. Valid values are
 *                      &amp;quot;1&amp;quot; or &amp;quot;M&amp;quot;.
 * @field payload       Indicates whether the primary or secondary are payload INDEXes.
 * @field description   The description of the relationship.
 */

EXPORT FsFileRelationshipRecord := lib_fileservices.FsFileRelationshipRecord;

/**
 * Constant that indicates IBM RECFM V format file.  Can be passed to SprayFixed for the record size.
 */

EXPORT RECFMV_RECSIZE := lib_fileservices.RECFMV_RECSIZE;

/**
 * Constant that indicates IBM RECFM VB format file.  Can be passed to SprayFixed for the record size.
 */

EXPORT RECFMVB_RECSIZE := lib_fileservices.RECFMVB_RECSIZE;

/**
 * Constant that indicates a variable little endian 4 byte length prefixed file.  Can be passed to SprayFixed for the record size.
 */

EXPORT INTEGER4 PREFIX_VARIABLE_RECSIZE := lib_fileservices.PREFIX_VARIABLE_RECSIZE;

/**
 * Constant that indicates a variable big endian 4 byte length prefixed file.  Can be passed to SprayFixed for the record size.
 */

EXPORT INTEGER4 PREFIX_VARIABLE_BIGENDIAN_RECSIZE := lib_fileservices.PREFIX_VARIABLE_BIGENDIAN_RECSIZE;

EXPORT FsDropZone := lib_fileservices.FsDropZone;

EXPORT FsDropZoneRecord := lib_fileservices.FsDropZoneRecord;

/*------------------------------------- Spray functions -----------------------------------------------------------*/

/**
 * Returns whether the file exists.
 *
 * @param lfn           The logical name of the file.
 * @param physical      Whether to also check for the physical existence on disk.  Defaults to FALSE.
 * @return              Whether the file exists.
 */

EXPORT boolean FileExists(varstring lfn, boolean physical=FALSE) :=
    lib_fileservices.FileServices.FileExists(lfn, physical);

/**
 * Removes the logical file from the system, and deletes from the disk.
 *
 * @param lfn           The logical name of the file.
 * @param allowMissing  Whether to suppress an error if the filename does not exist. Defaults to FALSE.
 */

EXPORT DeleteLogicalFile(varstring lfn, boolean allowMissing=FALSE) :=
    lib_fileservices.FileServices.DeleteLogicalFile(lfn, allowMissing);

/**
 * Changes whether access to a file is read only or not.
 *
 * @param lfn           The logical name of the file.
 * @param ro            Whether updates to the file are disallowed.  Defaults to TRUE.
 */
EXPORT SetReadOnly(varstring lfn, boolean ro=TRUE) :=
    lib_fileservices.FileServices.SetReadOnly(lfn, ro);

/**
 * Changes the name of a logical file.
 *
 * @param oldname       The current name of the file to be renamed.
 * @param newname       The new logical name of the file.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 */

EXPORT RenameLogicalFile(varstring oldname, varstring newname, boolean allowOverwrite=FALSE) :=
    lib_fileservices.FileServices.RenameLogicalFile(oldname, newname, allowOverwrite);

/**
 * Returns a logical filename that can be used to refer to a logical file in a local or remote dali.
 *
 * @param name          The logical name of the file.
 * @param foreigndali   The IP address of the foreign dali used to resolve the file.  If blank then the file is resolved
 *                      locally.  Defaults to blank.
 * @param abspath       Should a tilde (~) be prepended to the resulting logical file name.  Defaults to FALSE.
 */

EXPORT varstring ForeignLogicalFileName(varstring name, varstring foreigndali=&amp;apos;&amp;apos;, boolean abspath=FALSE, boolean omitClusterPrefix=FALSE) :=
    lib_fileservices.FileServices.ForeignLogicalFileName(name, foreigndali, abspath, omitClusterPrefix);

/**
 * Returns an encoded logical filename that can be used to refer to a external file.  Examples include directly
 * reading from a landing zone.  Upper case characters and other details are escaped.
 *
 * @param location      The IP address of the remote machine. &amp;apos;.&amp;apos; can be used for the local machine.
 * @param path          The path/name of the file on the remote machine.
 * @param abspath       Should a tilde (~) be prepended to the resulting logical file name.  Defaults to TRUE.
 * @return              The encoded logical filename.
 */

EXPORT varstring ExternalLogicalFileName(varstring location, varstring path, boolean abspath=TRUE) :=
    lib_fileservices.FileServices.ExternalLogicalFileName(location, path, abspath);

/**
 * Returns a string containing the description information associated with the specified filename. This description
 * is set either through ECL watch or by using the FileServices.SetFileDescription function.
 *
 * @param lfn           The logical name of the file.
 */

EXPORT varstring GetFileDescription(varstring lfn) :=
    lib_fileservices.FileServices.GetFileDescription(lfn);

/**
 * Sets the description associated with the specified filename.
 *
 * @param lfn           The logical name of the file.
 * @param val           The description to be associated with the file.
 */

EXPORT SetFileDescription(varstring lfn, varstring val) :=
    lib_fileservices.FileServices.SetFileDescription(lfn, val);

/**
 * Returns a dataset containing a list of files from the specified machineIP and directory.
 *
 * @param machineIP     The IP address of the remote machine.
 * @param directory     The path to the directory to read. This must be in the appropriate format for the operating
 *                      system running on the remote machine.
 * @param mask          The filemask specifying which files to include in the result. Defaults to &amp;apos;*&amp;apos; (all files).
 * @param recurse       Whether to include files from subdirectories under the directory. Defaults to FALSE.
 */
EXPORT dataset(FsFilenameRecord) RemoteDirectory(varstring machineIP, varstring dir, varstring mask=&amp;apos;*&amp;apos;, boolean recurse=FALSE) :=
    lib_fileservices.FileServices.RemoteDirectory(machineIP, dir, mask, recurse);

/**
 * Returns a dataset of information about the logical files known to the system.
 *
 * @param namepattern   The mask of the files to list. Defaults to &amp;apos;*&amp;apos; (all files).
 * @param includenormal Whether to include &amp;apos;normal&amp;apos; files. Defaults to TRUE.
 * @param includesuper  Whether to include SuperFiles. Defaults to FALSE.
 * @param unknownszero  Whether to set file sizes that are unknown to zero(0) instead of minus-one (-1). Defaults to FALSE.
 * @param foreigndali   The IP address of the foreign dali used to resolve the file.  If blank then the file is resolved
 *                      locally.  Defaults to blank.
 */
EXPORT dataset(FsLogicalFileInfoRecord) LogicalFileList(varstring namepattern=&amp;apos;*&amp;apos;, boolean includenormal=TRUE, boolean includesuper=FALSE, boolean unknownszero=FALSE, varstring foreigndali=&amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.LogicalFileList(namepattern, includenormal, includesuper, unknownszero, foreigndali);

/**
 * Compares two files, and returns a result indicating how well they match.
 *
 * @param file1         The logical name of the first file.
 * @param file2         The logical name of the second file.
 * @param logical_only  Whether to only compare logical information in the system datastore (Dali), and ignore physical
                        information on disk. [Default TRUE]
 * @param use_crcs      Whether to compare physical CRCs of all the parts on disk. This may be slow on large files.
                        Defaults to FALSE.
 * @return              0 if file1 and file2 match exactly
 *                      1 if file1 and file2 contents match, but file1 is newer than file2
 *                      -1 if file1 and file2 contents match, but file2 is newer than file1
 *                      2 if file1 and file2 contents do not match and file1 is newer than file2
 *                      -2 if file1 and file2 contents do not match and file2 is newer than file1
 */

EXPORT INTEGER4 CompareFiles(varstring lfn1, varstring lfn2, boolean logical_only=TRUE, boolean use_crcs=FALSE) :=
    lib_fileservices.FileServices.CompareFiles(lfn1, lfn2, logical_only, use_crcs);

/**
 * Checks the system datastore (Dali) information for the file against the physical parts on disk.
 *
 * @param lfn           The name of the file to check.
 * @param use_crcs      Whether to compare physical CRCs of all the parts on disk. This may be slow on large files.
 * @return              &amp;apos;OK&amp;apos; - The file parts match the datastore information
 *                      &amp;apos;Could not find file: &amp;lt;filename&amp;gt;&amp;apos; - The logical filename was not found
 *                      &amp;apos;Could not find part file: &amp;lt;partname&amp;gt;&amp;apos; - The partname was not found
 *                      &amp;apos;Modified time differs for: &amp;lt;partname&amp;gt;&amp;apos; - The partname has a different timestamp
 *                      &amp;apos;File size differs for: &amp;lt;partname&amp;gt;&amp;apos; - The partname has a file size
 *                      &amp;apos;File CRC differs for: &amp;lt;partname&amp;gt;&amp;apos; - The partname has a different CRC
 */

EXPORT varstring VerifyFile(varstring lfn, boolean usecrcs) :=
    lib_fileservices.FileServices.VerifyFile(lfn, usecrcs);

/**
 * Defines the relationship between two files. These may be DATASETs or INDEXes. Each record in the primary file
 * should be uniquely defined by the primaryfields (ideally), preferably efficiently.  This information is used
 * by the roxie browser to link files together.
 *
 * @param primary       The logical filename of the primary file.
 * @param secondary     The logical filename of the secondary file.
 * @param primaryfields The name of the primary key field for the primary file. The value &amp;quot;__fileposition__&amp;quot;
 *                      indicates the secondary is an INDEX that must use FETCH to access non-keyed fields.
 * @param secondaryfields The name of the foreign key field relating to the primary file.
 * @param relationship  The type of relationship between the primary and secondary files.
 *                      Containing either &amp;apos;link&amp;apos; or &amp;apos;view&amp;apos;.  Default is &amp;quot;link&amp;quot;.
 * @param cardinality   The cardinality of the relationship.  The format is &amp;lt;primary&amp;gt;:&amp;lt;secondary&amp;gt;. Valid values are
 *                      &amp;quot;1&amp;quot; or &amp;quot;M&amp;quot;.
 * @param payload       Indicates whether the primary or secondary are payload INDEXes.
 * @param description   The description of the relationship.
 */

EXPORT AddFileRelationship(varstring primary, varstring secondary, varstring primaryflds,  varstring secondaryflds, varstring kind=&amp;apos;link&amp;apos;, varstring cardinality, boolean payload, varstring description=&amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.AddFileRelationship(primary, secondary, primaryflds,  secondaryflds, kind, cardinality, payload, description);

/**
 * Returns a dataset of relationships.   The return records are structured in the FsFileRelationshipRecord format.
 *
 * @param primary       The logical filename of the primary file.
 * @param secondary     The logical filename of the secondary file.&amp;lt;/para&amp;gt;
 * @param primaryfields The name of the primary key field for the primary file.
 * @param secondaryfields The name of the foreign key field relating to the primary file.
 * @param relationship  The type of relationship between the primary and secondary files.
 *                      Containing either &amp;apos;link&amp;apos; or &amp;apos;view&amp;apos;.  Default is &amp;quot;link&amp;quot;.
 */

EXPORT dataset(FsFileRelationshipRecord) FileRelationshipList(varstring primary, varstring secondary, varstring primflds=&amp;apos;&amp;apos;, varstring secondaryflds=&amp;apos;&amp;apos;,  varstring kind=&amp;apos;link&amp;apos;) :=
    lib_fileservices.FileServices.FileRelationshipList(primary, secondary, primflds, secondaryflds, kind);

/**
 * Removes a relationship between two files.
 *
 * @param primary       The logical filename of the primary file.
 * @param secondary     The logical filename of the secondary file.
 * @param primaryfields The name of the primary key field for the primary file.
 * @param secondaryfields The name of the foreign key field relating to the primary file.
 * @param relationship  The type of relationship between the primary and secondary files.
 *                      Containing either &amp;apos;link&amp;apos; or &amp;apos;view&amp;apos;.  Default is &amp;quot;link&amp;quot;.
 */

EXPORT RemoveFileRelationship(varstring primary,  varstring secondary, varstring primaryflds=&amp;apos;&amp;apos;, varstring secondaryflds=&amp;apos;&amp;apos;,  varstring kind=&amp;apos;link&amp;apos;) :=
    lib_fileservices.FileServices.RemoveFileRelationship(primary,  secondary, primaryflds, secondaryflds,  kind);

/**
 * Returns the field mappings for the file, in the same format specified for the SetColumnMapping function.
 *
 * @param lfn           The logical filename of the primary file.
 */

EXPORT varstring GetColumnMapping(varstring lfn) :=
    lib_fileservices.FileServices.GetColumnMapping(lfn);

/**
 * Defines how the data in the fields of the file mist be transformed between the actual data storage format and the
 * input format used to query that data.  This is used by the user interface of the roxie browser.
 *
 * @param lfn           The logical filename of the primary file.
 * @param mapping       A string containing a comma separated list of field mappings.
 */

EXPORT SetColumnMapping(varstring lfn, varstring mapping) :=
    lib_fileservices.FileServices.SetColumnMapping(lfn, mapping);

/**
 * Returns a string that can be used in a DATASET declaration to read data from an RFS (Remote File Server) instance
 * (e.g. rfsmysql) on another node.
 *
 * @param server        A string containing the ip:port address for the remote file server.
 * @param query         The text of the query to send to the server
 */

EXPORT varstring EncodeRfsQuery(varstring server, varstring query) :=
    lib_fileservices.FileServices.RfsQuery(server, query);

/**
 * Sends the query to the rfs server.
 *
 * @param server        A string containing the ip:port address for the remote file server.
 * @param query         The text of the query to send to the server
 */

EXPORT RfsAction(varstring server, varstring query) :=
    lib_fileservices.FileServices.RfsAction(server, query);

/**
 * Moves the single physical file between two locations on the same remote machine. The
 * dafileserv utility program must be running on the location machine.
 *
 * @param location      The IP address of the remote machine.
 * @param frompath      The path/name of the file to move.
 * @param topath        The path/name of the target file.
 */
EXPORT MoveExternalFile(varstring location, varstring frompath, varstring topath) :=
    lib_fileservices.FileServices.MoveExternalFile(location, frompath, topath);

/**
 * Removes a single physical file from a remote machine. The
 * dafileserv utility program must be running on the location machine.
 *
 * @param location      The IP address of the remote machine.
 * @param path          The path/name of the file to remove.
 */
EXPORT DeleteExternalFile(varstring location, varstring path) :=
    lib_fileservices.FileServices.DeleteExternalFile(location, path);

/**
 * Creates the path on the location (if it does not already exist). The
 * dafileserv utility program must be running on the location machine.
 *
 * @param location      The IP address of the remote machine.
 * @param path          The path/name of the file to remove.
 */
EXPORT CreateExternalDirectory(varstring location, varstring path) :=
    lib_fileservices.FileServices.CreateExternalDirectory(location, path);

/**
 * Returns the value of the given attribute for the specified logicalfilename.
 *
 * @param lfn           The name of the logical file.
 * @param attrname      The name of the file attribute to return.
 */
EXPORT varstring GetLogicalFileAttribute(varstring lfn, varstring attrname) :=
    lib_fileservices.FileServices.GetLogicalFileAttribute(lfn, attrname);

/**
 * Toggles protection on and off for the specified logicalfilename.
 *
 * @param lfn           The name of the logical file.
 * @param value         TRUE to enable protection, FALSE to disable.
 */
EXPORT ProtectLogicalFile(varstring lfn, boolean value=TRUE) :=
    lib_fileservices.FileServices.ProtectLogicalFile(lfn, value);

/**
 * The DfuPlusExec action executes the specified command line just as the DfuPLus.exe program would do. This
 * allows you to have all the functionality of the DfuPLus.exe program available within your ECL code.
 *
 * param cmdline        The DFUPlus.exe command line to execute. The valid arguments are documented in the Client
 *                      Tools manual, in the section describing the DfuPlus.exe program.
 */
EXPORT DfuPlusExec(varstring cmdline) :=
    lib_fileservices.FileServices.DfuPlusExec(cmdline);

/*------------------------------------- Spray functions -----------------------------------------------------------*/

/**
 * Sprays a file of fixed length records from a single machine and distributes it across the nodes of the
 * destination group.
 *
 * @param sourceIP      The IP address of the file.
 * @param sourcePath    The path and name of the file.
 * @param recordsize    The size (in bytes) of the records in the file.
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to -1 (let system decide).
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Whether to replicate the new file. Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param failIfNoSourceFile If TRUE it causes a missing source file to trigger a failure.  Defaults to FALSE.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @param dfuServerQueue Name of target DFU Server queue. Default is &amp;apos;&amp;apos; (empty) for the first DFU queue in the environment.
 * @param noSplit      Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @return              The DFU workunit id for the job.
 */
EXPORT varstring fSprayFixed(varstring sourceIP, varstring sourcePath, integer4 recordSize, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.fSprayFixed(sourceIP, sourcePath, recordSize, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit);

/**
 * Same as fSprayFixed, but does not return the DFU Workunit ID.
 *
 * @see fSprayFixed
 */

EXPORT SprayFixed(varstring sourceIP, varstring sourcePath, integer4 recordSize, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.SprayFixed(sourceIP, sourcePath, recordSize, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit);

// fSprayVariable is now called fSprayDelimited (but the old name is available for backward compatibility)
EXPORT varstring fSprayVariable(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, varstring sourceCsvQuote=&amp;apos;\&amp;quot;&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=FALSE, boolean recordStructurePresent=FALSE, boolean quotedTerminator=TRUE, varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.fSprayVariable(sourceIP, sourcePath, sourceMaxRecordSize, sourceCsvSeparate, sourceCsvTerminate, sourceCsvQuote, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, sourceCsvEscape, failIfNoSourceFile, recordStructurePresent, quotedTerminator, encoding, expireDays, dfuServerQueue, noSplit);

// SprayVariable is now called SprayDelimited (but the old name is available for backward compatibility)
EXPORT SprayVariable(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, varstring sourceCsvQuote=&amp;apos;\&amp;quot;&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=FALSE, boolean recordStructurePresent=FALSE, boolean quotedTerminator=TRUE, varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.SprayVariable(sourceIP, sourcePath, sourceMaxRecordSize, sourceCsvSeparate, sourceCsvTerminate, sourceCsvQuote, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, sourceCsvEscape, failIfNoSourceFile, recordStructurePresent, quotedTerminator, encoding, expireDays, dfuServerQueue, noSplit);

/**
 * Sprays a file of fixed delimited records from a single machine and distributes it across the nodes of the
 * destination group.
 *
 * @param sourceIP      The IP address of the file.
 * @param sourcePath    The path and name of the file.
 * @param sourceCsvSeparate The character sequence which separates fields in the file.
 * @param sourceCsvTerminate The character sequence which separates records in the file.
 * @param sourceCsvQuote A string which can be used to delimit fields in the file.
 * @param sourceMaxRecordSize    The maximum size (in bytes) of the records in the file.
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Whether to replicate the new file. Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param sourceCsvEscape A character that is used to escape quote characters.  Defaults to none.
 * @param failIfNoSourceFile If TRUE it causes a missing source file to trigger a failure.  Defaults to FALSE.
 * @param recordStructurePresent If TRUE derives the record structure from the header of the file.
 * @param quotedTerminator Can the terminator character be included in a quoted field.  Defaults to TRUE.
 *                      If FALSE it allows quicker partitioning of the file (avoiding a complete file scan).
 * @param encoding      A null-terminated string containing the encoding. 
 *                      Can be set to one of the following: 
 *                      ascii, utf8, utf8n, utf16, utf16le, utf16be, utf32, utf32le,utf32be. If omitted, the default is ascii.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @param dfuServerQueue Name of target DFU Server queue. Default is &amp;apos;&amp;apos; (empty) for the first DFU queue in the environment.
 * @param noSplit      Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @return              The DFU workunit id for the job.
 */
EXPORT varstring fSprayDelimited(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, varstring sourceCsvQuote=&amp;apos;\&amp;quot;&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=FALSE, boolean recordStructurePresent=FALSE, boolean quotedTerminator=TRUE, varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.fSprayVariable(sourceIP, sourcePath, sourceMaxRecordSize, sourceCsvSeparate, sourceCsvTerminate, sourceCsvQuote, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, sourceCsvEscape, failIfNoSourceFile, recordStructurePresent, quotedTerminator, encoding, expireDays, dfuServerQueue, noSplit);

/**
 * Same as fSprayDelimited, but does not return the DFU Workunit ID.
 *
 * @see fSprayDelimited
 */

EXPORT SprayDelimited(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, varstring sourceCsvQuote=&amp;apos;\&amp;quot;&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=FALSE, boolean recordStructurePresent=FALSE, boolean quotedTerminator=TRUE, const varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.SprayVariable(sourceIP, sourcePath, sourceMaxRecordSize, sourceCsvSeparate, sourceCsvTerminate, sourceCsvQuote, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, sourceCsvEscape, failIfNoSourceFile, recordStructurePresent, quotedTerminator, encoding, expireDays, dfuServerQueue, noSplit);



/**
 * Sprays an xml file from a single machine and distributes it across the nodes of the destination group.
 *
 * @param sourceIP      The IP address of the file.
 * @param sourcePath    The path and name of the file.
 * @param sourceMaxRecordSize    The maximum size (in bytes) of the records in the file.
 * @param sourceRowTag  The xml tag that is used to delimit records in the source file.  (This tag cannot recursivly nest.)
 * @param sourceEncoding The unicode encoding of the file.  (utf8,utf8n,utf16be,utf16le,utf32be,utf32le)
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Whether to replicate the new file. Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param failIfNoSourceFile If TRUE it causes a missing source file to trigger a failure.  Defaults to FALSE.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @param dfuServerQueue Name of target DFU Server queue. Default is &amp;apos;&amp;apos; (empty) for the first DFU queue in the environment.
 * @param noSplit      Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fSprayXml(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceRowTag, varstring sourceEncoding=&amp;apos;utf8&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.fSprayXml(sourceIP, sourcePath, sourceMaxRecordSize, sourceRowTag, sourceEncoding, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit);

/**
 * Same as fSprayXml, but does not return the DFU Workunit ID.
 *
 * @see fSprayXml
 */

EXPORT SprayXml(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceRowTag, varstring sourceEncoding=&amp;apos;utf8&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE) :=
    lib_fileservices.FileServices.SprayXml(sourceIP, sourcePath, sourceMaxRecordSize, sourceRowTag, sourceEncoding, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit);



/**
 * Sprays an json file from a single machine and distributes it across the nodes of the destination group.
 *
 * @param sourceIP      The IP address of the file.
 * @param sourcePath    The path and name of the file.
 * @param sourceMaxRecordSize    The maximum size (in bytes) of the records in the file.
 * @param sourceRowPath The JSON path that is used to delimit records in the source file.
 * @param sourceEncoding The unicode encoding of the file.  (utf8,utf8n,utf16be,utf16le,utf32be,utf32le)
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Whether to replicate the new file. Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param failIfNoSourceFile If TRUE it causes a missing source file to trigger a failure.  Defaults to FALSE.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @param dfuServerQueue Name of target DFU Server queue. Default is &amp;apos;&amp;apos; (empty) for the first DFU queue in the environment.
 * @param noSplit      Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @param username      String containing a username to use for authenticated access to the ESP process; an empty string value
 *                      indicates that no user authentication is required; OPTIONAL, defaults to an empty string
 * @param userPw        String containing the password to be used with the user cited in the username argument; if username is
 *                      empty then this will be ignored; OPTIONAL, defaults to an empty string
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fSprayJson(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceRowPath=&amp;apos;/&amp;apos;, varstring sourceEncoding=&amp;apos;utf8&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.fSprayJson(sourceIP, sourcePath, sourceMaxRecordSize, sourceRowPath, sourceEncoding, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit, username, userPw);


/**
 * Same as fSprayJson, but does not return the DFU Workunit ID.
 *
 * @see fSprayJson
 */

EXPORT SprayJson(varstring sourceIP, varstring sourcePath, integer4 sourceMaxRecordSize=8192, varstring sourceRowPath=&amp;apos;/&amp;apos;, varstring sourceEncoding=&amp;apos;utf8&amp;apos;, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean compress=FALSE, boolean failIfNoSourceFile=FALSE, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=FALSE, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.SprayJson(sourceIP, sourcePath, sourceMaxRecordSize, sourceRowPath, sourceEncoding, destinationGroup, destinationLogicalName, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, compress, failIfNoSourceFile, expireDays, dfuServerQueue, noSplit, username, userPw);


/**
 * Copies a distributed file from multiple machines, and desprays it to a single file on a single machine.
 *
 * @param logicalName   The name of the file to despray.
 * @param destinationIP The IP of the target machine.
 * @param destinationPath The path of the file to create on the destination machine.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fDespray(varstring logicalName, varstring destinationIP, varstring destinationPath, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE) :=
    lib_fileservices.FileServices.fDespray(logicalName, destinationIP, destinationPath, timeOut, espServerIpPort, maxConnections, allowOverwrite);

/**
 * Same as fDespray, but does not return the DFU Workunit ID.
 *
 * @see fDespray
 */

EXPORT Despray(varstring logicalName, varstring destinationIP, varstring destinationPath, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE) :=
    lib_fileservices.FileServices.Despray(logicalName, destinationIP, destinationPath, timeOut, espServerIpPort, maxConnections, allowOverwrite);

/**
 * Copies a distributed file to another distributed file.
 *
 * @param sourceLogicalName The name of the file to despray.
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param sourceDali    The dali that contains the source file (blank implies same dali).  Defaults to same dali.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Should the copied file also be replicated on the destination?  Defaults to FALSE
 * @param asSuperfile   Should the file be copied as a superfile?  If TRUE and source is a superfile, then the
 *                      operation creates a superfile on the target, creating sub-files as needed and only overwriting
 *                      existing sub-files whose content has changed. If FALSE, a single file is created.  Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param forcePush     Should the copy process be executed on the source nodes (push) or on the destination nodes (pull)?
 *                      Default is to pull.
 * @param transferBufferSize Overrides the size (in bytes) of the internal buffer used to copy the file.  Default is 64k.
 * @param noSplit       Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fCopy(varstring sourceLogicalName, varstring destinationGroup, varstring destinationLogicalName, varstring sourceDali=&amp;apos;&amp;apos;, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean asSuperfile=FALSE, boolean compress=FALSE, boolean forcePush=FALSE, integer4 transferBufferSize=0, boolean preserveCompression=TRUE, boolean noSplit=FALSE, integer4 expireDays=-1) :=
    lib_fileservices.FileServices.fCopy(sourceLogicalName, destinationGroup, destinationLogicalName, sourceDali, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, asSuperfile, compress, forcePush, transferBufferSize, preserveCompression, noSplit, expireDays);

/**
 * Same as fCopy, but does not return the DFU Workunit ID.
 *
 * @see fCopy
 */

EXPORT Copy(varstring sourceLogicalName, varstring destinationGroup, varstring destinationLogicalName, varstring sourceDali=&amp;apos;&amp;apos;, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean asSuperfile=FALSE, boolean compress=FALSE, boolean forcePush=FALSE, integer4 transferBufferSize=0, boolean preserveCompression=TRUE, boolean noSplit=FALSE, integer4 expireDays=-1) :=
    lib_fileservices.FileServices.Copy(sourceLogicalName, destinationGroup, destinationLogicalName, sourceDali, timeOut, espServerIpPort, maxConnections, allowOverwrite, replicate, asSuperfile, compress, forcePush, transferBufferSize, preserveCompression, noSplit, expireDays);

/**
 * Ensures the specified file is replicated to its mirror copies.
 *
 * @param logicalName   The name of the file to replicate.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fReplicate(varstring logicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.fReplicate(logicalName, timeOut, espServerIpPort);

/**
 * Same as fReplicated, but does not return the DFU Workunit ID.
 *
 * @see fReplicate
 */

EXPORT Replicate(varstring logicalName, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.Replicate(logicalName, timeOut, espServerIpPort);

/**
 * Copies a distributed file to a distributed file on remote system.  Similar to fCopy, except the copy executes
 * remotely.  Since the DFU workunit executes on the remote DFU server, the user name authentication must be the same
 * on both systems, and the user must have rights to copy files on both systems.
 *
 * @param remoteEspFsURL The url of the remote ESP file copying service.
 * @param sourceLogicalName The name of the file to despray.
 * @param destinationGroup The name of the group to distribute the file across.
 * @param destinationLogicalName The logical name of the file to create.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param maxConnections The maximum number of target nodes to write to concurrently.  Defaults to 1.
 * @param allowOverwrite Is it valid to overwrite an existing file of the same name?  Defaults to FALSE
 * @param replicate     Should the copied file also be replicated on the destination?  Defaults to FALSE
 * @param asSuperfile   Should the file be copied as a superfile?  If TRUE and source is a superfile, then the
 *                      operation creates a superfile on the target, creating sub-files as needed and only overwriting
 *                      existing sub-files whose content has changed. If FALSE a single file is created.  Defaults to FALSE.
 * @param compress      Whether to compress the new file. Defaults to FALSE.
 * @param forcePush     Should the copy process should be executed on the source nodes (push) or on the destination nodes (pull)?
 *                      Default is to pull.
 * @param transferBufferSize Overrides the size (in bytes) of the internal buffer used to copy the file.  Default is 64k.
 * @param wrap          Should the fileparts be wrapped when copying to a smaller sized cluster?  The default is FALSE.
 * @param noSplit       Don&amp;apos;t split a file part to multiple target parts. Default is FALSE.
 * @param expireDays    Number of days to auto-remove file. Default is -1, not expire.
 * @param username      String containing a username to use for authenticated access to the ESP process; an empty string value
 *                      indicates that no user authentication is required. OPTIONAL, defaults to an empty string
 * @param userPW        String containing the password to be used with the user cited in the username argument; if username is
 *                      empty then this will be ignored; OPTIONAL, defaults to an empty string
 *
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fRemotePull(varstring remoteEspFsURL, varstring sourceLogicalName, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean asSuperfile=FALSE, boolean forcePush=FALSE, integer4 transferBufferSize=0, boolean wrap=FALSE, boolean compress=FALSE, boolean noSplit=FALSE, integer4 expireDays=-1, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.fRemotePull(remoteEspFsURL, sourceLogicalName, destinationGroup, destinationLogicalName, timeOut, maxConnections, allowOverwrite, replicate, asSuperfile, forcePush, transferBufferSize, wrap, compress, noSplit, expireDays, username, userPw);

/**
 * Same as fRemotePull, but does not return the DFU Workunit ID.
 *
 * @see fRemotePull
 */

EXPORT RemotePull(varstring remoteEspFsURL, varstring sourceLogicalName, varstring destinationGroup, varstring destinationLogicalName, integer4 timeOut=-1, integer4 maxConnections=-1, boolean allowOverwrite=FALSE, boolean replicate=FALSE, boolean asSuperfile=FALSE, boolean forcePush=FALSE, integer4 transferBufferSize=0, boolean wrap=FALSE, boolean compress=FALSE, boolean noSplit=FALSE, integer4 expireDays=-1, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.RemotePull(remoteEspFsURL, sourceLogicalName, destinationGroup, destinationLogicalName, timeOut, maxConnections, allowOverwrite, replicate, asSuperfile, forcePush, transferBufferSize, wrap, compress, noSplit, expireDays, username, userPw);

/*------------------------------------- File monitoring functions -------------------------------------------------------*/

/**
 * Creates a file monitor job in the DFU Server. If an appropriately named file arrives in this interval it will fire
 * the event with the name of the triggering object as the event subtype (see the EVENT function).
 *
 * @param eventToFire   The user-defined name of the event to fire when the filename appears. This value is used as
 *                      the first parameter to the EVENT function.
 * @param name          The name of the logical file to monitor.  This may contain wildcard characters ( * and ?)
 * @param shotCount     The number of times to generate the event before the monitoring job completes. A value
 *                      of -1 indicates the monitoring job continues until manually aborted. The default is 1.
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fMonitorLogicalFileName(varstring eventToFire, varstring name, integer4 shotCount=1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.fMonitorLogicalFileName(eventToFire, name, shotCount, espServerIpPort);

/**
 * Same as fMonitorLogicalFileName, but does not return the DFU Workunit ID.
 *
 * @see fMonitorLogicalFileName
 */

EXPORT MonitorLogicalFileName(varstring eventToFire, varstring name, integer4 shotCount=1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.MonitorLogicalFileName(eventToFire, name, shotCount, espServerIpPort);

/**
 * Creates a file monitor job in the DFU Server. If an appropriately named file arrives in this interval it will fire
 * the event with the name of the triggering object as the event subtype (see the EVENT function).
 *
 * @param eventToFire   The user-defined name of the event to fire when the filename appears. This value is used as
 *                      the first parameter to the EVENT function.
 * @param ip            The the IP address for the file to monitor. This may be omitted if the filename parameter
 *                      contains a complete URL.
 * @param filename      The full path of the file(s) to monitor.  This may contain wildcard characters ( * and ?)
 * @param subDirs       Whether to include files in sub-directories (when the filename contains wildcards).  Defaults to FALSE.
 * @param shotCount     The number of times to generate the event before the monitoring job completes. A value
 *                      of -1 indicates the monitoring job continues until manually aborted. The default is 1.
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @return              The DFU workunit id for the job.
 */

EXPORT varstring fMonitorFile(varstring eventToFire, varstring ip, varstring filename, boolean subDirs=FALSE, integer4 shotCount=1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.fMonitorFile(eventToFire, ip, filename, subDirs, shotCount, espServerIpPort);

/**
 * Same as fMonitorFile, but does not return the DFU Workunit ID.
 *
 * @see fMonitorFile
 */

EXPORT MonitorFile(varstring eventToFire, varstring ip, varstring filename, boolean subdirs=FALSE, integer4 shotCount=1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.MonitorFile(eventToFire, ip, filename, subdirs, shotCount, espServerIpPort);

/**
 * Waits for the specified DFU workunit to finish.
 *
 * @param wuid          The dfu wfid to wait for.
 * @param timeOut       The time in ms to wait for the operation to complete.  A value of 0 causes the call to return immediately.
 *                      Defaults to no timeout (-1).
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 * @return              A string containing the final status string of the DFU workunit.
 */

EXPORT varstring WaitDfuWorkunit(varstring wuid, integer4 timeOut=-1, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.WaitDfuWorkunit(wuid, timeOut, espServerIpPort);

/**
 * Aborts the specified DFU workunit.
 *
 * @param wuid          The dfu wfid to abort.
 * @param espServerIpPort The url of the ESP file copying service. Defaults to the value of ws_fs_server in the environment.
 */

EXPORT AbortDfuWorkunit(varstring wuid, varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) :=
    lib_fileservices.FileServices.AbortDfuWorkunit(wuid, espServerIpPort);

/*------------------------------------- Superfile functions -------------------------------------------------------*/

/**
 * Creates an empty superfile. This function is not included in a superfile transaction.
 *
 * @param superName     The logical name of the superfile.
 * @param sequentialParts Whether the sub-files must be sequentially ordered. Default to FALSE.
 * @param allowExist    Indicating whether to post an error if the superfile already exists. If TRUE, no error is
 *                      posted. Defaults to FALSE.
 */

EXPORT CreateSuperFile(varstring superName, boolean sequentialParts=FALSE, boolean allowExist=FALSE) :=
    lib_fileservices.FileServices.CreateSuperFile(superName, sequentialParts, allowExist);

/**
 * Checks if the specified filename is present in the Distributed File Utility (DFU) and is a SuperFile.
 *
 * @param superName     The logical name of the superfile.
 * @return              Whether the file exists.
 *
 * @see FileExists
 */

EXPORT boolean SuperFileExists(varstring superName) :=
    lib_fileservices.FileServices.SuperFileExists(superName);

/**
 * Deletes the superfile.
 *
 * @param superName     The logical name of the superfile.
 *
 * @see FileExists
 */

EXPORT DeleteSuperFile(varstring superName, boolean deletesub=FALSE) :=
    lib_fileservices.FileServices.DeleteSuperFile(superName, deletesub);

/**
 * Returns the number of sub-files contained within a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @return              The number of sub-files within the superfile.
 */

EXPORT unsigned4 GetSuperFileSubCount(varstring superName) :=
    lib_fileservices.FileServices.GetSuperFileSubCount(superName);

/**
 * Returns the name of the Nth sub-file within a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param fileNum       The 1-based position of the sub-file to return the name of.
 * @param absPath       Whether to prepend &amp;apos;~&amp;apos; to the name of the resulting logical file name.
 * @return              The logical name of the selected sub-file.
 */

EXPORT varstring GetSuperFileSubName(varstring superName, unsigned4 fileNum, boolean absPath=FALSE) :=
    lib_fileservices.FileServices.GetSuperFileSubName(superName, fileNum, absPath);

/**
 * Returns the position of a file within a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param subName       The logical name of the sub-file.
 * @return              The 1-based position of the sub-file within the superfile.
 */

EXPORT unsigned4 FindSuperFileSubName(varstring superName, varstring subName) :=
    lib_fileservices.FileServices.FindSuperFileSubName(superName, subName);

/**
 * Starts a superfile transaction.  All superfile operations within the transaction will either be
 * executed atomically or rolled back when the transaction is finished.
 */

EXPORT StartSuperFileTransaction() :=
    lib_fileservices.FileServices.StartSuperFileTransaction();

/**
 * Adds a file to a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param subName       The name of the logical file to add.
 * @param atPos         The position to add the sub-file, or 0 to append.  Defaults to 0.
 * @param addContents   Controls whether adding a superfile adds the superfile, or its contents.  Defaults to FALSE (do not expand).
 * @param strict        Check addContents only if subName is a superfile, and ensure superfiles exist.
 */

EXPORT AddSuperFile(varstring superName, varstring subName, unsigned4 atPos=0, boolean addContents=FALSE, boolean strict=FALSE) :=
    lib_fileservices.FileServices.AddSuperFile(superName, subName, atPos, addContents, strict);

/**
 * Removes a sub-file from a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param subName       The name of the sub-file to remove.
 * @param del           Indicates whether the sub-file should also be removed from the disk.  Defaults to FALSE.
 * @param removeContents Controls whether the contents of a sub-file which is a superfile should be recursively removed.  Defaults to FALSE.
 */

EXPORT RemoveSuperFile(varstring superName, varstring subName, boolean del=FALSE, boolean removeContents=FALSE) :=
    lib_fileservices.FileServices.RemoveSuperFile(superName, subName, del, removeContents);

/**
 * Removes all sub-files from a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param del           Indicates whether the sub-files should also be removed from the disk.  Defaults to FALSE.
 */

EXPORT ClearSuperFile(varstring superName, boolean del=FALSE) :=
    lib_fileservices.FileServices.ClearSuperFile(superName, del);

/**
 * Removes all soley-owned sub-files from a superfile.  If a sub-file is also contained within another superfile
 * then it is retained.
 *
 * @param superName     The logical name of the superfile.
 */

EXPORT RemoveOwnedSubFiles(varstring superName, boolean del=FALSE) :=
    lib_fileservices.FileServices.RemoveOwnedSubFiles(superName, del);

/**
 * Legacy version of RemoveOwnedSubFiles which was incorrectly named in a previous version.
 *
 * @see RemoveOwnedSubFIles
 */

EXPORT DeleteOwnedSubFiles(varstring superName) :=  // Obsolete, use RemoteOwnedSubFiles
    lib_fileservices.FileServices.DeleteOwnedSubFiles(superName);

/**
 * Swap the contents of two superfiles.
 *
 * @param superName1    The logical name of the first superfile.
 * @param superName2    The logical name of the second superfile.
 */

EXPORT SwapSuperFile(varstring superName1, varstring superName2) :=
    lib_fileservices.FileServices.SwapSuperFile(superName1, superName2);

/**
 * Removes a sub-file from a superfile and replaces it with another.
 *
 * @param superName     The logical name of the superfile.
 * @param oldSubFile    The logical name of the sub-file to remove.
 * @param newSubFile    The logical name of the sub-file to replace within the superfile.
 */

EXPORT ReplaceSuperFile(varstring superName, varstring oldSubFile, varstring newSubFile) :=
    lib_fileservices.FileServices.ReplaceSuperFile(superName, oldSubFile, newSubFile);

/**
 * Finishes a superfile transaction.  This executes all the operations since the matching StartSuperFileTransaction().
 * If there are any errors, then all of the operations are rolled back.
 */

EXPORT FinishSuperFileTransaction(boolean rollback=FALSE) :=
    lib_fileservices.FileServices.FinishSuperFileTransaction(rollback);

/**
 * Returns the list of sub-files contained within a superfile.
 *
 * @param superName     The logical name of the superfile.
 * @param recurse       Should the contents of child-superfiles be expanded.  Default is FALSE.
 * @return              A dataset containing the names of the sub-files.
 */

EXPORT dataset(FsLogicalFileNameRecord) SuperFileContents(varstring superName, boolean recurse=FALSE) :=
    lib_fileservices.FileServices.SuperFileContents(superName, recurse);

/**
 * Returns the list of superfiles that a logical file is contained within.
 *
 * @param name          The name of the logical file.
 * @return              A dataset containing the names of the superfiles.
 */

EXPORT dataset(FsLogicalFileNameRecord) LogicalFileSuperOwners(varstring name) :=
    lib_fileservices.FileServices.LogicalFileSuperOwners(name);

/**
 * Returns the list of all the superfiles in the system and their component sub-files.
 *
 * @return              A dataset containing pairs of superName,subName for each component file.
 */

EXPORT dataset(FsLogicalSuperSubRecord) LogicalFileSuperSubList() :=
    lib_fileservices.FileServices.LogicalFileSuperSubList();

/**
 * Moves the sub-files from the first entry in the list of superfiles to the next in the list, repeating the process
 * through the list of superfiles.
 *
 * @param superNames    A set of the names of the superfiles to act on. Any that do not exist will be created.
 *                      The contents of each superfile will be moved to the next in the list.
 * @param addHead       A string containing a comma-delimited list of logical file names to add to the first superfile
 *                      after the promotion process is complete.  Defaults to &amp;apos;&amp;apos;.
 * @param delTail       Indicates whether to physically delete the contents moved out of the last superfile. The default is FALSE.
 * @param createOnlyOne Specifies whether to only create a single superfile (truncate the list at the first
 *                      non-existent superfile). The default is FALSE.
 * @param reverse       Reverse the order of processing the superfiles list, effectively &amp;apos;demoting&amp;apos; instead of &amp;apos;promoting&amp;apos; the sub-files. The default is FALSE.
 *
 * @return              A string containing a comma separated list of the previous sub-file contents of the emptied superfile.
 */
EXPORT varstring fPromoteSuperFileList(set of varstring superNames, varstring addHead=&amp;apos;&amp;apos;, boolean delTail=FALSE, boolean createOnlyOne=FALSE, boolean reverse=FALSE) :=
    lib_fileservices.FileServices.fPromoteSuperFileList(superNames, addHead, delTail, createOnlyOne, reverse);


/**
 * Same as fPromoteSuperFileList, but does not return the DFU Workunit ID.
 *
 * @see fPromoteSuperFileList
 */
EXPORT PromoteSuperFileList(set of varstring superNames, varstring addHead=&amp;apos;&amp;apos;, boolean delTail=FALSE, boolean createOnlyOne=FALSE, boolean reverse=FALSE) :=
    lib_fileservices.FileServices.PromoteSuperFileList(superNames, addHead, delTail, createOnlyOne, reverse);

/**
 * Returns the full URL to an ESP server process
 *
 * @param username      String containing a username to use for authenticated
 *                      access to the ESP process; an empty string value
 *                      indicates that no user authentication is required;
 *                      OPTIONAL, defaults to an empty string
 * @param userPW        String containing the password to be used with the
 *                      user cited in the username argument; if username is
 *                      empty then this will be ignored; OPTIONAL, defaults
 *                      to an empty string
 *
 * @return              A string containing the full URL (including HTTP scheme
 *                      and port) to an ESP server process; if more than one
 *                      process is defined then the first found process will
 *                      be returned; will return an empty string if an ESP
 *                      server process cannot be found
 */
EXPORT varstring GetEspURL(const varstring username = &amp;apos;&amp;apos;, const varstring userPW = &amp;apos;&amp;apos;) :=
    lib_fileservices.FileServices.GetEspURL(username, userPW);


 /**
 * Returns the path to the default Drop Zone
 *
 *
 * @return              A string containing the path to the default Drop Zone.
 *                      If more than one Drop Zone
 *                      process is defined then the first found will
 *                      be returned; will return an empty string if a Drop Zone
 *                      cannot be found
 */
EXPORT varstring GetDefaultDropZone() :=
    lib_fileservices.FileServices.GetDefaultDropZone();

 /**
 * Returns a dataset with full paths to all Drop Zones
 *
 *
 * @return              A dataset containing all defined Drop Zone paths.
 *                      Will return an empty dataset if a Drop Zone
 *                      cannot be found
 */

EXPORT dataset(FsDropZoneRecord) GetDropZones() :=
    lib_fileservices.FileServices.GetDropZones();

END;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;str&quot;
             name=&quot;str&quot;
             sourcePath=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\share\ecllibrary\std\Str.ecl&quot;
             ts=&quot;1616674834000000&quot;&gt;
   /*##############################################################################
## HPCC SYSTEMS software Copyright (C) 2012 HPCC Systems.  All rights reserved.
############################################################################## */


externals := 
    SERVICE : fold
STRING EncodeBase64(const data src) :   eclrtl,pure,include,library=&amp;apos;eclrtl&amp;apos;,entrypoint=&amp;apos;rtlBase64Encode&amp;apos;;
DATA DecodeBase64(const string src) :   eclrtl,pure,include,library=&amp;apos;eclrtl&amp;apos;,entrypoint=&amp;apos;rtlBase64Decode&amp;apos;;
    END;

EXPORT Str := MODULE


/*
  Since this is primarily a wrapper for a plugin, all the definitions for this standard library
  module are included in a single file.  Generally I would expect them in individual files.
  */

IMPORT lib_stringlib;

/**
 * Compares the two strings case insensitively.  Returns a negative integer, zero, or a positive integer according to
 * whether the first string is less than, equal to, or greater than the second.
 * 
 * @param src1          The first string to be compared.
 * @param src2          The second string to be compared.
 * @see                 Str.EqualIgnoreCase
 */
 
EXPORT INTEGER4 CompareIgnoreCase(STRING src1, STRING src2) :=
  lib_stringlib.StringLib.StringCompareIgnoreCase(src1, src2);

/**
 * Tests whether the two strings are identical ignoring differences in case.
 * 
 * @param src1          The first string to be compared.
 * @param src2          The second string to be compared.
 * @see                 Str.CompareIgnoreCase
 */
 
EXPORT BOOLEAN EqualIgnoreCase(STRING src1, STRING src2) := CompareIgnoreCase(src1, src2) = 0;

/**
 * Returns the character position of the nth match of the search string with the first string.
 * If no match is found the attribute returns 0.
 * If an instance is omitted the position of the first instance is returned.
 * 
 * @param src           The string that is searched
 * @param sought        The string being sought.
 * @param instance      Which match instance are we interested in?
 */
 
EXPORT UNSIGNED4 Find(STRING src, STRING sought, UNSIGNED4 instance = 1) :=
  lib_stringlib.StringLib.StringFind(src, sought, instance);

/**
 * Returns the number of occurences of the second string within the first string.
 * 
 * @param src           The string that is searched
 * @param sought        The string being sought.
 */
 
EXPORT UNSIGNED4 FindCount(STRING src, STRING sought) := lib_stringlib.StringLib.StringFindCount(src, sought);

/**
 * Tests if the search string matches the pattern.
 * The pattern can contain wildcards &amp;apos;?&amp;apos; (single character) and &amp;apos;*&amp;apos; (multiple character).
 * 
 * @param src           The string that is being tested.
 * @param pattern       The pattern to match against.
 * @param ignore_case   Whether to ignore differences in case between characters
 */
 
EXPORT BOOLEAN WildMatch(STRING src, STRING _pattern, BOOLEAN ignore_case) :=
  lib_stringlib.StringLib.StringWildExactMatch(src, _pattern, ignore_case);

/**
 * Tests if the search string contains each of the characters in the pattern.
 * If the pattern contains duplicate characters those characters will match once for each occurence in the pattern.
 * 
 * @param src           The string that is being tested.
 * @param pattern       The pattern to match against.
 * @param ignore_case   Whether to ignore differences in case between characters
 */
 
EXPORT BOOLEAN Contains(STRING src, STRING _pattern, BOOLEAN ignore_case) :=
  lib_stringlib.StringLib.StringContains(src, _pattern, ignore_case);

/**
 * Returns the first string with all characters within the second string removed.
 * 
 * @param src           The string that is being tested.
 * @param filter        The string containing the set of characters to be excluded.
 * @see                 Str.Filter
 */
 
EXPORT STRING FilterOut(STRING src, STRING filter) := lib_stringlib.StringLib.StringFilterOut(src, filter);

/**
 * Returns the first string with all characters not within the second string removed.
 * 
 * @param src           The string that is being tested.
 * @param filter        The string containing the set of characters to be included.
 * @see                 Str.FilterOut
 */
 
EXPORT STRING Filter(STRING src, STRING filter) := lib_stringlib.StringLib.StringFilter(src, filter);

/**
 * Returns the source string with the replacement character substituted for all characters included in the
 * filter string.
 * MORE: Should this be a general string substitution?
 * 
 * @param src           The string that is being tested.
 * @param filter        The string containing the set of characters to be included.
 * @param replace_char  The character to be substituted into the result.
 * @see                 Std.Str.Translate, Std.Str.SubstituteExcluded
 */

EXPORT STRING SubstituteIncluded(STRING src, STRING filter, STRING1 replace_char) :=
  lib_stringlib.StringLib.StringSubstituteOut(src, filter, replace_char);

/**
 * Returns the source string with the replacement character substituted for all characters not included in the
 * filter string.
 * MORE: Should this be a general string substitution?
 * 
 * @param src           The string that is being tested.
 * @param filter        The string containing the set of characters to be included.
 * @param replace_char  The character to be substituted into the result.
 * @see                 Std.Str.SubstituteIncluded
 */

EXPORT STRING SubstituteExcluded(STRING src, STRING filter, STRING1 replace_char) :=
  lib_stringlib.StringLib.StringSubstitute(src, filter, replace_char);

/**
 * Returns the source string with the all characters that match characters in the search string replaced
 * with the character at the corresponding position in the replacement string.
 *
 * @param src           The string that is being tested.
 * @param search        The string containing the set of characters to be included.
 * @param replacement   The string containing the characters to act as replacements.
 * @see                 Std.Str.SubstituteIncluded
 */

//MORE: Would be more efficient to create a mapping object, and pass that to the replacement function.
EXPORT STRING Translate(STRING src, STRING search, STRING replacement) :=
  lib_stringlib.StringLib.StringTranslate(src, search, replacement);

/**
 * Returns the argument string with all upper case characters converted to lower case.
 * 
 * @param src           The string that is being converted.
 */

EXPORT STRING ToLowerCase(STRING src) := lib_stringlib.StringLib.StringToLowerCase(src);

/**
 * Return the argument string with all lower case characters converted to upper case.
 * 
 * @param src           The string that is being converted.
 */

EXPORT STRING ToUpperCase(STRING src) := lib_stringlib.StringLib.StringToUpperCase(src);

/**
 * Returns the argument string with the first letter of each word in upper case and all other
 * letters left as-is.
 * A contiguous sequence of alphanumeric characters is treated as a word.
 * 
 * @param src           The string that is being converted.
 */

EXPORT STRING ToCapitalCase(STRING src) := lib_stringlib.StringLib.StringToCapitalCase(src);

/**
 * Returns the argument string with the first letter of each word in upper case and all other
 * letters lower case.
 * A contiguous sequence of alphanumeric characters is treated as a word.
 *
 * @param src           The string that is being converted.
 */

EXPORT STRING ToTitleCase(STRING src) := lib_stringlib.StringLib.StringToTitleCase(src);

/**
 * Returns the argument string with all characters in reverse order.
 * Note the argument is not TRIMMED before it is reversed.
 * 
 * @param src           The string that is being reversed.
 */

EXPORT STRING Reverse(STRING src) := lib_stringlib.StringLib.StringReverse(src);

/**
 * Returns the source string with the replacement string substituted for all instances of the search string.
 * 
 * @param src           The string that is being transformed.
 * @param sought        The string to be replaced.
 * @param replacement   The string to be substituted into the result.
 */

EXPORT STRING FindReplace(STRING src, STRING sought, STRING replacement) :=
  lib_stringlib.StringLib.StringFindReplace(src, sought, replacement);

/**
 * Returns the nth element from a comma separated string.
 * 
 * @param src           The string containing the comma separated list.
 * @param instance      Which item to select from the list.
 */

EXPORT STRING Extract(STRING src, UNSIGNED4 instance) := lib_stringlib.StringLib.StringExtract(src, instance);

/**
 * Returns the source string with all instances of multiple adjacent space characters (2 or more spaces together)
 * reduced to a single space character.  Leading and trailing spaces are removed, and tab characters are converted
 * to spaces.
 * 
 * @param src           The string to be cleaned.
 */

EXPORT STRING CleanSpaces(STRING src) := lib_stringlib.StringLib.StringCleanSpaces(src);

/**
 * Returns true if the prefix string matches the leading characters in the source string.  Trailing spaces are 
 * stripped from the prefix before matching.
 * // x.myString.StartsWith(&amp;apos;x&amp;apos;) as an alternative syntax would be even better
 * 
 * @param src           The string being searched in.
 * @param prefix        The prefix to search for.
 */

EXPORT BOOLEAN StartsWith(STRING src, STRING prefix) := src[1..LENGTH(TRIM(prefix))]=prefix;

/**
 * Returns true if the suffix string matches the trailing characters in the source string.  Trailing spaces are 
 * stripped from both strings before matching.
 * 
 * @param src           The string being searched in.
 * @param suffix        The prefix to search for.
 */
EXPORT BOOLEAN EndsWith(STRING src, STRING suffix) := src[LENGTH(TRIM(src))-LENGTH(TRIM(suffix))+1..]=suffix;


/**
 * Removes the suffix from the search string, if present, and returns the result.  Trailing spaces are 
 * stripped from both strings before matching.
 * 
 * @param src           The string being searched in.
 * @param suffix        The prefix to search for.
 */
EXPORT STRING RemoveSuffix(STRING src, STRING suffix) :=
            IF(EndsWith(src, suffix), src[1..length(trim(src))-length(trim(suffix))], src);


/**
 * Returns a string containing a list of elements from a comma separated string.
 *
 * @param src           The string containing the comma separated list.
 * @param mask          A bitmask of which elements should be included.  Bit 0 is item1, bit1 item 2 etc.
 */

EXPORT STRING ExtractMultiple(STRING src, UNSIGNED8 mask) := lib_stringlib.StringLib.StringExtractMultiple(src, mask);

/**
 * Returns the number of words that the string contains.  Words are separated by one or more separator strings. No 
 * spaces are stripped from either string before matching.
 * 
 * @param src           The string being searched in.
 * @param separator     The string used to separate words
 * @param allow_blank   Indicates if empty/blank string items are included in the results.
 */

EXPORT UNSIGNED4 CountWords(STRING src, STRING separator, BOOLEAN allow_blank = FALSE) := lib_stringlib.StringLib.CountWords(src, separator, allow_blank);

/**
 * Returns the list of words extracted from the string.  Words are separated by one or more separator strings. No 
 * spaces are stripped from either string before matching.
 * 
 * @param src           The string being searched in.
 * @param separator     The string used to separate words
 * @param allow_blank   Indicates if empty/blank string items are included in the results.
 */
 
EXPORT SET OF STRING SplitWords(STRING src, STRING separator, BOOLEAN allow_blank = FALSE) := lib_stringlib.StringLib.SplitWords(src, separator, allow_blank);


/**
 * Returns the list of words extracted from the string.  Words are separated by one or more separator strings. No
 * spaces are stripped from either string before matching.
 *
 * @param words         The set of strings to be combined.
 * @param separator     The string used to separate words.
 */

EXPORT STRING CombineWords(SET OF STRING words, STRING separator) := lib_stringlib.StringLib.CombineWords(words, separator);


/**
 * Returns the minimum edit distance between the two strings.  An insert change or delete counts as a single edit.
 * The two strings are trimmed before comparing.
 * 
 * @param _left         The first string to be compared.
 * @param _right        The second string to be compared.
 * @param radius        The maximum edit distance that is acceptable, or 0 for no limit.  Defaults to 0.
 * @return              The minimum edit distance between the two strings.  Edit distances above radius will
                        return an arbitrary value larger than radius.
 */

EXPORT UNSIGNED4 EditDistance(STRING _left, STRING _right, UNSIGNED4 radius = 0) :=
    lib_stringlib.StringLib.EditDistanceV3(_left, _right, radius);

/**
 * Returns true if the minimum edit distance between the two strings is with a specific range.
 * The two strings are trimmed before comparing.
 * 
 * @param _left         The first string to be compared.
 * @param _right        The second string to be compared.
 * @param radius        The maximum edit distance that is acceptable.
 * @return              Whether or not the two strings are within the given specified edit distance.
 */

EXPORT BOOLEAN EditDistanceWithinRadius(STRING _left, STRING _right, UNSIGNED4 radius) :=
    lib_stringlib.StringLib.EditDistanceWithinRadiusV2(_left, _right, radius);


/**
 * Returns the number of words in the string.  Words are separated by one or more spaces.
 * 
 * @param text          The string to be broken into words.
 * @return              The number of words in the string.
 */

EXPORT UNSIGNED4 WordCount(STRING text) :=
    lib_stringlib.StringLib.StringWordCount(text);

/**
 * Returns the n-th word from the string.  Words are separated by one or more spaces.
 * 
 * @param text          The string to be broken into words.
 * @param n             Which word should be returned from the function.
 * @return              The number of words in the string.
 */

EXPORT STRING GetNthWord(STRING text, UNSIGNED4 n) :=
    lib_stringlib.StringLib.StringGetNthWord(text, n);

/**
 * Returns everything except the first word from the string.  Words are separated by one or more whitespace characters.
 * Whitespace before and after the first word is also removed.
 *
 * @param text          The string to be broken into words.
 * @return              The string excluding the first word.
 */

EXPORT ExcludeFirstWord(STRING text) := lib_stringlib.Stringlib.StringExcludeNthWord(text, 1);

/**
 * Returns everything except the last word from the string.  Words are separated by one or more whitespace characters.
 * Whitespace after a word is removed with the word and leading whitespace is removed with the first word.
 *
 * @param text          The string to be broken into words.
 * @return              The string excluding the last word.
 */

EXPORT ExcludeLastWord(STRING text) := lib_stringlib.Stringlib.StringExcludeLastWord(text);

/**
 * Returns everything except the nth word from the string.  Words are separated by one or more whitespace characters.
 * Whitespace after a word is removed with the word and leading whitespace is removed with the first word.
 *
 * @param text          The string to be broken into words.
 * @param n             Which word should be returned from the function.
 * @return              The string excluding the nth word.
 */

EXPORT ExcludeNthWord(STRING text, UNSIGNED2 n) := lib_stringlib.Stringlib.StringExcludeNthWord(text, n);

/**
 * Tests if the search string contains the supplied word as a whole word.
 *
 * @param src           The string that is being tested.
 * @param word          The word to be searched for.
 * @param ignore_case   Whether to ignore differences in case between characters.
 */

EXPORT BOOLEAN FindWord(STRING src, STRING word, BOOLEAN ignore_case=FALSE) := FUNCTION
   return IF (ignore_case,
              REGEXFIND(&amp;apos;\\b&amp;apos;+word+&amp;apos;\\b&amp;apos;, src, NOCASE),
              REGEXFIND(&amp;apos;\\b&amp;apos;+word+&amp;apos;\\b&amp;apos;, src));
END;

/*
 * Returns a string containing text repeated n times.
 *
 * @param text          The string to be repeated.
 * @param n             Number of repetitions.
 * @return              A string containing n concatenations of the string text.
 */

EXPORT STRING Repeat(STRING text, UNSIGNED4 n) := lib_stringlib.Stringlib.StringRepeat(text, n);

/*
 * Converts the data value to a sequence of hex pairs.
 *
 * @param value         The data value that should be expanded as a sequence of hex pairs.
 * @return              A string containing a sequence of hex pairs.
 */

EXPORT STRING ToHexPairs(DATA value) := lib_stringlib.StringLib.Data2String(value);

/*
 * Converts a string containing sequences of hex pairs to a data value.
 *
 * Embedded spaces are ignored, out of range characters are treated as &amp;apos;0&amp;apos;, a trailing nibble
 * at the end of the string is ignored.
 *
 *
 * @param hex_pairs     The string containing the hex pairs to process.
 * @return              A data value with each byte created from a pair of hex digits.
 */

EXPORT DATA FromHexPairs(STRING hex_pairs) := lib_stringlib.StringLib.String2Data(hex_pairs);

/*
 * Encode binary data to base64 string.
 *
 * Every 3 data bytes are encoded to 4 base64 characters. If the length of the input is not divisible 
 * by 3, up to 2 &amp;apos;=&amp;apos; characters are appended to the output. 
 *
 *
 * @param value         The binary data array to process.
 * @return              Base 64 encoded string.
 */

EXPORT STRING EncodeBase64(DATA value) := externals.EncodeBase64(value);

/*
 * Decode base64 encoded string to binary data.
 *
 * If the input is not valid base64 encoding (invalid characters, or ends mid-quartet), an empty
 * result is returned. Whitespace in the input is skipped.
 *
 *
 * @param value        The base 64 encoded string.
 * @return             Decoded binary data if the input is valid else zero length data.
 */

EXPORT DATA DecodeBase64(STRING value) := externals.DecodeBase64(value);

END;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;date&quot;
             name=&quot;date&quot;
             sourcePath=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\share\ecllibrary\std\Date.ecl&quot;
             ts=&quot;1616674830000000&quot;&gt;
   /*##############################################################################
## HPCC SYSTEMS software Copyright (C) 2012 HPCC Systems.  All rights reserved.
############################################################################## */

/* The functions defined in this module are provisional, and subject to change */

IMPORT lib_stringlib.StringLib;
IMPORT lib_timelib.TimeLib;

EXPORT Date := MODULE


// A record structure with the different date elements separated out.
EXPORT Date_rec := RECORD
    INTEGER2    year;
    UNSIGNED1   month;
    UNSIGNED1   day;
END;


// An unsigned number holding a date in the decimal form YYYYMMDD.
// This type doesn&amp;apos;t support dates before 1AD.
EXPORT Date_t := UNSIGNED4;


// A number of elapsed days.  Origin depends on the function called.
EXPORT Days_t := INTEGER4;


// A record structure with the different time elements separated out.
EXPORT Time_rec := RECORD
    UNSIGNED1   hour;
    UNSIGNED1   minute;
    UNSIGNED1   second;
END;


// An unsigned number holding a time of day in the decimal form HHMMDD.
EXPORT Time_t := UNSIGNED3;


// A signed number holding a number of seconds.  Can be used to represent either
// a duration or the number of seconds since epoch (Jan 1, 1970).
EXPORT Seconds_t := INTEGER8;


// A record structure with the different date and time elements separated out.
EXPORT DateTime_rec := RECORD
    Date_rec;
    Time_Rec;
END;


// A signed number holding a number of microseconds.  Can be used to represent
// either a duration or the number of microseconds since epoch (Jan 1, 1970).
EXPORT Timestamp_t := INTEGER8;


/**
 * Extracts the year from a date type.
 *
 * @param date          The date.
 * @return              An integer representing the year.
 */

EXPORT INTEGER2 Year(Date_t date) := date DIV 10000;


/**
 * Extracts the month from a date type.
 *
 * @param date          The date.
 * @return              An integer representing the year.
 */

EXPORT UNSIGNED1 Month(Date_t date) := (date DIV 100) % 100;


/**
 * Extracts the day of the month from a date type.
 *
 * @param date          The date.
 * @return              An integer representing the year.
 */

EXPORT UNSIGNED1 Day(Date_t date) := date % 100;


/**
 * Extracts the hour from a time type.
 *
 * @param time          The time.
 * @return              An integer representing the hour.
 */

EXPORT UNSIGNED1 Hour(Time_t time) := time DIV 10000;


/**
 * Extracts the minutes from a time type.
 *
 * @param time          The time.
 * @return              An integer representing the minutes.
 */

EXPORT UNSIGNED1 Minute(Time_t time) := (time DIV 100) % 100;


/**
 * Extracts the seconds from a time type.
 *
 * @param time          The time.
 * @return              An integer representing the seconds.
 */

EXPORT UNSIGNED1 Second(Time_t time) := time % 100;


/**
 * Combines year, month day to create a date type.
 *
 * @param year          The year (0-9999).
 * @param month         The month (1-12).
 * @param day           The day (1..daysInMonth).
 * @return              A date created by combining the fields.
 */

EXPORT Date_t DateFromParts(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) := (year * 100 + month) * 100 + day;


/**
 * Combines hour, minute second to create a time type.
 *
 * @param hour          The hour (0-23).
 * @param minute        The minute (0-59).
 * @param second        The second (0-59).
 * @return              A time created by combining the fields.
 */

EXPORT Time_t TimeFromParts(UNSIGNED1 hour, UNSIGNED1 minute, UNSIGNED1 second) := (hour * 100 + minute) * 100 + second;


/**
 * Combines date and time components to create a seconds type.  The date must
 * be represented within the Gregorian calendar after the year 1600.
 *
 * @param year                  The year (1601-30827).
 * @param month                 The month (1-12).
 * @param day                   The day (1..daysInMonth).
 * @param hour                  The hour (0-23).
 * @param minute                The minute (0-59).
 * @param second                The second (0-59).
 * @param is_local_time         TRUE if the datetime components are expressed
 *                              in local time rather than UTC, FALSE if the
 *                              components are expressed in UTC.  Optional,
 *                              defaults to FALSE.
 * @return                      A Seconds_t value created by combining the fields.
 */

EXPORT Seconds_t SecondsFromParts(INTEGER2 year,
                                  UNSIGNED1 month,
                                  UNSIGNED1 day,
                                  UNSIGNED1 hour,
                                  UNSIGNED1 minute,
                                  UNSIGNED1 second,
                                  BOOLEAN is_local_time = FALSE) :=
    TimeLib.SecondsFromParts(year, month, day, hour, minute, second, is_local_time);


/**
 * Converts the number of seconds since epoch to a structure containing
 * date and time parts.  The result must be representable within the
 * Gregorian calendar after the year 1600.
 *
 * @param seconds               The number of seconds since epoch.
 * @param is_local_time         TRUE if seconds is expressed in local time
 *                              rather than UTC, FALSE if seconds is expressed
 *                              in UTC.  Optional, defaults to FALSE.
 * @return                      Module with exported attributes for year, month,
 *                              day, hour, minute, second, day_of_week, date
 *                              and time.
 */

EXPORT SecondsToParts(Seconds_t seconds, BOOLEAN is_local_time = FALSE) := FUNCTION
    parts := ROW(TimeLib.SecondsToParts(seconds, is_local_time));

    result := MODULE
        EXPORT INTEGER2 year := parts.year + 1900;
        EXPORT UNSIGNED1 month := parts.mon + 1;
        EXPORT UNSIGNED1 day := parts.mday;
        EXPORT UNSIGNED1 hour := parts.hour;
        EXPORT UNSIGNED1 minute := parts.min;
        EXPORT UNSIGNED1 second := parts.sec;
        EXPORT UNSIGNED1 day_of_week := parts.wday + 1;
        EXPORT Date_t date := DateFromParts(year,month,day);
        EXPORT Time_t time := TimeFromParts(hour,minute,second);
    END;

    RETURN result;
END;


/**
 * Converts the number of microseconds since epoch to the number of seconds
 * since epoch.
 *
 * @param timestamp             The number of microseconds since epoch.
 * @return                      The number of seconds since epoch.
 */

EXPORT Seconds_t TimestampToSeconds(Timestamp_t timestamp) := timestamp DIV 1000000;

/**
 * Tests whether the year is a leap year in the Gregorian calendar.
 *
 * @param year          The year (0-9999).
 * @return              True if the year is a leap year.
 */

EXPORT BOOLEAN IsLeapYear(INTEGER2 year) := (year % 4 = 0) AND ((year % 100 != 0) OR (year % 400 = 0));


/**
 * Tests whether a date is a leap year in the Gregorian calendar.
 *
 * @param date          The date.
 * @return              True if the year is a leap year.
 */

EXPORT BOOLEAN IsDateLeapYear(Date_t date) := IsLeapYear(Year(date));

SHARED YearDelta := +4800;  // Offset the years by 4800 so dates up to -4713 work

SHARED GregorianDateOrigin := -1753469;      // 1 Jan 1AD = 1


/**
 * Combines year, month, day in the Gregorian calendar to create the number
 * days since 31st December 1BC.
 *
 * @param year          The year (-4713..9999).
 * @param month         The month (1-12).  A missing value (0) is treated as 1.
 * @param day           The day (1..daysInMonth).  A missing value (0) is treated as 1.
 * @return              The number of elapsed days (1 Jan 1AD = 1)
 */

EXPORT Days_t FromGregorianYMD(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) := FUNCTION
    //See Frequently Asked Questions about Calendars by Claus Toendering
    safeDay := MAX(1, day); // treat 0 as 1
    safeMonth := MAX(1, month); // treat 0 as 1
    a := (14 - safeMonth) DIV 12;
    y := year + YearDelta - a;
    m := safeMonth + 12*a - 3;
    jd := safeDay + (153 * m + 2) DIV 5 + 365 * y + y DIV 4 - y DIV 100 + y DIV 400;

    RETURN jd + (GregorianDateOrigin - 1);
END;


/**
 * Converts the number days since 31st December 1BC to a date in the Gregorian calendar.
 *
 * @param days          The number of elapsed days (1 Jan 1AD = 1)
 * @return              Module containing Year, Month, Day in the Gregorian calendar
 */

EXPORT ToGregorianYMD(Days_t days) := FUNCTION
    // See Fliegel and van Flandern (1968) and other quoted sources
    // (e.g., http://www.ortelius.de/kalender/calc_en.php)
    // Process as 4, 100 and 400 year cycles.
    daysIn4Years := 3*365+366;
    daysIn100Years := 25*daysIn4Years-1;
    daysIn400Years := 4*daysIn100Years+1;

    // Calculate days in each of the cycles.
    adjustedDays := days - GregorianDateOrigin;
    num400Years := adjustedDays div daysIn400Years;
    rem400Years := adjustedDays % daysIn400Years;

    num100Years := ((rem400Years div daysIn100Years + 1) * 3) DIV 4;
    rem100Years := rem400Years - num100Years * daysIn100Years;

    num4Years := rem100Years div daysIn4Years;
    rem4Years := rem100Years % daysIn4Years;

    years := ((rem4Years div 365 + 1) * 3) DIV 4;
    numdays := rem4Years - years * 365;

    //Now calculate the actual year, month day
    y := num400Years * 400 + num100Years * 100 + num4Years * 4 + years;
    m := (numdays * 5 + 308) div 153 - 2;
    d := numdays - (m + 4) * 153 div 5 + 122;
    result := MODULE
        EXPORT year := (y + (m + 2) div 12) - YearDelta;
        EXPORT month := (m + 2) % 12 + 1;
        EXPORT day := d + 1;
    END;

    RETURN result;
END;


/**
 * Converts a date in the Gregorian calendar to the number days since 31st December 1BC.
 *
 * @param date          The date (using the Gregorian calendar)
 * @return              The number of elapsed days (1 Jan 1AD = 1)
 */

EXPORT Days_t FromGregorianDate(Date_t date) :=
    DEFINE FromGregorianYMD(Year(date), Month(date), Day(date));


/**
 * Converts the number days since 31st December 1BC to a date in the Gregorian calendar.
 *
 * @param days          The number of elapsed days (1 Jan 1AD = 1)
 * @return              A Date_t in the Gregorian calendar
 */

EXPORT Date_t ToGregorianDate(Days_t days) := DEFINE FUNCTION
    date := ToGregorianYMD(days);

    RETURN DateFromParts(date.year, date.month, date.day);
END;


/**
 * Returns a number representing the day of the year indicated by the given date.
 * The date must be in the Gregorian calendar after the year 1600.
 *
 * @param date          A Date_t value.
 * @return              A number (1-366) representing the number of days since
 *                      the beginning of the year.
 */

EXPORT UNSIGNED2 DayOfYear(Date_t date) := FUNCTION
    theYear := Year(date);
    theMonth := Month(date);
    theDay := Day(date);

    dayNum := TimeLib.GetDayOfYear(theYear, theMonth, theDay) + 1;

    RETURN dayNum;
END;


/**
 * Returns a number representing the day of the week indicated by the given date.
 * The date must be in the Gregorian calendar after the year 1600.
 *
 * @param date          A Date_t value.
 * @return              A number 1-7 representing the day of the week, where 1 = Sunday.
 */

EXPORT UNSIGNED1 DayOfWeek(Date_t date) := FUNCTION
    theYear := Year(date);
    theMonth := Month(date);
    theDay := Day(date);

    dayCode := TimeLib.GetDayOfWeek(theYear, theMonth, theDay) + 1;

    RETURN dayCode;
END;


/**
 * Tests whether the year is a leap year in the Julian calendar.
 *
 * @param year          The year (0-9999).
 * @return              True if the year is a leap year.
 */

EXPORT BOOLEAN IsJulianLeapYear(INTEGER2 year) := (year % 4 = 0);


SHARED JulianDateOrigin := -1753505;                // 1 Jan 1AD = 1


/**
 * Combines year, month, day in the Julian calendar to create the number
 * days since 31st December 1BC.
 *
 * @param year          The year (-4800..9999).
 * @param month         The month (1-12).
 * @param day           The day (1..daysInMonth).
 * @return              The number of elapsed days (1 Jan 1AD = 1)
 */

EXPORT Days_t FromJulianYMD(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) := FUNCTION
    //See Frequently Asked Questions about Calendars by Claus Toendering
    a := (14 - month) DIV 12;
    y := year + YearDelta - a;
    m := month + 12*a - 3;
    jd := day + (153 * m + 2) DIV 5 + 365 * y + y DIV 4;

    RETURN jd + (JulianDateOrigin-1);
END;


/**
 * Converts the number days since 31st December 1BC to a date in the Julian calendar.
 *
 * @param days          The number of elapsed days (1 Jan 1AD = 1)
 * @return              Module containing Year, Month, Day in the Julian calendar
 */

EXPORT ToJulianYMD(Days_t days) := FUNCTION
    //See Frequently Asked Questions about Calendars by Claus Toendering
    daysIn4Years := 3*365+366;
    c := days - JulianDateOrigin;
    d := (4 * c + 3) DIV daysIn4Years;
    e := c - ((daysIn4Years * d) DIV 4);
    m := (5 * e + 2) DIV 153;
    result := MODULE
        EXPORT UNSIGNED1 day := e - ((153 * m + 2) DIV 5) + 1;
        EXPORT UNSIGNED1 month := m + 3 - 12 * (m DIV 10);
        EXPORT INTEGER2 year := d - YearDelta + (m DIV 10);
    END;

    RETURN result;
END;


/**
 * Converts a date in the Julian calendar to the number days since 31st December 1BC.
 *
 * @param date          The date (using the Julian calendar)
 * @return              The number of elapsed days (1 Jan 1AD = 1)
 */

EXPORT Days_t FromJulianDate(Date_t date) := DEFINE FromJulianYMD(Year(date), Month(date), Day(date));


/**
 * Converts the number days since 31st December 1BC to a date in the Julian calendar.
 *
 * @param days          The number of elapsed days (1 Jan 1AD = 1)
 * @return              A Date_t in the Julian calendar
 */

EXPORT Date_t ToJulianDate(Days_t days) := DEFINE FUNCTION
    date := ToJulianYMD(days);

    RETURN DateFromParts(date.year, date.month, date.day);
END;

SHARED Date1900Delta := 693596;      // 1 Jan 1900 = 0


/**
 * Returns the number of days since 1st January 1900 (using the Gregorian Calendar)
 *
 * @param year          The year (-4713..9999).
 * @param month         The month (1-12).  A missing value (0) is treated as 1.
 * @param day           The day (1..daysInMonth).  A missing value (0) is treated as 1.
 * @return              The number of elapsed days since 1st January 1900
 */

EXPORT Days_t DaysSince1900(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) :=
    FromGregorianYMD(year, month, day) - Date1900Delta;


/**
 * Returns the number of days since 1st January 1900 (using the Gregorian Calendar)
 *
 * @param date          The date
 * @return              The number of elapsed days since 1st January 1900
 */

EXPORT Days_t ToDaysSince1900(Date_t date) := DaysSince1900(Year(date),Month(date),Day(date));


/**
 * Converts the number days since 1st January 1900 to a date in the Julian calendar.
 *
 * @param days          The number of elapsed days since 1st Jan 1900
 * @return              A Date_t in the Julian calendar
 */

EXPORT Date_t FromDaysSince1900(Days_t days) := ToGregorianDate(days + Date1900Delta);


/**
 * Calculate the number of whole years between two dates.
 *
 * @param from          The first date
 * @param to            The last date
 * @return              The number of years between them.
 */

EXPORT INTEGER YearsBetween (Date_t from, Date_t to) := FUNCTION
    fromDate := MIN(from, to);
    toDate := MAX(from, to);
    years := Year(toDate) - Year(fromDate);
    adjustedYears := years - IF(Month(fromDate) &amp;gt; Month(toDate) OR (Month(fromDate) = Month(toDate) AND Day(fromDate) &amp;gt; Day(toDate)), 1, 0);

    RETURN adjustedYears * IF(from &amp;gt; to, -1, 1);
END;


/**
 * Calculate the number of whole months between two dates.
 *
 * If month_ends_equal is set to TRUE and the given dates fall on the last day
 * of their respective months, the dates&amp;apos; day values will be considered equal
 * regardless of their actual values.  For example, given the dates 20160331
 * and 20160930 (last day of March and last day of September, respectively), if
 * month_ends_equal is FALSE then the function&amp;apos;s result will be 5; if
 * month_ends_equal is TRUE then the result will be 6.
 *
 * @param from              The first date
 * @param to                The last date
 * @param month_ends_equal  If TRUE and both dates fall on the last day of
 *                          their respective months, treat the difference
 *                          between the dates as whole months regardless of
 *                          the actual day values; if FALSE then the day value
 *                          of each date may be considered when calculating
 *                          the difference; OPTIONAL, defaults to FALSE
 * @return                  The number of months between them.
 */

EXPORT INTEGER MonthsBetween(Date_t from, Date_t to, BOOLEAN month_ends_equal = FALSE) := FUNCTION
    fromDate := MIN(from, to);
    toDate := MAX(from, to);
    years := Year(toDate) - Year(fromDate);
    months := Month(toDate) - Month(fromDate);
    result := years * 12 + months;
    fromIsMonthEnd := Day(fromDate) = CHOOSE(Month(fromDate),31,IF(IsLeapYear(Year(fromDate)),29,28),31,30,31,30,31,31,30,31,30,31);
    toIsMonthEnd := Day(toDate) = CHOOSE(Month(toDate),31,IF(IsLeapYear(Year(toDate)),29,28),31,30,31,30,31,31,30,31,30,31);
    adjustment := MAP
        (
            month_ends_equal AND fromIsMonthEnd AND toIsMonthEnd =&amp;gt; 0,
            Day(fromDate) &amp;gt; Day(toDate) =&amp;gt; 1,
            0
        );
    adjustedResult := result - adjustment;

    RETURN adjustedResult * IF(from &amp;gt; to, -1, 1);
END;


/**
 * Calculate the number of days between two dates.
 *
 * @param from          The first date
 * @param to            The last date
 * @return              The number of days between them.
 */

EXPORT INTEGER DaysBetween(Date_t from, Date_t to) := FUNCTION
    fromDays := FromGregorianDate(from);
    toDays   := FromGregorianDate(to);

    RETURN toDays - fromDays;
END;


/**
 * Combines the fields from a Date_rec to create a Date_t
 *
 * @param date          The row containing the date.
 * @return              A Date_t representing the combined values.
 */

EXPORT Date_t DateFromDateRec(Date_rec date) := (date.year * 100 + date.month) * 100 + date.day;


/**
 * Combines the fields from a Date_rec to create a Date_t
 *
 * @param date          The row containing the date.
 * @return              A Date_t representing the combined values.
 */

EXPORT Date_t DateFromRec(Date_rec date) := DateFromDateRec(date) : DEPRECATED(&amp;apos;Replaced with DateFromDateRec() function&amp;apos;);


/**
 * Combines the fields from a Time_rec to create a Time_t
 *
 * @param time          The row containing the time.
 * @return              A Time_t representing the combined values.
 */

EXPORT Time_t TimeFromTimeRec(Time_rec time) := (time.hour * 100 + time.minute) * 100 + time.second;


/**
 * Combines the date fields from a DateTime_rec to create a Date_t
 *
 * @param datetime      The row containing the datetime.
 * @return              A Date_t representing the combined values.
 */

EXPORT Date_t DateFromDateTimeRec(DateTime_rec datetime) := (datetime.year * 100 + datetime.month) * 100 + datetime.day;


/**
 * Combines the time fields from a DateTime_rec to create a Time_t
 *
 * @param datetime      The row containing the datetime.
 * @return              A Time_t representing the combined values.
 */

EXPORT Time_t TimeFromDateTimeRec(DateTime_rec datetime) := (datetime.hour * 100 + datetime.minute) * 100 + datetime.second;


/**
 * Combines the date and time fields from a DateTime_rec to create a Seconds_t
 *
 * @param datetime      The row containing the datetime.
 * @param is_local_time TRUE if the datetime components are expressed in local
 *                      time rather than UTC, FALSE if the components are
 *                      expressed in UTC.  Optional, defaults to FALSE.
 * @return              A Seconds_t representing the combined values.
 */

EXPORT Seconds_t SecondsFromDateTimeRec(DateTime_rec datetime, BOOLEAN is_local_time = FALSE) :=
    SecondsFromParts(datetime.year, datetime.month, datetime.day, datetime.hour, datetime.minute, datetime.second, is_local_time);


/**
 * Converts a string to a Date_t using the relevant string format.
 *
 * @param date_text     The string to be converted.
 * @param format        The format of the input string.
 *                      (See documentation for strftime)
 * @return              The date that was matched in the string.  Returns 0 if failed to match
 *                      or if the date components match but the result is an invalid date.
 *
 * Supported characters:
    %B          Full month name
    %b or %h    Abbreviated month name
    %d          Day of month (two digits)
    %e          Day of month (two digits, or a space followed by a single digit)
    %m          Month (two digits)
    %t          Whitespace
    %y          Year within century (00-99)
    %Y          Full year (yyyy)
    %j          Julian day (1-366)

Common date formats
    American    &amp;apos;%m/%d/%Y&amp;apos;  mm/dd/yyyy
    Euro        &amp;apos;%d/%m/%Y&amp;apos;  dd/mm/yyyy
    Iso format  &amp;apos;%Y-%m-%d&amp;apos;  yyyy-mm-dd
    Iso basic   &amp;apos;%Y%m%d&amp;apos;    yyyymmdd
                &amp;apos;%d-%b-%Y&amp;apos;  dd-mon-yyyy    e.g., &amp;apos;21-Mar-1954&amp;apos;
 */

EXPORT Date_t FromStringToDate(STRING date_text, VARSTRING format) :=
    StringLib.StringToDate(date_text, format);


/**
 * Converts a string to a date using the relevant string format.
 *
 * @param date_text     The string to be converted.
 * @param format        The format of the input string.
 *                      (See documentation for strftime)
 * @return              The date that was matched in the string.
 *                      Returns 0 if failed to match.
 */

EXPORT Date_t FromString(STRING date_text, VARSTRING format) :=
    FromStringToDate(date_text, format) : DEPRECATED(&amp;apos;Replaced with FromStringToDate() function&amp;apos;);


/**
 * Converts a string to a Time_t using the relevant string format.
 *
 * @param date_text     The string to be converted.
 * @param format        The format of the input string.
 *                      (See documentation for strftime)
 * @return              The time that was matched in the string.  Returns 0 if failed to match.
 *
 * Supported characters:
    %H          Hour (two digits)
    %k          Hour (two digits, or a space followed by a single digit)
    %M          Minute (two digits)
    %S          Second (two digits)
    %t          Whitespace
 */

EXPORT Time_t FromStringToTime(STRING time_text, VARSTRING format) :=
    StringLib.StringToTimeOfDay(time_text, format);


/**
 * Converts a string to a Seconds_t using the relevant string format.
 *
 * @param datetime_text The string to be converted.
 * @param format        The format of the input string.
 *                      (See documentation for strftime)
 * @param is_local_time TRUE if datetime_text is expressed in local time
 *                      rather than UTC, FALSE otherwise.  Optional, defaults
 *                      to FALSE.
 * @return              The seconds that was matched in the string.  Returns 0 if failed to match.
 *
 * Supported date characters:
    %B          Full month name
    %b or %h    Abbreviated month name
    %d          Day of month (two digits)
    %e          Day of month (two digits, or a space followed by a single digit)
    %m          Month (two digits)
    %y          Year within century (00-99)
    %Y          Full year (yyyy)
    %j          Julian day (1-366)
 *
 * Supported time characters:
    %H          Hour (two digits)
    %k          Hour (two digits, or a space followed by a single digit)
    %M          Minute (two digits)
    %S          Second (two digits)
 *
 * Other supported characters:
    %t          Whitespace
 */

EXPORT Seconds_t FromStringToSeconds(STRING datetime_text, VARSTRING format, BOOLEAN is_local_time = FALSE) :=
    TimeLib.StringToSeconds(datetime_text, format, is_local_time);


/**
 * Matches a string against a set of date string formats and returns a valid
 * Date_t object from the first format that successfully parses the string.
 *
 * @param date_text     The string to be converted.
 * @param formats       A set of formats to check against the string.
 *                      (See documentation for strftime)
 * @return              The date that was matched in the string.
 *                      Returns 0 if failed to match.
 *
 * Supported characters:
    %B          Full month name
    %b or %h    Abbreviated month name
    %d          Day of month (two digits)
    %e          Day of month (two digits, or a space followed by a single digit)
    %m          Month (two digits)
    %t          Whitespace
    %y          Year within century (00-99)
    %Y          Full year (yyyy)
    %j          Julian day (1-366)

Common date formats
    American    &amp;apos;%m/%d/%Y&amp;apos;  mm/dd/yyyy
    Euro        &amp;apos;%d/%m/%Y&amp;apos;  dd/mm/yyyy
    Iso format  &amp;apos;%Y-%m-%d&amp;apos;  yyyy-mm-dd
    Iso basic   &amp;apos;%Y%m%d&amp;apos;    yyyymmdd
                &amp;apos;%d-%b-%Y&amp;apos;  dd-mon-yyyy    e.g., &amp;apos;21-Mar-1954&amp;apos;
 */

EXPORT Date_t MatchDateString(STRING date_text, SET OF VARSTRING formats) :=
    StringLib.MatchDate(date_text, formats);


/**
 * Matches a string against a set of time string formats and returns a valid
 * Time_t object from the first format that successfully parses the string.
 *
 * @param time_text     The string to be converted.
 * @param formats       A set of formats to check against the string.
 *                      (See documentation for strftime)
 * @return              The time that was matched in the string.
 *                      Returns 0 if failed to match.
 */

EXPORT Time_t MatchTimeString(STRING time_text, SET OF VARSTRING formats) :=
    StringLib.MatchTimeOfDay(time_text, formats);


/**
 * Formats a date as a string.
 *
 * @param date          The date to be converted.
 * @param format        The format template to use for the conversion;
 *                      see strftime() for appropriate values.  The maximum
 *                      length of the resulting string is 255 characters.
 *                      Optional; defaults to &amp;apos;%Y-%m-%d&amp;apos; which is YYYY-MM-DD.
 * @return              Blank if date cannot be formatted, or the date in the
 *                      requested format.
 */

EXPORT STRING DateToString(Date_t date, VARSTRING format = &amp;apos;%Y-%m-%d&amp;apos;) :=
    TimeLib.DateToString(date, format);


/**
 * Formats a time as a string.
 *
 * @param time          The time to be converted.
 * @param format        The format template to use for the conversion;
 *                      see strftime() for appropriate values.  The maximum
 *                      length of the resulting string is 255 characters.
 *                      Optional; defaults to &amp;apos;%H:%M:%S&amp;apos; which is HH:MM:SS.
 * @return              Blank if the time cannot be formatted, or the time
 *                      in the requested format.
 */

EXPORT STRING TimeToString(Time_t time, VARSTRING format = &amp;apos;%H:%M:%S&amp;apos;) :=
    TimeLib.TimeToString(time, format);


/**
 * Converts a Seconds_t value into a human-readable string using a format template.
 *
 * @param seconds       The seconds since epoch.
 * @param format        The format template to use for the conversion; see
 *                      strftime() for appropriate values.  The maximum length
 *                      of the resulting string is 255 characters.
 *                      Optional; defaults to &amp;apos;%Y-%m-%dT%H:%M:%S&amp;apos; which is YYYY-MM-DDTHH:MM:SS.
 * @return              The converted seconds as a string.
 */

EXPORT STRING SecondsToString(Seconds_t seconds, VARSTRING format = &amp;apos;%Y-%m-%dT%H:%M:%S&amp;apos;) :=
    TimeLib.SecondsToString(seconds, format);


/**
 * Converts a Timestamp_t value into a human-readable string using a format template.
 *
 * @param timestamp     The microseconds since epoch.
 * @param format        The format template to use for the conversion; see
 *                      strftime() for appropriate format specifiers.  Two
 *                      additional format specifiers are available to show
 *                      fractional seconds:
 *                          %@ - fraction of seconds in microseconds (6 digits)
 *                          %# - fraction of seconds in milliseconds (3 digits)
 *                      The maximum length of the resulting string is 255
 *                      characters.  This parameter is optional and defaults to
 *                      &amp;apos;%Y-%m-%dT%H:%M:%S.%@&amp;apos; which is YYYY-MM-DDTHH:MM:SS.ssssss.
 * @return              The converted timestamp as a string.
 */

EXPORT STRING TimestampToString(Timestamp_t timestamp, VARSTRING format = &amp;apos;%Y-%m-%dT%H:%M:%S.%@&amp;apos;) := FUNCTION
    ms := INTFORMAT(timestamp % 1000000, 6, 1);
    f2 := REGEXREPLACE(&amp;apos;%@&amp;apos;, format, ms);
    f3 := REGEXREPLACE(&amp;apos;%#&amp;apos;, f2, ms[..3]);
    RETURN TimeLib.SecondsToString(timestamp DIV 1000000, f3);
END;


/**
 * Formats a date as a string.
 *
 * @param date          The date to be converted.
 * @param format        The format the date is output in.
 *                      (See documentation for strftime)
 * @return              Blank if date cannot be formatted, or the date in the
 *                      requested format.
 */

EXPORT STRING ToString(Date_t date, VARSTRING format) := DateToString(date, format) : DEPRECATED(&amp;apos;Replaced with DateToString() function&amp;apos;);


/**
 * Converts a date from one format to another
 *
 * @param date_text     The string containing the date to be converted.
 * @param from_format   The format the date is to be converted from.
 * @param to_format     The format the date is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 * @see                 FromStringToDate
 */

EXPORT STRING ConvertDateFormat(STRING date_text, VARSTRING from_format=&amp;apos;%m/%d/%Y&amp;apos;, VARSTRING to_format=&amp;apos;%Y%m%d&amp;apos;) := FUNCTION
    parsedDate := FromStringToDate(date_text, from_format);

    reformatResult := IF(parsedDate = (Date_t)0, &amp;apos;&amp;apos;, DateToString(parsedDate, to_format));

    RETURN reformatResult;
END;


/**
 * Converts a date from one format to another
 *
 * @param date_text     The string containing the date to be converted.
 * @param from_format   The format the date is to be converted from.
 * @param to_format     The format the date is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 */

EXPORT STRING ConvertFormat(STRING date_text, VARSTRING from_format=&amp;apos;%m/%d/%Y&amp;apos;, VARSTRING to_format=&amp;apos;%Y%m%d&amp;apos;) :=
    ConvertDateFormat(date_text, from_format, to_format) : DEPRECATED(&amp;apos;Replaced with ConvertDateFormat() function&amp;apos;);


/**
 * Converts a time from one format to another
 *
 * @param time_text     The string containing the time to be converted.
 * @param from_format   The format the time is to be converted from.
 * @param to_format     The format the time is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 */

EXPORT STRING ConvertTimeFormat(STRING time_text, VARSTRING from_format=&amp;apos;%H%M%S&amp;apos;, VARSTRING to_format=&amp;apos;%H:%M:%S&amp;apos;) :=
    TimeToString(FromStringToTime(time_text, from_format), to_format);


/**
 * Converts a date that matches one of a set of formats to another.
 *
 * @param date_text     The string containing the date to be converted.
 * @param from_formats  The list of formats the date is to be converted from.
 * @param to_format     The format the date is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 * @see                 MatchDateString
 */

EXPORT STRING ConvertDateFormatMultiple(STRING date_text, SET OF VARSTRING from_formats, VARSTRING to_format=&amp;apos;%Y%m%d&amp;apos;) := FUNCTION
    matchResult := MatchDateString(date_text, from_formats);

    reformatResult := IF(matchResult = (Date_t)0, &amp;apos;&amp;apos;, DateToString(matchResult, to_format));

    RETURN reformatResult;
END;


/**
 * Converts a date that matches one of a set of formats to another.
 *
 * @param date_text     The string containing the date to be converted.
 * @param from_formats  The list of formats the date is to be converted from.
 * @param to_format     The format the date is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 */

EXPORT STRING ConvertFormatMultiple(STRING date_text, SET OF VARSTRING from_formats, VARSTRING to_format=&amp;apos;%Y%m%d&amp;apos;) :=
    ConvertDateFormatMultiple(date_text, from_formats, to_format) : DEPRECATED(&amp;apos;Replaced with ConvertDateFormatMultiple() function&amp;apos;);


/**
 * Converts a time that matches one of a set of formats to another.
 *
 * @param time_text     The string containing the time to be converted.
 * @param from_formats  The list of formats the time is to be converted from.
 * @param to_format     The format the time is to be converted to.
 * @return              The converted string, or blank if it failed to match the format.
 */

EXPORT STRING ConvertTimeFormatMultiple(STRING time_text, SET OF VARSTRING from_formats, VARSTRING to_format=&amp;apos;%H:%m:%s&amp;apos;) :=
    TimeToString(MatchTimeString(time_text, from_formats), to_format);


/**
 * Adjusts a date by incrementing or decrementing year, month and/or day values.
 * The date must be in the Gregorian calendar after the year 1600.
 * If the new calculated date is invalid then it will be normalized according
 * to mktime() rules.  Example: 20140130 + 1 month = 20140302.
 *
 * @param date          The date to adjust.
 * @param year_delta    The requested change to the year value;
 *                      optional, defaults to zero.
 * @param month_delta   The requested change to the month value;
 *                      optional, defaults to zero.
 * @param day_delta     The requested change to the day of month value;
 *                      optional, defaults to zero.
 * @return              The adjusted Date_t value.
 */

EXPORT Date_t AdjustDate(Date_t date,
                         INTEGER2 year_delta = 0,
                         INTEGER4 month_delta = 0,
                         INTEGER4 day_delta = 0) :=
    TimeLib.AdjustDate(date, year_delta, month_delta, day_delta);


/**
 * Adjusts a date by adding or subtracting seconds.  The date must be in the
 * Gregorian calendar after the year 1600.  If the new calculated
 * date is invalid then it will be normalized according to mktime() rules.
 * Example: 20140130 + 172800 seconds = 20140201.
 *
 * @param date          The date to adjust.
 * @param seconds_delta The requested change to the date, in seconds.
 * @return              The adjusted Date_t value.
 */

EXPORT Date_t AdjustDateBySeconds(Date_t date, INTEGER4 seconds_delta) :=
    TimeLib.AdjustDateBySeconds(date, seconds_delta);


/**
 * Adjusts a time by incrementing or decrementing hour, minute and/or second
 * values.  If the new calculated time is invalid then it will be normalized
 * according to mktime() rules.
 *
 * @param time          The time to adjust.
 * @param hour_delta    The requested change to the hour value;
 *                      optional, defaults to zero.
 * @param minute_delta  The requested change to the minute value;
 *                      optional, defaults to zero.
 * @param second_delta  The requested change to the second of month value;
 *                      optional, defaults to zero.
 * @return              The adjusted Time_t value.
 */

EXPORT Time_t AdjustTime(Time_t time,
                         INTEGER2 hour_delta = 0,
                         INTEGER4 minute_delta = 0,
                         INTEGER4 second_delta = 0) :=
    TimeLib.AdjustTime(time, hour_delta, minute_delta, second_delta);


/**
 * Adjusts a time by adding or subtracting seconds.  If the new calculated
 * time is invalid then it will be normalized according to mktime() rules.
 *
 * @param time          The time to adjust.
 * @param seconds_delta The requested change to the time, in seconds.
 * @return              The adjusted Time_t value.
 */

EXPORT Time_t AdjustTimeBySeconds(Time_t time, INTEGER4 seconds_delta) :=
    TimeLib.AdjustTimeBySeconds(time, seconds_delta);


/**
 * Adjusts a Seconds_t value by adding or subtracting years, months, days,
 * hours, minutes and/or seconds.  This is performed by first converting the
 * seconds into a full date/time structure, applying any delta values to
 * individual date/time components, then converting the structure back to the
 * number of seconds.  This interim date must lie within Gregorian calendar
 * after the year 1600.  If the interim structure is found to have an invalid
 * date/time then it will be normalized according to mktime() rules.  Therefore,
 * some delta values (such as &amp;quot;1 month&amp;quot;) are actually relative to the value of
 * the seconds argument.
 *
 * @param seconds       The number of seconds to adjust.
 * @param year_delta    The requested change to the year value;
 *                      optional, defaults to zero.
 * @param month_delta   The requested change to the month value;
 *                      optional, defaults to zero.
 * @param day_delta     The requested change to the day of month value;
 *                      optional, defaults to zero.
 * @param hour_delta    The requested change to the hour value;
 *                      optional, defaults to zero.
 * @param minute_delta  The requested change to the minute value;
 *                      optional, defaults to zero.
 * @param second_delta  The requested change to the second of month value;
 *                      optional, defaults to zero.
 * @return              The adjusted Seconds_t value.
 */

EXPORT Seconds_t AdjustSeconds(Seconds_t seconds,
                               INTEGER2 year_delta = 0,
                               INTEGER4 month_delta = 0,
                               INTEGER4 day_delta = 0,
                               INTEGER4 hour_delta = 0,
                               INTEGER4 minute_delta = 0,
                               INTEGER4 second_delta = 0) :=
    TimeLib.AdjustSeconds(seconds, year_delta, month_delta, day_delta, hour_delta, minute_delta, second_delta);


/**
 * Adjusts a date by incrementing or decrementing months and/or years.  This
 * routine uses the rule outlined in McGinn v. State, 46 Neb. 427, 65 N.W. 46 (1895):
 * &amp;quot;The term calendar month, whether employed in statutes or contracts, and
 * not appearing to have been used in a different sense, denotes a period
 * terminating with the day of the succeeding month numerically corresponding
 * to the day of its beginning, less one. If there be no corresponding day of
 * the succeeding month, it terminates with the last day thereof.&amp;quot;  The
 * internet suggests similar legal positions exist in the Commonwealth
 * and Germany.  Note that day adjustments are performed after year and month
 * adjustments using the preceding rules.  As an example, Jan. 31, 2014 + 1 month
 * will result in Feb. 28, 2014; Jan. 31, 2014 + 1 month + 1 day will result
 * in Mar. 1, 2014.
 *
 * @param date          The date to adjust, in the Gregorian calendar after 1600.
 * @param year_delta    The requested change to the year value;
 *                      optional, defaults to zero.
 * @param month_delta   The requested change to the month value;
 *                      optional, defaults to zero.
 * @param day_delta     The requested change to the day value;
 *                      optional, defaults to zero.
 * @return              The adjusted Date_t value.
 */

EXPORT Date_t AdjustCalendar(Date_t date,
                             INTEGER2 year_delta = 0,
                             INTEGER4 month_delta = 0,
                             INTEGER4 day_delta = 0) :=
    TimeLib.AdjustCalendar(date, year_delta, month_delta, day_delta);

/**
 * Helper function.  Calculates the 1-based week number of a date, starting from
 * a reference date.  Week 1 always contains the reference date, and week 2
 * begins on the following day of the week indicated by the value of
 * startingDayOfWeek.  This is not an ISO-8601 implementation of computing week
 * numbers (&amp;quot;week dates&amp;quot;).
 *
 * @param date              The date for which to compute the week number;
 *                          must be greater than or equal to referenceDate
 * @param referenceDate     The date from which the week number counting begins;
 *                          must be less than or equal to date
 * @param startingDayOfWeek The index number of the first day of a week, 1-7,
 *                          where 1 = Sunday
 * @return                  The 1-based week number of date, relative to
 *                          referenceDate
 *
 * @see YearWeekNumFromDate, MonthWeekNumFromDate
 */

SHARED WeekNumForDate(Date_t date, Date_t referenceDate, UNSIGNED1 startingDayOfWeek) := FUNCTION
    referenceDayOfWeek := DayOfWeek(referenceDate);
    startingDayOfWeekDelta := (startingDayOfWeek - referenceDayOfWeek) % 7;
    referenceFirstDateOfWeek := AdjustDate(referenceDate, day_delta := startingDayOfWeekDelta);
    numberOfDays := DaysBetween(referenceFirstDateOfWeek, date) + 1;
    weekNum0 := (numberOfDays + 6) DIV 7;
    weekNum := IF(startingDayOfWeek &amp;gt; referenceDayOfWeek, weekNum0 + 1, weekNum0);

    RETURN weekNum;
END;

/**
 * Returns a number representing the day of the week indicated by the given date in ISO-8601.
 * The date must be in the Gregorian calendar after the year 1600.
 *
 * @param date          A Date_t value.
 * @return              A number 1-7 representing the day of the week, where 1 = Monday.
 */
EXPORT ISODayOfWeekFromDate(Date_t d) := ((DayOfWeek(d) + 5) % 7) + 1;		

/**
 * Helper function to figure out the number of weeks for a given year.
 * For more details, see: https://en.wikipedia.org/wiki/ISO_week_date#Weeks_per_year
 *
 * @param date          A Date_t value.
 * @return              Number between 0 and 6 to help figure out whether year is long (53 weeks) or short (52 weeks).
 */
SHARED ISOWeeksP(INTEGER2 year) := (year + TRUNCATE(year/4) - TRUNCATE(year/100) + TRUNCATE(year/400)) % 7;

/**
 * Returns true for years with 53 weeks, and false for years with 52 weeks.
 *
 * @param date          A Date_t value.
 * @return              TRUE if year is a long year (i.e. 53 weeks), FALSE otherwise.
 */
EXPORT ISOIsLongYear(INTEGER2 year) := (ISOWeeksP(year) = 4 OR ISOWeeksP(year - 1) = 3);

/**
 * Returns a number representing the maximum number of weeks for the year from date.
 *
 * @param date          A Date_t value.
 * @return              The number 52 for short years and 53 for long ones.
 */
EXPORT ISOWeeksFromDate(Date_t d) := 52 + IF(ISOIsLongYear(Year(d)), 1, 0);

/**
 * Returns a number representing the raw week number of the given date.
 *
 * @param date          A Date_t value.
 * @return              A number from 1 to 53.
 */
EXPORT ISORawWeekNumForDate(Date_t d) := TRUNCATE((DayOfYear(d) - ISODayOfWeekFromDate(d) + 10) / 7);

/**
 * Returns the ISO 1-based week number and year, of that week number, of a date.
 * First day(s) of a year may be in the previous year&amp;apos;s last week number.
 * This is an ISO-8601 implementation of computing week numbers (&amp;quot;week dates&amp;quot;).
 *
 * @param date          A Date_t value.
 * @return              A number 1-53 representing the week number in a year, 
 *                      and year 1600+ representing the year of that week number
 *                      (could be previous year from given date).
 */
EXPORT ISOWeekNumWeekDayAndYearFromDate(Date_t d) := FUNCTION
    givenYear := Year(d); 
    lastDayPreviousYear := DateFromParts(givenYear - 1, 12, 31);
    lastWeekPreviousYear := ISOWeeksFromDate(lastDayPreviousYear);
    lastDayGivenYear := DateFromParts(givenYear, 12, 31);
    lastWeekGivenYear := ISOWeeksFromDate(lastDayGivenYear);
    rawWeekNumber := ISORawWeekNumForDate(d);
    weekNumber := IF(rawWeekNumber &amp;lt; 1, lastWeekPreviousYear, IF(rawWeekNumber &amp;gt; lastWeekGivenYear, 1, rawWeekNumber));
    weekNumberYear := (givenYear + IF(rawWeekNumber &amp;lt; 1, -1, IF(rawWeekNumber &amp;gt; lastWeekGivenYear, 1, 0)));
    weekDay := ISODayOfWeekFromDate(d);
    result := MODULE
        EXPORT weekNumber := weekNumber;
        EXPORT year := weekNumberYear;
        EXPORT weekDay := weekDay;
    END;
    RETURN result;
END;

/**
 * Returns the ISO-8601 week date in extended (e.g. 2018-W23-7) or 
 * compact (e.g. 2018W237) form.
 * This is an ISO-8601 implementation of computing week numbers (&amp;quot;week dates&amp;quot;).
 *
 * @param date          A Date_t value.
 * @return              A number 1-53 representing the week number in a year, 
 *                      and year 1600+ representing the year of that week number
 *                      (could be previous year from given date).
 */
EXPORT ISOWeekDate(Date_t d, BOOLEAN extended = FALSE) := FUNCTION
    ISOWeekNumWeekDayAndYear := ISOWeekNumWeekDayAndYearFromDate(d);
    sep := IF(extended, &amp;apos;-&amp;apos;, &amp;apos;&amp;apos;);
    RETURN INTFORMAT(ISOWeekNumWeekDayAndYear.year, 4, 1) + sep + &amp;apos;W&amp;apos; + INTFORMAT(ISOWeekNumWeekDayAndYear.weeknumber, 2, 1) + sep + ISOWeekNumWeekDayAndYear.weekday;
END;

/**
 * Returns the 1-based week number of a date within the date&amp;apos;s year.  Week 1
 * always contains the first day of the year, and week 2 begins on the
 * following day of the week indicated by the value of startingDayOfWeek.  This
 * is not an ISO-8601 implementation of computing week numbers (&amp;quot;week dates&amp;quot;).
 *
 * @param date              The date for which to compute the week number
 * @param startingDayOfWeek The index number of the first day of a week, 1-7,
 *                          where 1 = Sunday; OPTIONAL, defaults to 1
 * @return                  The 1-based week number of date, relative to
 *                          the beginning of the date&amp;apos;s year
 *
 * @see MonthWeekNumFromDate
 */

EXPORT YearWeekNumFromDate(Date_t date, UNSIGNED1 startingDayOfWeek = 1) := FUNCTION
    yearStart := DateFromParts(Year(date), 1, 1);

    RETURN WeekNumForDate(date, yearStart, startingDayOfWeek);
END;

/**
 * Returns the 1-based week number of a date within the date&amp;apos;s month.  Week 1
 * always contains the first day of the month, and week 2 begins on the
 * following day of the week indicated by the value of startingDayOfWeek.  This
 * is not an ISO-8601 implementation of computing week numbers (&amp;quot;week dates&amp;quot;).
 *
 * @param date              The date for which to compute the week number
 * @param startingDayOfWeek The index number of the first day of a week, 1-7,
 *                          where 1 = Sunday; OPTIONAL, defaults to 1
 * @return                  The 1-based week number of date, relative to
 *                          the beginning of the date&amp;apos;s month
 *
 * @see YearWeekNumFromDate
 */

EXPORT MonthWeekNumFromDate(Date_t date, UNSIGNED1 startingDayOfWeek = 1) := FUNCTION
    monthStart := DateFromParts(Year(date), Month(date), 1);

    RETURN WeekNumForDate(date, monthStart, startingDayOfWeek);
END;


/**
 * Returns a boolean indicating whether daylight savings time is currently
 * in effect locally.
 *
 * @return      TRUE if daylight savings time is currently in effect, FALSE otherwise.
 */

EXPORT BOOLEAN IsLocalDaylightSavingsInEffect() :=
    TimeLib.IsLocalDaylightSavingsInEffect();


/**
 * Returns the offset (in seconds) of the time represented from UTC, with
 * positive values indicating locations east of the Prime Meridian.  Given a
 * UTC time in seconds since epoch, you can find the local time by adding the
 * result of this function to the seconds.  Note that daylight savings time is
 * factored into the offset.
 *
 * @return              The number of seconds offset from UTC.
 */

EXPORT INTEGER4 LocalTimeZoneOffset() :=
    TimeLib.LocalTimeZoneOffset();


/**
 * Returns the current date.
 *
 * @param in_local_time     TRUE if the returned value should be local to the
 *                          cluster computing the date, FALSE for UTC.
 *                          Optional, defaults to FALSE.
 * @return                  A Date_t representing the current date.
 */

EXPORT Date_t CurrentDate(BOOLEAN in_local_time = FALSE) :=
    TimeLib.CurrentDate(in_local_time);


/**
 * Returns the current date in the local time zone.
 *
 * @return              A Date_t representing the current date.
 */

EXPORT Date_t Today() := CurrentDate(TRUE);


/**
 * Returns the current time of day
 *
 * @param in_local_time     TRUE if the returned value should be local to the
 *                          cluster computing the time, FALSE for UTC.
 *                          Optional, defaults to FALSE.
 * @return                  A Time_t representing the current time of day.
 */

EXPORT Time_t CurrentTime(BOOLEAN in_local_time = FALSE) :=
    TimeLib.CurrentTime(in_local_time);


/**
 * Returns the current date and time as the number of seconds since epoch.
 *
 * @param in_local_time     TRUE if the returned value should be local to the
 *                          cluster computing the time, FALSE for UTC.
 *                          Optional, defaults to FALSE.
 * @return                  A Seconds_t representing the current time in
 *                          UTC or local time, depending on the argument.
 */

EXPORT Seconds_t CurrentSeconds(BOOLEAN in_local_time = FALSE) :=
    TimeLib.CurrentSeconds(in_local_time);


/**
 * Returns the current date and time as the number of microseconds since epoch.
 *
 * @param in_local_time     TRUE if the returned value should be local to the
 *                          cluster computing the time, FALSE for UTC.
 *                          Optional, defaults to FALSE.
 * @return                  A Timestamp_t representing the current time in
 *                          microseconds in UTC or local time, depending on
 *                          the argument.
 */

EXPORT Timestamp_t CurrentTimestamp(BOOLEAN in_local_time = FALSE) :=
    TimeLib.CurrentTimestamp(in_local_time);


/**
 * Returns the beginning and ending dates for the month surrounding the given date.
 *
 * @param as_of_date    The reference date from which the month will be
 *                      calculated.  This date must be a date within the
 *                      Gregorian calendar.  Optional, defaults to the
 *                      current date in UTC.
 * @return              Module with exported attributes for startDate and endDate.
 */

EXPORT DatesForMonth(Date_t as_of_date = CurrentDate(FALSE)) := FUNCTION
    lastDay := TimeLib.GetLastDayOfMonth(as_of_date);
    firstDay := (lastDay DIV 100) * 100 + 1;

    result := MODULE
        EXPORT Date_t startDate := firstDay;
        EXPORT Date_t endDate := lastDay;
    END;

    RETURN result;
END;


/**
 * Returns the beginning and ending dates for the week surrounding the given date
 * (Sunday marks the beginning of a week).
 *
 * @param as_of_date    The reference date from which the week will be
 *                      calculated.  This date must be a date within the
 *                      Gregorian calendar.  Optional, defaults to the
 *                      current date in UTC.
 * @return              Module with exported attributes for startDate and endDate.
 */

EXPORT DatesForWeek(Date_t as_of_date = CurrentDate(FALSE)) := FUNCTION
    lastWeekDates := ROW(TimeLib.DatesForWeek(as_of_date));

    result := MODULE
        EXPORT Date_t startDate := lastWeekDates.startDate;
        EXPORT Date_t endDate := lastWeekDates.endDate;
    END;

    RETURN result;
END;


/**
 * Tests whether a date is valid, both by range-checking the year and by
 * validating each of the other individual components.
 *
 * @param date              The date to validate.
 * @param yearLowerBound    The minimum acceptable year.
 *                          Optional; defaults to 1800.
 * @param yearUpperBound    The maximum acceptable year.
 *                          Optional; defaults to 2100.
 * @return                  TRUE if the date is valid, FALSE otherwise.
 */

EXPORT BOOLEAN IsValidDate(Date_t date,
                           INTEGER2 yearLowerBound = 1800,
                           INTEGER2 yearUpperBound = 2100) := FUNCTION
    yearInBounds := (Year(date) BETWEEN yearLowerBound AND yearUpperBound);
    monthInBounds := (Month(date) BETWEEN 1 AND 12);
    maxDayInMonth := CHOOSE(Month(date),31,IF(IsLeapYear(Year(date)),29,28),31,30,31,30,31,31,30,31,30,31);
    dayInBounds := (Day(date) BETWEEN 1 AND maxDayInMonth);

    RETURN yearInBounds AND monthInBounds AND dayInBounds;
END;


/**
 * Tests whether a date is valid in the Gregorian calendar.  The year
 * must be between 1601 and 30827.
 *
 * @param date              The Date_t to validate.
 * @return                  TRUE if the date is valid, FALSE otherwise.
 */

EXPORT BOOLEAN IsValidGregorianDate(Date_t date) := FUNCTION
    yearInBounds := (Year(date) BETWEEN 1601 AND 30827);
    matchesNormalized := (date = AdjustDate(date)); // AdjustDate normalizes, so this is a validation check

    RETURN yearInBounds AND matchesNormalized;
END;


/**
 * Tests whether a time is valid.
 *
 * @param time              The time to validate.
 * @return                  TRUE if the time is valid, FALSE otherwise.
 */

EXPORT BOOLEAN IsValidTime(Time_t time) := FUNCTION
    hourInBounds := (Hour(time) &amp;lt;= 23);
    minuteInBounds := (Minute(time) &amp;lt;= 59);
    secondInBounds := (Second(time) &amp;lt;= 59);

    RETURN hourInBounds AND minuteInBounds AND secondInBounds;
END;

//------------------------------------------------------------------------------
// Transforms
//------------------------------------------------------------------------------

/**
 * A transform to create a Date_rec from the individual elements
 *
 * @param year          The year
 * @param month         The month (1-12).
 * @param day           The day (1..daysInMonth).
 * @return              A transform that creates a Date_rec containing the date.
 */

EXPORT Date_rec CreateDate(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) := TRANSFORM
    SELF.year := year;
    SELF.month := month;
    SELF.day := day;
END;


/**
 * A transform to create a Date_rec from a Seconds_t value.
 *
 * @param seconds               The number seconds since epoch.
 * @param is_local_time         TRUE if seconds is expressed in local time
 *                              rather than UTC, FALSE if seconds is expressed
 *                              in UTC.  Optional, defaults to FALSE.
 * @return                      A transform that creates a Date_rec containing
 *                              the date.
 */

EXPORT Date_rec CreateDateFromSeconds(Seconds_t seconds, BOOLEAN is_local_time = FALSE) := TRANSFORM
    timeParts := SecondsToParts(seconds, is_local_time);

    SELF.year := timeParts.year;
    SELF.month := timeParts.month;
    SELF.day := timeParts.day;
END;


/**
 * A transform to create a Time_rec from the individual elements
 *
 * @param hour          The hour (0-23).
 * @param minute        The minute (0-59).
 * @param second        The second (0-59).
 * @return              A transform that creates a Time_rec containing the time of day.
 */

EXPORT Time_rec CreateTime(UNSIGNED1 hour, UNSIGNED1 minute, UNSIGNED1 second) := TRANSFORM
    SELF.hour := hour;
    SELF.minute := minute;
    SELF.second := second;
END;


/**
 * A transform to create a Time_rec from a Seconds_t value.
 *
 * @param seconds               The number seconds since epoch.
 * @param is_local_time         TRUE if seconds is expressed in local time
 *                              rather than UTC, FALSE if seconds is expressed
 *                              in UTC.  Optional, defaults to FALSE.
 * @return                      A transform that creates a Time_rec containing
 *                              the time of day.
 */

EXPORT Time_rec CreateTimeFromSeconds(Seconds_t seconds, BOOLEAN is_local_time = FALSE) := TRANSFORM
    timeParts := SecondsToParts(seconds, is_local_time);

    SELF.hour := timeParts.hour;
    SELF.minute := timeParts.minute;
    SELF.second := timeParts.second;
END;


/**
 * A transform to create a DateTime_rec from the individual elements
 *
 * @param year          The year
 * @param month         The month (1-12).
 * @param day           The day (1..daysInMonth).
 * @param hour          The hour (0-23).
 * @param minute        The minute (0-59).
 * @param second        The second (0-59).
 * @return              A transform that creates a DateTime_rec containing date
 *                      and time components.
 */

EXPORT DateTime_rec CreateDateTime(INTEGER2 year,
                                   UNSIGNED1 month,
                                   UNSIGNED1 day,
                                   UNSIGNED1 hour,
                                   UNSIGNED1 minute,
                                   UNSIGNED1 second) := TRANSFORM
    SELF.year := year;
    SELF.month := month;
    SELF.day := day;
    SELF.hour := hour;
    SELF.minute := minute;
    SELF.second := second;
END;


/**
 * A transform to create a DateTime_rec from a Seconds_t value.
 *
 * @param seconds               The number seconds since epoch.
 * @param is_local_time         TRUE if seconds is expressed in local time
 *                              rather than UTC, FALSE if seconds is expressed
 *                              in UTC.  Optional, defaults to FALSE.
 * @return                      A transform that creates a DateTime_rec
 *                              containing date and time components.
 */

EXPORT DateTime_rec CreateDateTimeFromSeconds(Seconds_t seconds, BOOLEAN is_local_time = FALSE) := TRANSFORM
    timeParts := SecondsToParts(seconds, is_local_time);

    SELF.year := timeParts.year;
    SELF.month := timeParts.month;
    SELF.day := timeParts.day;
    SELF.hour := timeParts.hour;
    SELF.minute := timeParts.minute;
    SELF.second := timeParts.second;
END;

//------------------------------------------------------------------------------
// Time Zone Module
//------------------------------------------------------------------------------

EXPORT TimeZone := MODULE, FORWARD

/**
 * Record definition for exported time zone information
 */

EXPORT TZDataLayout := RECORD
    STRING5         tzAbbrev;       // Time zone abbreviation; always uppercase; may be duplicated between records
    INTEGER4        secondsOffset;  // Number of seconds east (positive) or west (negative) of UTC
    SET OF STRING15 locations;      // Names of locations that use the given time zone abbreviation
END;

/**
 * Hardcoded time zone definitions; a general description of each time zone
 * is included as a line comment.  This information was collected from
 * https://www.timeanddate.com/time/zones/ with one modification (see below).
 *
 * The IST abbreviation can indicate three different time zones:
 *      India Standard Time
 *      Irish Standard Time
 *      Israel Standard Time
 *
 * Unfortunately, two of those IST time zones lie in the same location:  ASIA.
 * That makes it impossible to differentiate between them, and they have very
 * different offsets.  As a consequence, locations for Israel Standard Time and
 * Israel Daylight Time have been changed from ASIA to ISRAEL.
 */

EXPORT TZ_DATA := DATASET
    (
        [
            {&amp;apos;A&amp;apos;, 3600, [&amp;apos;MILITARY&amp;apos;]}, // Alpha Time Zone
            {&amp;apos;ACDT&amp;apos;, 37800, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Central Daylight Time
            {&amp;apos;ACST&amp;apos;, 34200, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Central Standard Time
            {&amp;apos;ACT&amp;apos;, -18000, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Acre Time
            {&amp;apos;ACT&amp;apos;, 34200, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Central Time
            {&amp;apos;ACWST&amp;apos;, 31500, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Central Western Standard Time
            {&amp;apos;ADT&amp;apos;, 10800, [&amp;apos;ASIA&amp;apos;]}, // Arabia Daylight Time
            {&amp;apos;ADT&amp;apos;, -10800, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;ATLANTIC&amp;apos;]}, // Atlantic Daylight Time
            {&amp;apos;AEDT&amp;apos;, 39600, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Eastern Daylight Time
            {&amp;apos;AEST&amp;apos;, 36000, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Eastern Standard Time
            {&amp;apos;AET&amp;apos;, 36000, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Eastern Time
            {&amp;apos;AFT&amp;apos;, 16200, [&amp;apos;ASIA&amp;apos;]}, // Afghanistan Time
            {&amp;apos;AKDT&amp;apos;, -28800, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Alaska Daylight Time
            {&amp;apos;AKST&amp;apos;, -32400, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Alaska Standard Time
            {&amp;apos;ALMT&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Alma-Ata Time
            {&amp;apos;AMST&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Amazon Summer Time
            {&amp;apos;AMST&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Armenia Summer Time
            {&amp;apos;AMT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Amazon Time
            {&amp;apos;AMT&amp;apos;, 14400, [&amp;apos;ASIA&amp;apos;]}, // Armenia Time
            {&amp;apos;ANAST&amp;apos;, 43200, [&amp;apos;ASIA&amp;apos;]}, // Anadyr Summer Time
            {&amp;apos;ANAT&amp;apos;, 43200, [&amp;apos;ASIA&amp;apos;]}, // Anadyr Time
            {&amp;apos;AOE&amp;apos;, -43200, [&amp;apos;PACIFIC&amp;apos;]}, // Anywhere on Earth
            {&amp;apos;AQTT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Aqtobe Time
            {&amp;apos;ART&amp;apos;, -10800, [&amp;apos;ANTARCTICA&amp;apos;, &amp;apos;SOUTH AMERICA&amp;apos;]}, // Argentina Time
            {&amp;apos;AST&amp;apos;, 7200, [&amp;apos;ASIA&amp;apos;]}, // Arabia Standard Time
            {&amp;apos;AST&amp;apos;, -14400, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;ATLANTIC&amp;apos; , &amp;apos;CARIBBEAN&amp;apos;]}, // Atlantic Standard Time
            {&amp;apos;AT&amp;apos;, -14400, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;ATLANTIC&amp;apos;, &amp;apos;CARIBBEAN&amp;apos;]}, // Atlantic Time
            {&amp;apos;AWDT&amp;apos;, 32400, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Western Daylight Time
            {&amp;apos;AWST&amp;apos;, 28800, [&amp;apos;AUSTRALIA&amp;apos;]}, // Australian Western Standard Time
            {&amp;apos;AZOST&amp;apos;, 0, [&amp;apos;ATLANTIC&amp;apos;]}, // Azores Summer Time
            {&amp;apos;AZOT&amp;apos;, -3600, [&amp;apos;ATLANTIC&amp;apos;]}, // Azores Time
            {&amp;apos;AZST&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Azerbaijan Summer Time
            {&amp;apos;AZT&amp;apos;, 14400, [&amp;apos;ASIA&amp;apos;]}, // Azerbaijan Time
            {&amp;apos;B&amp;apos;, 7200, [&amp;apos;MILITARY&amp;apos;]}, // Bravo Time Zone
            {&amp;apos;BNT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Brunei Darussalam Time
            {&amp;apos;BOT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Bolivia Time
            {&amp;apos;BRST&amp;apos;, -7200, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Brazil Summer Time
            {&amp;apos;BRT&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Brazil Time
            {&amp;apos;BST&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Bangladesh Standard Time
            {&amp;apos;BST&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // Bougainville Standard Time
            {&amp;apos;BST&amp;apos;, 3600, [&amp;apos;EUROPE&amp;apos;]}, // British Summer Time
            {&amp;apos;BTT&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Bhutan Time
            {&amp;apos;C&amp;apos;, 10800, [&amp;apos;MILITARY&amp;apos;]}, // Charlie Time Zone
            {&amp;apos;CAST&amp;apos;, 28800, [&amp;apos;ANTARCTICA&amp;apos;]}, // Casey Time
            {&amp;apos;CAT&amp;apos;, 7200, [&amp;apos;AFRICA&amp;apos;]}, // Central Africa Time
            {&amp;apos;CCT&amp;apos;, 23400, [&amp;apos;INDIAN OCEAN&amp;apos;]}, // Cocos Islands Time
            {&amp;apos;CDT&amp;apos;, -18000, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Central Daylight Time
            {&amp;apos;CDT&amp;apos;, -14400, [&amp;apos;CARIBBEAN&amp;apos;]}, // Cuba Daylight Time
            {&amp;apos;CEST&amp;apos;, 7200, [&amp;apos;EUROPE&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // Central European Summer Time
            {&amp;apos;CET&amp;apos;, 3600, [&amp;apos;EUROPE&amp;apos;, &amp;apos;AFRICA&amp;apos;]}, // Central European Time
            {&amp;apos;CHADT&amp;apos;, 49500, [&amp;apos;PACIFIC&amp;apos;]}, // Chatham Island Daylight Time
            {&amp;apos;CHAST&amp;apos;, 45900, [&amp;apos;PACIFIC&amp;apos;]}, // Chatham Island Standard Time
            {&amp;apos;CHOST&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Choibalsan Summer Time
            {&amp;apos;CHOT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Choibalsan Time
            {&amp;apos;ChST&amp;apos;, 36000, [&amp;apos;PACIFIC&amp;apos;]}, // Chamorro Standard Time
            {&amp;apos;CHUT&amp;apos;, 36000, [&amp;apos;PACIFIC&amp;apos;]}, // Chuuk Time
            {&amp;apos;CIDST&amp;apos;, -14400, [&amp;apos;CARIBBEAN&amp;apos;]}, // Cayman Islands Daylight Saving Time
            {&amp;apos;CIST&amp;apos;, -18000, [&amp;apos;CARIBBEAN&amp;apos;]}, // Cayman Islands Standard Time
            {&amp;apos;CKT&amp;apos;, -36000, [&amp;apos;PACIFIC&amp;apos;]}, // Cook Island Time
            {&amp;apos;CLST&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // Chile Summer Time
            {&amp;apos;CLT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // Chile Standard Time
            {&amp;apos;COT&amp;apos;, -18000, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Colombia Time
            {&amp;apos;CST&amp;apos;, -21600, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;CENTRAL AMERICA&amp;apos;]}, // Central Standard Time
            {&amp;apos;CST&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // China Standard Time
            {&amp;apos;CST&amp;apos;, -18000, [&amp;apos;CARIBBEAN&amp;apos;]}, // Cuba Standard Time
            {&amp;apos;CT&amp;apos;, -21600, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;CENTRAL AMERICA&amp;apos;]}, // Central Time
            {&amp;apos;CVT&amp;apos;, -3600, [&amp;apos;AFRICA&amp;apos;]}, // Cape Verde Time
            {&amp;apos;CXT&amp;apos;, 25200, [&amp;apos;AUSTRALIA&amp;apos;]}, // Christmas Island Time
            {&amp;apos;D&amp;apos;, 14400, [&amp;apos;MILITARY&amp;apos;]}, // Delta Time Zone
            {&amp;apos;DAVT&amp;apos;, 25200, [&amp;apos;ANTARCTICA&amp;apos;]}, // Davis Time
            {&amp;apos;DDUT&amp;apos;, 36000, [&amp;apos;ANTARCTICA&amp;apos;]}, // Dumont-d&amp;apos;Urville Time
            {&amp;apos;E&amp;apos;, 18000, [&amp;apos;MILITARY&amp;apos;]}, // Echo Time Zone
            {&amp;apos;EASST&amp;apos;, -18000, [&amp;apos;PACIFIC&amp;apos;]}, // Easter Island Summer Time
            {&amp;apos;EAST&amp;apos;, -21600, [&amp;apos;PACIFIC&amp;apos;]}, // Easter Island Standard Time
            {&amp;apos;EAT&amp;apos;, 10800, [&amp;apos;AFRICA&amp;apos;, &amp;apos;INDIAN OCEAN&amp;apos;]}, // Eastern Africa Time
            {&amp;apos;ECT&amp;apos;, -18000, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Ecuador Time
            {&amp;apos;EDT&amp;apos;, -14400, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;CARIBBEAN&amp;apos;]}, // Eastern Daylight Time
            {&amp;apos;EEST&amp;apos;, 10800, [&amp;apos;EUROPE&amp;apos;, &amp;apos;ASIA&amp;apos;]}, // Eastern European Summer Time
            {&amp;apos;EET&amp;apos;, 7200, [&amp;apos;EUROPE&amp;apos;, &amp;apos;ASIA&amp;apos;, &amp;apos;AFRICA&amp;apos;]}, // Eastern European Time
            {&amp;apos;EGST&amp;apos;, 0, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Eastern Greenland Summer Time
            {&amp;apos;EGT&amp;apos;, -3600, [&amp;apos;NORTH AMERICA&amp;apos;]}, // East Greenland Time
            {&amp;apos;EST&amp;apos;, -18000, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;CARIBBEAN&amp;apos;, &amp;apos;CENTRAL AMERICA&amp;apos;]}, // Eastern Standard Time
            {&amp;apos;ET&amp;apos;, -18000, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;CARIBBEAN&amp;apos;, &amp;apos;CENTRAL AMERICA&amp;apos;]}, // Eastern Time
            {&amp;apos;F&amp;apos;, 21600, [&amp;apos;MILITARY&amp;apos;]}, // Foxtrot Time Zone
            {&amp;apos;FET&amp;apos;, 10800, [&amp;apos;EUROPE&amp;apos;]}, // Further-Eastern European Time
            {&amp;apos;FJST&amp;apos;, 46800, [&amp;apos;PACIFIC&amp;apos;]}, // Fiji Summer Time
            {&amp;apos;FJT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Fiji Time
            {&amp;apos;FKST&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Falkland Islands Summer Time
            {&amp;apos;FKT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Falkland Island Time
            {&amp;apos;FNT&amp;apos;, -7200, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Fernando de Noronha Time
            {&amp;apos;G&amp;apos;, 25200, [&amp;apos;MILITARY&amp;apos;]}, // Golf Time Zone
            {&amp;apos;GALT&amp;apos;, -21600, [&amp;apos;PACIFIC&amp;apos;]}, // Galapagos Time
            {&amp;apos;GAMT&amp;apos;, -32400, [&amp;apos;PACIFIC&amp;apos;]}, // Gambier Time
            {&amp;apos;GET&amp;apos;, 14400, [&amp;apos;ASIA&amp;apos;]}, // Georgia Standard Time
            {&amp;apos;GFT&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // French Guiana Time
            {&amp;apos;GILT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Gilbert Island Time
            {&amp;apos;GMT&amp;apos;, 0, [&amp;apos;EUROPE&amp;apos;, &amp;apos;AFRICA&amp;apos;, &amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // Greenwich Mean Time
            {&amp;apos;GST&amp;apos;, 14400, [&amp;apos;ASIA&amp;apos;]}, // Gulf Standard Time
            {&amp;apos;GST&amp;apos;, -7200, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // South Georgia Time
            {&amp;apos;GYT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Guyana Time
            {&amp;apos;H&amp;apos;, 28800, [&amp;apos;MILITARY&amp;apos;]}, // Hotel Time Zone
            {&amp;apos;HADT&amp;apos;, -32400, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Hawaii-Aleutian Daylight Time
            {&amp;apos;HAST&amp;apos;, -36000, [&amp;apos;NORTH AMERICA&amp;apos;, &amp;apos;PACIFIC&amp;apos;]}, // Hawaii-Aleutian Standard Time
            {&amp;apos;HKT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Hong Kong Time
            {&amp;apos;HOVST&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Hovd Summer Time
            {&amp;apos;HOVT&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Hovd Time
            {&amp;apos;I&amp;apos;, 32400, [&amp;apos;MILITARY&amp;apos;]}, // India Time Zone
            {&amp;apos;ICT&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Indochina Time
            {&amp;apos;IDT&amp;apos;, 10800, [&amp;apos;ISRAEL&amp;apos;]}, // Israel Daylight Time; location was ASIA
            {&amp;apos;IOT&amp;apos;, 21600, [&amp;apos;INDIAN OCEAN&amp;apos;]}, // Indian Chagos Time
            {&amp;apos;IRDT&amp;apos;, 16200, [&amp;apos;ASIA&amp;apos;]}, // Iran Daylight Time
            {&amp;apos;IRKST&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Irkutsk Summer Time
            {&amp;apos;IRKT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Irkutsk Time
            {&amp;apos;IRST&amp;apos;, 12600, [&amp;apos;ASIA&amp;apos;]}, // Iran Standard Time
            {&amp;apos;IST&amp;apos;, 19800, [&amp;apos;ASIA&amp;apos;]}, // India Standard Time
            {&amp;apos;IST&amp;apos;, 3600, [&amp;apos;EUROPE&amp;apos;]}, // Irish Standard Time
            {&amp;apos;IST&amp;apos;, 7200, [&amp;apos;ISRAEL&amp;apos;]}, // Israel Standard Time; location was ASIA
            {&amp;apos;JST&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Japan Standard Time
            {&amp;apos;K&amp;apos;, 36000, [&amp;apos;MILITARY&amp;apos;]}, // Kilo Time Zone
            {&amp;apos;KGT&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Kyrgyzstan Time
            {&amp;apos;KOST&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // Kosrae Time
            {&amp;apos;KRAST&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Krasnoyarsk Summer Time
            {&amp;apos;KRAT&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Krasnoyarsk Time
            {&amp;apos;KST&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Korea Standard Time
            {&amp;apos;KUYT&amp;apos;, 14400, [&amp;apos;EUROPE&amp;apos;]}, // Kuybyshev Time
            {&amp;apos;L&amp;apos;, 39600, [&amp;apos;MILITARY&amp;apos;]}, // Lima Time Zone
            {&amp;apos;LHDT&amp;apos;, 39600, [&amp;apos;AUSTRALIA&amp;apos;]}, // Lord Howe Daylight Time
            {&amp;apos;LHST&amp;apos;, 37800, [&amp;apos;AUSTRALIA&amp;apos;]}, // Lord Howe Standard Time
            {&amp;apos;LINT&amp;apos;, 50400, [&amp;apos;PACIFIC&amp;apos;]}, // Line Islands Time
            {&amp;apos;M&amp;apos;, 43200, [&amp;apos;MILITARY&amp;apos;]}, // Mike Time Zone
            {&amp;apos;MAGST&amp;apos;, 43200, [&amp;apos;ASIA&amp;apos;]}, // Magadan Summer Time
            {&amp;apos;MAGT&amp;apos;, 39600, [&amp;apos;ASIA&amp;apos;]}, // Magadan Time
            {&amp;apos;MART&amp;apos;, -34200, [&amp;apos;PACIFIC&amp;apos;]}, // Marquesas Time
            {&amp;apos;MAWT&amp;apos;, 18000, [&amp;apos;ANTARCTICA&amp;apos;]}, // Mawson Time
            {&amp;apos;MDT&amp;apos;, -21600, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Mountain Daylight Time
            {&amp;apos;MHT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Marshall Islands Time
            {&amp;apos;MMT&amp;apos;, 23400, [&amp;apos;ASIA&amp;apos;]}, // Myanmar Time
            {&amp;apos;MSD&amp;apos;, 14400, [&amp;apos;EUROPE&amp;apos;]}, // Moscow Daylight Time
            {&amp;apos;MSK&amp;apos;, 10800, [&amp;apos;EUROPE&amp;apos;, &amp;apos;ASIA&amp;apos;]}, // Moscow Standard Time
            {&amp;apos;MST&amp;apos;, -25200, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Mountain Standard Time
            {&amp;apos;MT&amp;apos;, -25200, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Mountain Time
            {&amp;apos;MUT&amp;apos;, 14400, [&amp;apos;AFRICA&amp;apos;]}, // Mauritius Time
            {&amp;apos;MVT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Maldives Time
            {&amp;apos;MYT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Malaysia Time
            {&amp;apos;N&amp;apos;, -3600, [&amp;apos;MILITARY&amp;apos;]}, // November Time Zone
            {&amp;apos;NCT&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // New Caledonia Time
            {&amp;apos;NDT&amp;apos;, -9000, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Newfoundland Daylight Time
            {&amp;apos;NFT&amp;apos;, 39600, [&amp;apos;AUSTRALIA&amp;apos;]}, // Norfolk Time
            {&amp;apos;NOVST&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Novosibirsk Summer Time
            {&amp;apos;NOVT&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Novosibirsk Time
            {&amp;apos;NPT&amp;apos;, 20700, [&amp;apos;ASIA&amp;apos;]}, // Nepal Time
            {&amp;apos;NRT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Nauru Time
            {&amp;apos;NST&amp;apos;, -12600, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Newfoundland Standard Time
            {&amp;apos;NUT&amp;apos;, -39600, [&amp;apos;PACIFIC&amp;apos;]}, // Niue Time
            {&amp;apos;NZDT&amp;apos;, 46800, [&amp;apos;PACIFIC&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // New Zealand Daylight Time
            {&amp;apos;NZST&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;, &amp;apos;ANTARCTICA&amp;apos;]}, // New Zealand Standard Time
            {&amp;apos;O&amp;apos;, -7200, [&amp;apos;MILITARY&amp;apos;]}, // Oscar Time Zone
            {&amp;apos;OMSST&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Omsk Summer Time
            {&amp;apos;OMST&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Omsk Standard Time
            {&amp;apos;ORAT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Oral Time
            {&amp;apos;P&amp;apos;, -10800, [&amp;apos;MILITARY&amp;apos;]}, // Papa Time Zone
            {&amp;apos;PDT&amp;apos;, -25200, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Pacific Daylight Time
            {&amp;apos;PET&amp;apos;, -18000, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Peru Time
            {&amp;apos;PETST&amp;apos;, 43200, [&amp;apos;ASIA&amp;apos;]}, // Kamchatka Summer Time
            {&amp;apos;PETT&amp;apos;, 43200, [&amp;apos;ASIA&amp;apos;]}, // Kamchatka Time
            {&amp;apos;PGT&amp;apos;, 36000, [&amp;apos;PACIFIC&amp;apos;]}, // Papua New Guinea Time
            {&amp;apos;PHOT&amp;apos;, 46800, [&amp;apos;PACIFIC&amp;apos;]}, // Phoenix Island Time
            {&amp;apos;PHT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Philippine Time
            {&amp;apos;PKT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Pakistan Standard Time
            {&amp;apos;PMDT&amp;apos;, -7200, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Pierre &amp;amp; Miquelon Daylight Time
            {&amp;apos;PMST&amp;apos;, -10800, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Pierre &amp;amp; Miquelon Standard Time
            {&amp;apos;PONT&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // Pohnpei Standard Time
            {&amp;apos;PST&amp;apos;, -28800, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Pacific Standard Time
            {&amp;apos;PST&amp;apos;, -28800, [&amp;apos;PACIFIC&amp;apos;]}, // Pitcairn Standard Time
            {&amp;apos;PT&amp;apos;, -28800, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Pacific Time
            {&amp;apos;PWT&amp;apos;, 32400, [&amp;apos;PACIFIC&amp;apos;]}, // Palau Time
            {&amp;apos;PYST&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Paraguay Summer Time
            {&amp;apos;PYT&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Paraguay Time
            {&amp;apos;PYT&amp;apos;, 30600, [&amp;apos;ASIA&amp;apos;]}, // Pyongyang Time
            {&amp;apos;Q&amp;apos;, -14400, [&amp;apos;MILITARY&amp;apos;]}, // Quebec Time Zone
            {&amp;apos;QYZT&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Qyzylorda Time
            {&amp;apos;R&amp;apos;, -18000, [&amp;apos;MILITARY&amp;apos;]}, // Romeo Time Zone
            {&amp;apos;RET&amp;apos;, 14400, [&amp;apos;AFRICA&amp;apos;]}, // Reunion Time
            {&amp;apos;ROTT&amp;apos;, -10800, [&amp;apos;ANTARCTICA&amp;apos;]}, // Rothera Time
            {&amp;apos;S&amp;apos;, -21600, [&amp;apos;MILITARY&amp;apos;]}, // Sierra Time Zone
            {&amp;apos;SAKT&amp;apos;, 39600, [&amp;apos;ASIA&amp;apos;]}, // Sakhalin Time
            {&amp;apos;SAMT&amp;apos;, 14400, [&amp;apos;EUROPE&amp;apos;]}, // Samara Time
            {&amp;apos;SAST&amp;apos;, 7200, [&amp;apos;AFRICA&amp;apos;]}, // South Africa Standard Time
            {&amp;apos;SBT&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // Solomon Islands Time
            {&amp;apos;SCT&amp;apos;, 14400, [&amp;apos;AFRICA&amp;apos;]}, // Seychelles Time
            {&amp;apos;SGT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Singapore Time
            {&amp;apos;SRET&amp;apos;, 39600, [&amp;apos;ASIA&amp;apos;]}, // Srednekolymsk Time
            {&amp;apos;SRT&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Suriname Time
            {&amp;apos;SST&amp;apos;, -39600, [&amp;apos;PACIFIC&amp;apos;]}, // Samoa Standard Time
            {&amp;apos;SYOT&amp;apos;, 10800, [&amp;apos;ANTARCTICA&amp;apos;]}, // Syowa Time
            {&amp;apos;T&amp;apos;, -25200, [&amp;apos;MILITARY&amp;apos;]}, // Tango Time Zone
            {&amp;apos;TAHT&amp;apos;, -36000, [&amp;apos;PACIFIC&amp;apos;]}, // Tahiti Time
            {&amp;apos;TFT&amp;apos;, 18000, [&amp;apos;INDIAN OCEAN&amp;apos;]}, // French Southern and Antarctic Time
            {&amp;apos;TJT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Tajikistan Time
            {&amp;apos;TKT&amp;apos;, 46800, [&amp;apos;PACIFIC&amp;apos;]}, // Tokelau Time
            {&amp;apos;TLT&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // East Timor Time
            {&amp;apos;TMT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Turkmenistan Time
            {&amp;apos;TOST&amp;apos;, 50400, [&amp;apos;PACIFIC&amp;apos;]}, // Tonga Summer Time
            {&amp;apos;TOT&amp;apos;, 46800, [&amp;apos;PACIFIC&amp;apos;]}, // Tonga Time
            {&amp;apos;TRT&amp;apos;, 10800, [&amp;apos;ASIA&amp;apos;, &amp;apos;EUROPE&amp;apos;]}, // Turkey Time
            {&amp;apos;TVT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Tuvalu Time
            {&amp;apos;U&amp;apos;, -28800, [&amp;apos;MILITARY&amp;apos;]}, // Uniform Time Zone
            {&amp;apos;ULAST&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Ulaanbaatar Summer Time
            {&amp;apos;ULAT&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Ulaanbaatar Time
            {&amp;apos;UTC&amp;apos;, 0, [&amp;apos;WORLDWIDE&amp;apos;]}, // Coordinated Universal Time
            {&amp;apos;UYST&amp;apos;, -7200, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Uruguay Summer Time
            {&amp;apos;UYT&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Uruguay Time
            {&amp;apos;UZT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Uzbekistan Time
            {&amp;apos;V&amp;apos;, -32400, [&amp;apos;MILITARY&amp;apos;]}, // Victor Time Zone
            {&amp;apos;VET&amp;apos;, -14400, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Venezuelan Standard Time
            {&amp;apos;VLAST&amp;apos;, 39600, [&amp;apos;ASIA&amp;apos;]}, // Vladivostok Summer Time
            {&amp;apos;VLAT&amp;apos;, 36000, [&amp;apos;ASIA&amp;apos;]}, // Vladivostok Time
            {&amp;apos;VOST&amp;apos;, 21600, [&amp;apos;ANTARCTICA&amp;apos;]}, // Vostok Time
            {&amp;apos;VUT&amp;apos;, 39600, [&amp;apos;PACIFIC&amp;apos;]}, // Vanuatu Time
            {&amp;apos;W&amp;apos;, -36000, [&amp;apos;MILITARY&amp;apos;]}, // Whiskey Time Zone
            {&amp;apos;WAKT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Wake Time
            {&amp;apos;WARST&amp;apos;, -10800, [&amp;apos;SOUTH AMERICA&amp;apos;]}, // Western Argentine Summer Time
            {&amp;apos;WAST&amp;apos;, 7200, [&amp;apos;AFRICA&amp;apos;]}, // West Africa Summer Time
            {&amp;apos;WAT&amp;apos;, 3600, [&amp;apos;AFRICA&amp;apos;]}, // West Africa Time
            {&amp;apos;WEST&amp;apos;, 3600, [&amp;apos;EUROPE&amp;apos;, &amp;apos;AFRICA&amp;apos;]}, // Western European Summer Time
            {&amp;apos;WET&amp;apos;, 0, [&amp;apos;EUROPE&amp;apos;, &amp;apos;AFRICA&amp;apos;]}, // Western European Time
            {&amp;apos;WFT&amp;apos;, 43200, [&amp;apos;PACIFIC&amp;apos;]}, // Wallis and Futuna Time
            {&amp;apos;WGST&amp;apos;, -7200, [&amp;apos;NORTH AMERICA&amp;apos;]}, // Western Greenland Summer Time
            {&amp;apos;WGT&amp;apos;, -10800, [&amp;apos;NORTH AMERICA&amp;apos;]}, // West Greenland Time
            {&amp;apos;WIB&amp;apos;, 25200, [&amp;apos;ASIA&amp;apos;]}, // Western Indonesian Time
            {&amp;apos;WIT&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Eastern Indonesian Time
            {&amp;apos;WITA&amp;apos;, 28800, [&amp;apos;ASIA&amp;apos;]}, // Central Indonesian Time
            {&amp;apos;WST&amp;apos;, 50400, [&amp;apos;PACIFIC&amp;apos;]}, // West Samoa Time
            {&amp;apos;WST&amp;apos;, 3600, [&amp;apos;AFRICA&amp;apos;]}, // Western Sahara Summer Time
            {&amp;apos;WT&amp;apos;, 0, [&amp;apos;AFRICA&amp;apos;]}, // Western Sahara Standard Time
            {&amp;apos;X&amp;apos;, -39600, [&amp;apos;MILITARY&amp;apos;]}, // X-ray Time Zone
            {&amp;apos;Y&amp;apos;, -43200, [&amp;apos;MILITARY&amp;apos;]}, // Yankee Time Zone
            {&amp;apos;YAKST&amp;apos;, 36000, [&amp;apos;ASIA&amp;apos;]}, // Yakutsk Summer Time
            {&amp;apos;YAKT&amp;apos;, 32400, [&amp;apos;ASIA&amp;apos;]}, // Yakutsk Time
            {&amp;apos;YAPT&amp;apos;, 36000, [&amp;apos;PACIFIC&amp;apos;]}, // Yap Time
            {&amp;apos;YEKST&amp;apos;, 21600, [&amp;apos;ASIA&amp;apos;]}, // Yekaterinburg Summer Time
            {&amp;apos;YEKT&amp;apos;, 18000, [&amp;apos;ASIA&amp;apos;]}, // Yekaterinburg Time
            {&amp;apos;Z&amp;apos;, 0, [&amp;apos;MILITARY&amp;apos;]} // Zulu Time Zone
        ],
        TZDataLayout
    );

/**
 * Return a list of unique time zone abbreviations from the hardcoded dataset.
 * All abbreviations are in uppercase.
 *
 * @return              A new DATASET({STRING5 tzAbbrev}) containing the
 *                      unique time zone abbreviations.
 */

EXPORT UniqueTZAbbreviations() := FUNCTION
    RETURN TABLE(TZ_DATA, {tzAbbrev}, tzAbbrev);
END;

/**
 * Return a list of unique location names from the hardcoded dataset.
 * All names are in uppercase.
 *
 * @return              A new DATASET({STRING name}) containing the
 *                      unique location names.
 */

EXPORT UniqueTZLocations() := FUNCTION
    NameRec := {STRING name};

    // Gather all locations as a collection of child datasets
    collectedNames := PROJECT
        (
            TZ_DATA,
            TRANSFORM
                (
                    {
                        DATASET(NameRec)    names
                    },
                    SELF.names := DATASET(LEFT.locations, NameRec)
                )
        );

    // Flatten collected names, so there is one name per record
    flattenedNames := NORMALIZE
        (
            collectedNames,
            LEFT.names,
            TRANSFORM
                (
                    NameRec,
                    SELF.name := RIGHT.name
                )
        );

    // Deduplicate the names
    ds3 := TABLE(flattenedNames, {name}, name);

    RETURN ds3;
END;

/**
 * Finds the time zone records for a given location.
 *
 * @param   location        The name of the location to search for; must be a
 *                          non-empty uppercase string; REQUIRED
 * @return                  A new DATASET(STRING5 tzAbbrev, INTEGER4 secondsOffset)
 *                          containing the found records
 * @see     FindTZData
 */

EXPORT TZDataForLocation(STRING location) := FUNCTION
    ResultRec := RECORD
        STRING5         tzAbbrev;
        INTEGER4        secondsOffset;
    END;

    foundRecs := TZ_DATA(location IN locations);
    foundTrimmed := PROJECT
        (
            foundRecs,
            TRANSFORM
                (
                    ResultRec,
                    SELF := LEFT
                )
        );

    RETURN foundTrimmed;
END;

/**
 * Finds the time zone records for a given abbreviation and optional location.
 * A location should be provided as a method of differentiation if the
 * abbreviation has duplicate entries.
 *
 * @param   timeZoneAbbrev  The time zone abbreviation to search for;
 *                          must be a non-empty uppercase string; REQUIRED
 * @param   location        The name of the location to search for; if a
 *                          location is not provided or is an empty string,
 *                          all records matching only the abbreviation are
 *                          returned; OPTIONAL, defaults to an empty string
 * @return                  A new DATASET(TZDataLayout) containing the found
 *                          records
 * @see     TZDataForLocation
 */

EXPORT DATASET(TZDataLayout) FindTZData(STRING5 timeZoneAbbrev, STRING location = &amp;apos;&amp;apos;) := FUNCTION
    RETURN TZ_DATA(tzAbbrev = timeZoneAbbrev AND (location = &amp;apos;&amp;apos; OR location IN locations));
END;

/**
 * Compute the offset, in seconds, between two different time zones.  Each
 * time zone is designated by a required time zone abbreviation and an
 * optional location name.  The result is the number of seconds (which can be
 * either positive or negative) that would have to be applied to a time when
 * traveling from &amp;apos;fromTimeZoneAbbrev&amp;apos; to &amp;apos;toTimeZoneAbbrev&amp;apos;.
 *
 * Be aware that some time zones explicitly represent daylight savings time, so
 * it is entirely possible to change not only time zones but DST observance as
 * well in a single call.
 *
 * @param   fromTimeZoneAbbrev  The time zone abbreviation designated as the
 *                              starting point; must be a non-empty uppercase
 *                              string; REQUIRED
 * @param   toTimeZoneAbbrev    The time zone abbreviation designated as the
 *                              ending point; must be a non-empty uppercase
 *                              string; REQUIRED
 * @param   fromLocation        The name of the location that goes along with
 *                              fromTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching fromTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @param   toLocation          The name of the location that goes along with
 *                              toTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching toTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      The number of seconds between the two time
 *                              zones; will return zero if either time zone
 *                              cannot be found
 * @see     AdjustTimeTZ
 */

EXPORT INTEGER4 SecondsBetweenTZ(STRING5 fromTimeZoneAbbrev,
                                 STRING5 toTimeZoneAbbrev,
                                 STRING fromLocation = &amp;apos;&amp;apos;,
                                 STRING toLocation = &amp;apos;&amp;apos;) := FUNCTION
    fromTZ := FindTZData(fromTimeZoneAbbrev, fromLocation);
    toTZ := FindTZData(toTimeZoneAbbrev, toLocation);
    hasTZInfo := EXISTS(fromTZ) AND EXISTS(toTZ);

    fromSecondsOffset := fromTZ[1].secondsOffset;
    toSecondsOffset := toTZ[1].secondsOffset;

    RETURN IF
        (
            hasTZInfo,
            toSecondsOffset - fromSecondsOffset,
            0
        );
END;

/**
 * Adjust a given Time_t time value for another time zone.  Both the given time
 * and the destination time zone are designated by a required time zone
 * abbreviation and an optional location name.
 *
 * @param   time                The time value to adjust; REQUIRED
 * @param   fromTimeZoneAbbrev  The time zone abbreviation that the time
 *                              value is assumed to be within; must be a
 *                              non-empty uppercase string; REQUIRED
 * @param   toTimeZoneAbbrev    The time zone abbreviation designated as the
 *                              ending point; must be a non-empty uppercase
 *                              string; REQUIRED
 * @param   fromLocation        The name of the location that goes along with
 *                              fromTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching fromTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @param   toLocation          The name of the location that goes along with
 *                              toTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching toTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      The given time value adjusted by the difference
 *                              between the two given time zones; if either
 *                              time zone cannot be found then the original
 *                              time value will be returned unchanged
 * @see     SecondsBetweenTZ
 */

EXPORT Time_t AdjustTimeTZ(Time_t time,
                           STRING5 fromTimeZoneAbbrev,
                           STRING5 toTimeZoneAbbrev,
                           STRING fromLocation = &amp;apos;&amp;apos;,
                           STRING toLocation = &amp;apos;&amp;apos;) := FUNCTION
    diff := SecondsBetweenTZ(fromTimeZoneAbbrev, toTimeZoneAbbrev, fromLocation, toLocation);
    newTime := AdjustTime(time, second_delta := diff);

    RETURN newTime;
END;

/**
 * Converts a UTC time to a time designated by a time zone abbreviation and
 * optional location.
 *
 * @param   utcTime             The UTC time value to adjust; REQUIRED
 * @param   toTimeZoneAbbrev    The time zone abbreviation designated as the
 *                              ending point; must be a non-empty uppercase
 *                              string; REQUIRED
 * @param   toLocation          The name of the location that goes along with
 *                              toTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching toTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      The given UTC time value adjusted to the time
 *                              zone defined by toTimeZoneAbbrev and toLocation;
 *                              if the time zone cannot be found then the
 *                              original time value will be returned unchanged
 * @see     AdjustTimeTZ
 * @see     ToUTCTime
 */

EXPORT Time_t ToLocalTime(Time_t utcTime,
                          STRING5 toTimeZoneAbbrev,
                          STRING toLocation = &amp;apos;&amp;apos;) := FUNCTION
    RETURN AdjustTimeTZ(utcTime, &amp;apos;UTC&amp;apos;, toTimeZoneAbbrev, toLocation := toLocation);
END;

/**
 * Converts a local time, defined with a time zone abbreviation and optional
 * location, to a UTC time.
 *
 * @param   localTime           The time value to adjust; REQUIRED
 * @param   fromTimeZoneAbbrev  The time zone abbreviation that the localTime
 *                              value is assumed to be within; must be a
 *                              non-empty uppercase string; REQUIRED
 * @param   fromLocation        The name of the location that goes along with
 *                              fromTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching fromTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      The given local time value adjusted to UTC time;
 *                              if the given time zone cannot be found then the
 *                              original UTC time value will be returned
 *                              unchanged
 * @see     AdjustTimeTZ
 * @see     ToLocalTime
 */

EXPORT Time_t ToUTCTime(Time_t localTime,
                        STRING5 fromTimeZoneAbbrev,
                        STRING fromLocation = &amp;apos;&amp;apos;) := FUNCTION
    RETURN AdjustTimeTZ(localTime, fromTimeZoneAbbrev, &amp;apos;UTC&amp;apos;, fromLocation := fromLocation);
END;

/**
 * Given a dataset that contains a time zone abbreviation and optional location,
 * this function macro appends four new attributes to the dataset that contain
 * useful information for translating a time value into another time zone.
 * This could be useful as an ETL step where time data is made common in
 * respect to one particular time zone (e.g. UTC).
 *
 * The actions within this function macro are conceptually similar to
 * SecondsBetweenTZ() but applied to an entire dataset, and somewhat more
 * efficiently.
 *
 * Note:  In order for this function macro to execute correctly, the calling
 * code must import the Std library.
 *
 * @param   inFile              The dataset to process; REQUIRED
 * @param   timeZoneAbbrevField The attribute within inFile that contains
 *                              the time zone abbreviation to use for matching;
 *                              the values in this attribute should be in
 *                              uppercase; this is not a string; REQUIRED
 * @param   newOffsetField      The attribute that will be appended to inFile
 *                              and will contain the number of seconds offset
 *                              from UTC; this is not a string; REQUIRED
 * @param   fromLocationField   The attribute within inFile that contains the
 *                              time zone location for the time zone cited by
 *                              timeZoneAbbrevField; this is not a string;
 *                              OPTIONAL, defaults to a null value (indicating
 *                              that there is no time zone location attribute)
 * @param   toTimeZoneAbbrev    The &amp;apos;to&amp;apos; time zone abbreviation to use for all
 *                              calculations, as a string; OPTIONAL, defaults
 *                              to &amp;apos;UTC&amp;apos;
 * @param   toLocation          The name of the location that goes along with
 *                              toTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching toTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      A new dataset with the same record definition
 *                              as inFile but with four new attributes added;
 *                              the new attributes are named based on the name
 *                              given as the newOffsetField attribute:
 *                                  INTEGER4    &amp;lt;newOffsetField&amp;gt;            // Offset, in seconds, between original time zone and toTimeZoneAbbrev
 *                                  BOOLEAN     &amp;lt;newOffsetField&amp;gt;_is_valid   // TRUE if &amp;lt;newOffsetField&amp;gt; contains a valid value
 *                                  STRING5     &amp;lt;newOffsetField&amp;gt;_tz         // The value of toTimeZoneAbbrev
 *                                  STRING15    &amp;lt;newOffsetField&amp;gt;_location   // The time zone location for &amp;lt;newOffsetField&amp;gt;_tz
 *                              If &amp;lt;newOffsetField&amp;gt;_is_valid is FALSE then
 *                              &amp;lt;newOffsetField&amp;gt; will be zero.
 * @see     AppendTZAdjustedTime
 *
 * Examples:
 *
 *   ds := DATASET
 *      (
 *          [
 *              {120000, &amp;apos;CT&amp;apos;},
 *              {120000, &amp;apos;ET&amp;apos;}
 *          ],
 *          {Std.Date.Time_t time, STRING tz}
 *      );
 *
 *  utcOffsetDS := Std.Date.TimeZone.AppendTZOffset(ds, tz, seconds_to_utc);
 *  OUTPUT(utcOffsetDS, NAMED(&amp;apos;offset_to_utc_result&amp;apos;));
 *
 *  ptOffsetDS := Std.Date.TimeZone.AppendTZOffset
 *      (
 *          ds,
 *          tz,
 *          seconds_to_pacific_time,
 *          toTimeZoneAbbrev := &amp;apos;PT&amp;apos;,
 *          toLocation := &amp;apos;NORTH AMERICA&amp;apos;
 *      );
 *  OUTPUT(ptOffsetDS, NAMED(&amp;apos;offset_to_pacific_time_result&amp;apos;));
 */

EXPORT AppendTZOffset(inFile,
                      timeZoneAbbrevField,
                      newOffsetField,
                      fromLocationField = &amp;apos;&amp;apos;,
                      toTimeZoneAbbrev = &amp;apos;\&amp;apos;UTC\&amp;apos;&amp;apos;,
                      toLocation = &amp;apos;\&amp;apos;\&amp;apos;&amp;apos;) := FUNCTIONMACRO
    // Find the destination time zone information just once
    #UNIQUENAME(destOffsetDS);
    LOCAL %destOffsetDS% := Std.Date.TimeZone.FindTZData(toTimeZoneAbbrev, toLocation);
    #UNIQUENAME(destOffsetFound);
    LOCAL %destOffsetFound% := EXISTS(%destOffsetDS%);
    #UNIQUENAME(destLocation);
    LOCAL %destLocation% := IF(toLocation != &amp;apos;&amp;apos;, toLocation, %destOffsetDS%[1].locations[1]);
    #UNIQUENAME(destOffset);
    LOCAL %destOffset% := %destOffsetDS%[1].secondsOffset;

    RETURN JOIN
        (
            inFile,
            Std.Date.TimeZone.TZ_DATA,
            LEFT.timeZoneAbbrevField = RIGHT.tzAbbrev
                #IF(#TEXT(fromLocationField) != &amp;apos;&amp;apos;)
                    AND LEFT.fromLocationField IN RIGHT.locations
                #END
                AND %destOffsetFound%,
            TRANSFORM
                (
                    {
                        RECORDOF(inFile),
                        INTEGER4    newOffsetField,
                        BOOLEAN     #EXPAND(#TEXT(newOffsetField) + &amp;apos;_is_valid&amp;apos;),
                        STRING5     #EXPAND(#TEXT(newOffsetField) + &amp;apos;_tz&amp;apos;),
                        STRING15    #EXPAND(#TEXT(newOffsetField) + &amp;apos;_location&amp;apos;)
                    },

                    wasFound := RIGHT.tzAbbrev != &amp;apos;&amp;apos;;

                    SELF.newOffsetField := IF(wasFound, %destOffset% - RIGHT.secondsOffset, 0),
                    SELF.#EXPAND(#TEXT(newOffsetField) + &amp;apos;_is_valid&amp;apos;) := wasFound,
                    SELF.#EXPAND(#TEXT(newOffsetField) + &amp;apos;_tz&amp;apos;) := toTimeZoneAbbrev,
                    SELF.#EXPAND(#TEXT(newOffsetField) + &amp;apos;_location&amp;apos;) := %destLocation%,
                    SELF := LEFT
                ),
            LEFT OUTER, LOOKUP
        );
ENDMACRO;

/**
 * Given a dataset that contains a time (in Time_t format), a time zone
 * abbreviation, and an optional time zone location, this function macro
 * appends four new attributes to the dataset:  A new Time_t attribute
 * containing the original time expressed in a different time zone, and three
 * attributes providing information regarding that destination time zone and
 * the validity of the translation.  This could be useful as an ETL step where
 * time data is made common in respect to one particular time zone (e.g. UTC).
 *
 * The actions within this function macro are conceptually similar to
 * AdjustTimeTZ() but applied to an entire dataset, and somewhat more
 * efficiently.
 *
 * Note:  In order for this function macro to execute correctly, the calling
 * code must import the Std library.
 *
 * @param   inFile              The dataset to process; REQUIRED
 * @param   timeField           The attribute within inFile that contains a
 *                              time represented in Time_t format; this is not
 *                              a string; REQUIRED
 * @param   timeZoneAbbrevField The attribute within inFile that contains
 *                              the time zone abbreviation to use for matching;
 *                              the values in this attribute should be in
 *                              uppercase; this is not a string; REQUIRED
 * @param   newTimeField        The attribute that will be appended to inFile
 *                              and will contain the adjusted value of timeField;
 *                              this is not a string; REQUIRED
 * @param   fromLocationField   The attribute within inFile that contains the
 *                              time zone location for the time zone cited by
 *                              timeZoneAbbrevField; this is not a string;
 *                              OPTIONAL, defaults to a null value (indicating
 *                              that there is no time zone location attribute)
 * @param   toTimeZoneAbbrev    The &amp;apos;to&amp;apos; time zone abbreviation to use for all
 *                              calculations, as a string; OPTIONAL, defaults
 *                              to &amp;apos;UTC&amp;apos;
 * @param   toLocation          The name of the location that goes along with
 *                              toTimeZoneAbbrev; if a location is not
 *                              provided or is an empty string, the first
 *                              record matching toTimeZoneAbbrev will be used;
 *                              OPTIONAL, defaults to an empty string
 * @return                      A new dataset with the same record definition
 *                              as inFile but with four new attributes added;
 *                              the new attributes are named based on the name
 *                              given as the newOffsetField attribute:
 *                                  Std.Date.Time_t &amp;lt;newOffsetField&amp;gt;            // Value of timeField expressed in new time zone
 *                                  BOOLEAN         &amp;lt;newOffsetField&amp;gt;_is_valid   // TRUE if &amp;lt;newOffsetField&amp;gt; contains a valid value
 *                                  STRING5         &amp;lt;newOffsetField&amp;gt;_tz         // The value of toTimeZoneAbbrev
 *                                  STRING15        &amp;lt;newOffsetField&amp;gt;_location   // The time zone location for &amp;lt;newOffsetField&amp;gt;_tz
 *                              If &amp;lt;newOffsetField&amp;gt;_is_valid is FALSE then
 *                              &amp;lt;newOffsetField&amp;gt; will have the same value as
 *                              timeField.
 * @see     AppendTZOffset
 *
 * Example:
 *
 *   ds := DATASET
 *      (
 *          [
 *              {120000, &amp;apos;CT&amp;apos;},
 *              {120000, &amp;apos;ET&amp;apos;}
 *          ],
 *          {Std.Date.Time_t time, STRING tz}
 *      );
 *
 *  utcRewriteDS := Std.Date.TimeZone.AppendTZAdjustedTime(ds, time, tz, utc_time);
 *  OUTPUT(utcRewriteDS, NAMED(&amp;apos;utc_result&amp;apos;));
 *
 *  ptRewriteDS := Std.Date.TimeZone.AppendTZAdjustedTime
 *      (
 *          ds,
 *          time,
 *          tz,
 *          pacific_time,
 *          toTimeZoneAbbrev := &amp;apos;PT&amp;apos;,
 *          toLocation := &amp;apos;NORTH AMERICA&amp;apos;
 *      );
 *  OUTPUT(ptRewriteDS, NAMED(&amp;apos;pacific_time_result&amp;apos;));
 */

EXPORT AppendTZAdjustedTime(inFile,
                            timeField,
                            timeZoneAbbrevField,
                            newTimeField,
                            fromLocationField = &amp;apos;&amp;apos;,
                            toTimeZoneAbbrev = &amp;apos;\&amp;apos;UTC\&amp;apos;&amp;apos;,
                            toLocation = &amp;apos;\&amp;apos;\&amp;apos;&amp;apos;) := FUNCTIONMACRO
    // Find the destination time zone information just once
    #UNIQUENAME(destOffsetDS);
    LOCAL %destOffsetDS% := Std.Date.TimeZone.FindTZData(toTimeZoneAbbrev, toLocation);
    #UNIQUENAME(destOffsetFound);
    LOCAL %destOffsetFound% := EXISTS(%destOffsetDS%);
    #UNIQUENAME(destLocation);
    LOCAL %destLocation% := IF(toLocation != &amp;apos;&amp;apos;, toLocation, %destOffsetDS%[1].locations[1]);
    #UNIQUENAME(destOffset);
    LOCAL %destOffset% := %destOffsetDS%[1].secondsOffset;

    RETURN JOIN
        (
            inFile,
            Std.Date.TimeZone.TZ_DATA,
            LEFT.timeZoneAbbrevField = RIGHT.tzAbbrev
                #IF(#TEXT(fromLocationField) != &amp;apos;&amp;apos;)
                    AND LEFT.fromLocationField IN RIGHT.locations
                #END
                AND %destOffsetFound%,
            TRANSFORM
                (
                    {
                        RECORDOF(inFile),
                        Std.Date.Time_t     newTimeField,
                        BOOLEAN             #EXPAND(#TEXT(newTimeField) + &amp;apos;_is_valid&amp;apos;),
                        STRING5             #EXPAND(#TEXT(newTimeField) + &amp;apos;_tz&amp;apos;),
                        STRING15            #EXPAND(#TEXT(newTimeField) + &amp;apos;_location&amp;apos;)
                    },

                    wasFound := RIGHT.tzAbbrev != &amp;apos;&amp;apos;;

                    SELF.newTimeField := IF
                        (
                            wasFound,
                            Std.Date.AdjustTime(LEFT.timeField, second_delta := (%destOffset% - RIGHT.secondsOffset)),
                            LEFT.timeField
                        ),
                    SELF.#EXPAND(#TEXT(newTimeField) + &amp;apos;_is_valid&amp;apos;) := wasFound,
                    SELF.#EXPAND(#TEXT(newTimeField) + &amp;apos;_tz&amp;apos;) := toTimeZoneAbbrev,
                    SELF.#EXPAND(#TEXT(newTimeField) + &amp;apos;_location&amp;apos;) := %destLocation%,
                    SELF := LEFT
                ),
            LEFT OUTER, LOOKUP
        );
ENDMACRO;

END; // TimeZone Module

END; // Date Module&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red.common&quot; name=&quot;red.common&quot;&gt;
  &lt;Attribute key=&quot;constants&quot;
             name=&quot;constants&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\constants.ecl&quot;
             ts=&quot;1615995476046157&quot;&gt;
   import std;
import red;

	EXPORT constants := module
	export digits := &amp;apos;0123456789&amp;apos;;
	
	export line_feed 									:= &amp;apos;\n&amp;apos;;
	export double_quote 							:= &amp;apos;\&amp;quot;&amp;apos;;
	export email_sk_header 						:= &amp;apos;FIELD&amp;apos; + &amp;apos;\t&amp;apos; + &amp;apos;SK_VALUE&amp;apos; + &amp;apos;\t&amp;apos; + &amp;apos;RECORD_COUNT&amp;apos;+ line_feed;
	export email_line_seperator 			:= &amp;apos;*******************************&amp;apos; + line_feed;
	export mbs_pre_fact_revenue 			:= &amp;apos;Check File: red.source.billing.mbs.files_stg.pre_fact_revenue_stg_ds&amp;apos;;
	export mbs_pre_fact_usage_online 	:= &amp;apos;Check File: red.source.billing.mbs.files_stg.pre_fact_usage_online_stg_ds&amp;apos;;
	export mbs_pre_fact_usage_batch 	:= &amp;apos;Check File: red.source.billing.mbs.files_stg.pre_fact_usage_batch_stg_ds&amp;apos;;
	export mbsi_pre_fact 							:= &amp;apos;Check File: red.source.billing.mbsi.files_stg.pre_fact_revenue_stg_ds&amp;apos;;
	export dayton_pre_fact 						:= &amp;apos;Check File: red.source.billing.dayton.files_stg.pre_fact_revenue_usage_stg_ds&amp;apos;;
	export r3_pre_fact_usage					:= &amp;apos;Check File: red.source.billing.r3batch.files_stg.pre_fact_usage_batch_stg_ds&amp;apos;;
	export mbs_pre_fact_royalty 			:= &amp;apos;Check File: red.source.billing.mbs.files_stg.pre_fact_royalty_stg_ds&amp;apos;;
	export ins_royalty_pre_fact 			:= &amp;apos;Check File: red.source.royatly.files.pre_fact_ins_royalty_stg_ds&amp;apos;;
	export ins_royalty_rev_pre_fact		:= &amp;apos;Check File: red.source.royatly.files.pre_fact_ins_royalty_revenue_stg_ds&amp;apos;;
	
/* Email List */	
	export email_mbs_reportcode_issues  := &amp;apos;Joseph.Branson@lexisnexisrisk.com, Kristine.Adkisson@lexisnexisrisk.com, Ryan.Hupp@lexisnexisrisk.com, susan.goss@lexisnexisrisk.com, ken.mccoy@lexisnexisrisk.com, song.thor@lexisnexisrisk.com, lori.medley@lexisnexisrisk.com, Andres.Hovancsak@lexisnexisrisk.com&amp;apos;;
	export InsViz_Support  						:= &amp;apos;InsViz.Support@lexisnexisrisk.com, gopala.rudraraju@lexisnexis.com&amp;apos;;
	export rules_cdf_count_check  := &amp;apos;InsViz.Support@lexisnexisrisk.com,raja.sundarrajan@lexisnexis.com,arjun.mudunuru@lexisnexisrisk.com&amp;apos;;
	export email_coplogic_internetPD_pricing_issues  := &amp;apos;Ryan.Hupp@lexisnexisrisk.com, kenneth.l.smith@lexisnexisrisk.com, arjun.mudunuru@lexisnexisrisk.com, Amy.Christian@lexisnexisrisk.com,ProcurementServicesPM@lexisnexis.com&amp;apos;;
	export email_fido_core_team 			:= &amp;apos;FIDOCoreTeam@risk.lexisnexis.com&amp;apos;;
	export email_address_fido_issues 	:= &amp;apos;FIDO@risk.lexisnexis.com&amp;apos;;
	export alert_zero_sub_product_id_email_list 	:= &amp;apos;risk.fulfillment@lexisnexis.com,FIDOCoreTeam@risk.lexisnexis.com&amp;apos;;
	export attrition_email_list				:= &amp;apos;gopala.rudraraju@lexisnexis.com, jacob.pellock@lexisnexis.com, Amanda.Crawford@lexisnexis.com, robert.fredericks@lexisnexis.com, stephen.rosser@lexisnexis.com&amp;apos;;
	export appriss_oop_rev_adj_email_list 	:= &amp;apos;rba-acct-revenue@lexisnexisrisk.com, rene.gibson@lexisnexisrisk.com&amp;apos;;
	export govt_tier_eloqua_email_list 	:= &amp;apos;gopala.rudraraju@lexisnexisrisk.com, ed.dierker@lexisnexisrisk.com, jacari.witchard@lexisnexisrisk.com&amp;apos;;
	export mbs_dashboard_email_list 	:= &amp;apos;nyruthya.sanandan@lexisnexisrisk.com&amp;apos;;
	export govt_segmentation_email_list 	:= &amp;apos;Nyruthya.Sanandan@lexisnexisrisk.com, Qiuying.Li@lexisnexisrisk.com, stephen.rosser@lexisnexisrisk.com, Hua.Xia@lexisnexisrisk.com, Jyothi.Karra@lexisnexisrisk.com&amp;apos;;
	
	
	export email_smtp_server 	:= &amp;apos;appmail.risk.regn.net&amp;apos;;
	// Changes in Dali changes all the references in the code to ncf_dali and fcra_dali to new IP in the field ins_dali_dnsname.
	export ins_dali_dnsname             :=  &amp;apos;alpha_prod_thor_dali.risk.regn.net&amp;apos;;
  export ins_qc_dali        := &amp;apos;alpha_qc_thor_dali.risk.regn.net&amp;apos;;
  export ins_dev_dali       := &amp;apos;alpha_dev_thor_dali.risk.regn.net&amp;apos;;
	export ncf_dali 					:= &amp;apos;10.194.12.1:7070&amp;apos;;
	export fcra_dali 					:= &amp;apos;10.194.12.1:7070&amp;apos;;
	export forac_dali					:=	&amp;apos;10.194.10.1:7070&amp;apos;;
	export boca_dataland_dali := &amp;apos;10.173.44.105:7070&amp;apos;;
	export boca_prod_dali     := &amp;apos;10.173.44.105:7070&amp;apos;;
  export hca_prod_dali      := &amp;apos;10.194.42.30:7070&amp;apos;;  // Healthcare Alpha Data Builds
  export hcb_prod_dali      := &amp;apos;10.173.75.30:7070&amp;apos;;  // Healthcare Boca Delivery
  export hc_dev_dali        := &amp;apos;10.173.70.52:7070&amp;apos;;  // Healthcare Dev
  export vault_dali         := &amp;apos;alpha_vault_thor_dali.risk.regn.net&amp;apos;;
  export uk_dev_dali        := &amp;apos;10.193.64.11:7070&amp;apos;;
  export uk_prod_dali       := &amp;apos;10.193.68.11:7070&amp;apos;;
	export fido_dev_dali 			:= &amp;apos;10.194.169.1:7070&amp;apos;;
	export fido_prod_dali 		:= &amp;apos;10.194.93.1:7070&amp;apos;;
	export fido_dr_ip 			:= &amp;apos;http://10.173.93.142:8010&amp;apos;;
	export fido_dev_ip 				:= &amp;apos;http://10.194.169.2:8010&amp;apos;;
	export fido_prod_ip 			:= &amp;apos;http://10.194.93.3:8010&amp;apos;;	

	export fido_ip			 := map(red.common.stored_env = &amp;apos;dev&amp;apos; =&amp;gt; fido_dev_ip, 
										red.common.stored_env = &amp;apos;dr&amp;apos; =&amp;gt; fido_dr_ip,
										fido_prod_ip
									);


	export foreign 						:= &amp;apos;~foreign&amp;apos;;

	thor_group 	:= std.system.Thorlib.group();
	export hpcc_env 		:= map(thor_group = &amp;apos;thor40_83&amp;apos; =&amp;gt; &amp;apos;prod&amp;apos;,
															thor_group = &amp;apos;thor_fido_dev&amp;apos; =&amp;gt; &amp;apos;dev&amp;apos;,
															thor_group = &amp;apos;mythor&amp;apos; =&amp;gt; &amp;apos;dev&amp;apos;,
															&amp;apos;unknown&amp;apos;);
	EXPORT super_file_generations := DATASET([
			{&amp;apos;dim_customer_account&amp;apos;, 4},
			{&amp;apos;fact_capz_allocation_snapshot&amp;apos;, 4}
		], {STRING file_name, integer num_generations});

	EXPORT dims_have_grand_gens_for_rolling_year := [&amp;apos;fact_revenue&amp;apos;,&amp;apos;fact_usage&amp;apos;];
end;&amp;#13;&amp;#10;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_env&quot;
             name=&quot;stored_env&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_env.ecl&quot;
             ts=&quot;1615993079012713&quot;&gt;
   export string4 STORED_ENV := &amp;apos;prod&amp;apos; : stored(&amp;apos;env&amp;apos;);&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_adhoc_despray_folder&quot;
             name=&quot;stored_adhoc_despray_folder&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_adhoc_despray_folder.ecl&quot;
             ts=&quot;1615993079002738&quot;&gt;
   import red;
export STRING stored_adhoc_despray_folder := &amp;apos;&amp;apos; : stored (&amp;apos;adhoc_despray&amp;apos;); // this will be a folder on the Landingzone that is under \\dm folder.
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_outbound_drive&quot;
             name=&quot;stored_outbound_drive&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_outbound_drive.ecl&quot;
             ts=&quot;1615993079025677&quot;&gt;
   export string4 stored_outbound_drive := &amp;apos;D&amp;apos; : stored(&amp;apos;outbound_drive&amp;apos;);&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_build_hostname&quot;
             name=&quot;stored_build_hostname&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_build_hostname.ecl&quot;
             ts=&quot;1615993079007724&quot;&gt;
   EXPORT stored_build_hostname :=  &amp;apos;&amp;apos; : stored(&amp;apos;hostname&amp;apos;);
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_build_despray_hostname&quot;
             name=&quot;stored_build_despray_hostname&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_build_despray_hostname.ecl&quot;
             ts=&quot;1615995476055132&quot;&gt;
   EXPORT stored_build_despray_hostname :=  &amp;apos;&amp;apos; : stored(&amp;apos;despray_host_name&amp;apos;);
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;stored_inbound_drive&quot;
             name=&quot;stored_inbound_drive&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\stored_inbound_drive.ecl&quot;
             ts=&quot;1615993079016701&quot;&gt;
   &amp;#13;&amp;#10;export string4 stored_inbound_drive := &amp;apos;D&amp;apos; : stored(&amp;apos;inbound_drive&amp;apos;);&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red.common.util&quot; name=&quot;red.common.util&quot;&gt;
  &lt;Attribute key=&quot;fn_promote_ds&quot;
             name=&quot;fn_promote_ds&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\util\fn_promote_ds.ecl&quot;
             ts=&quot;1615993079064573&quot;&gt;
   import red.dm;
import * from std;

import red.common.spray;

export fn_Promote_ds(Dataset dset, String Path, String FileName, boolean dim = false, string delim =&amp;apos;\t&amp;apos;, boolean heading = false, string despray_prefix = &amp;apos;&amp;apos;) := FUNCTION
	start_pos								:= std.str.find(FileName,&amp;apos;::&amp;apos;,2);
	FileName_csv		 				:= if(start_pos = 0, 
																FileName, 
																FileName[start_pos + 2..] +&amp;apos;_&amp;apos; + FileName[..4] + FileName[7..8]);
																
	fileDate 								:= (string)std.date.today()  : stored(&amp;apos;filedate&amp;apos;);
	FileNameNewLogical 			:= Path + &amp;apos;::&amp;apos; + fileDate+ &amp;apos;::&amp;apos;+ FileName +&amp;apos;_&amp;apos; + workunit;		
	despray_prefix_str			:= if (length(trim(despray_prefix)) &amp;gt; 0, trim(despray_prefix) + &amp;apos;_&amp;apos;, &amp;apos;&amp;apos;);
	FileNameNewLogical_csv 	:= dm.dim_despray_prefix + &amp;apos;::&amp;apos;+ trim(despray_prefix_str) + FileName_csv;		
	
	// force independent on dims/facts so graphs aren&amp;apos;t duplicated for each output
	indy_dset								:= dset : independent;
	data_for_file						:= if(dim, indy_dset, dset);
	
	SaveNewFile_thor 				:=	output(data_for_file, , FileNameNewLogical, thor, compressed);
	
	SaveNewFile_csv := 
		if(heading = false,
			output(data_for_file, , FileNameNewLogical_csv, CSV(heading(0), SEPARATOR(delim), TERMINATOR(&amp;apos;\n&amp;apos;), MAXLENGTH(10240)), overwrite, compressed),
			output(data_for_file, , FileNameNewLogical_csv, CSV(HEADING(SINGLE), SEPARATOR(delim), TERMINATOR(&amp;apos;\n&amp;apos;), MAXLENGTH(10240)), overwrite, compressed));

	
	Promote_File 						:= Spray.fn_promotefile(Path, fileDate, FileName, FileName);
	
	Return 	If(dim, 
							Sequential(Parallel(SaveNewFile_thor, SaveNewFile_csv), Promote_File), // Apllies for dim&amp;apos;s and fact&amp;apos;s
							Sequential(SaveNewFile_thor, Promote_File)); 								 					// Apllies for spray, stg etc.
end;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;getnumgenerations&quot;
             name=&quot;getNumGenerations&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\util\getNumGenerations.ecl&quot;
             ts=&quot;1615993079074546&quot;&gt;
   /****
    *   this function returns the no_of_generations configured for the dim file in constants, returns 2 
    *   when the dim_name is not configured
    *   input   file_name       name of the dim
    *   output  integer         value of gens_count configured for dim, default is 2
**/

EXPORT getNumGenerations(String file_name) := FUNCTION
IMPORT STD, RED;

    just_name := std.str.reverse(STD.str.splitwords(std.str.reverse(file_name), &amp;apos;::&amp;apos;)[1]);

    lastyeardate := std.date.adjustdate(std.date.today(), month_delta := -13);

    dmNameYyyymm := std.str.findreplace(file_name[1..8],&amp;apos;:&amp;apos;, &amp;apos;&amp;apos;);

    RETURN  IF(Exists(red.common.constants.super_file_generations(file_name = just_name)) = TRUE, 
                red.common.constants.super_file_generations(file_name = just_name)[1].num_generations,
                IF(just_name IN red.common.constants.dims_have_grand_gens_for_rolling_year,
                    if(lastyeardate &amp;lt; ((unsigned4)(dmNameYyyymm +&amp;apos;01&amp;apos;)),
                        4,
                        2
                    ),
                2)
    );
END;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module flags=&quot;5&quot;
         fullname=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\plugins\fileservices.dll&quot;
         key=&quot;lib_fileservices&quot;
         name=&quot;lib_fileservices&quot;
         plugin=&quot;fileservices.dll&quot;
         sourcePath=&quot;lib_fileservices&quot;
         ts=&quot;1616676430000000&quot;
         version=&quot;FILESERVICES 2.1.4&quot;&gt;
  &lt;Text&gt;export FsFilenameRecord := record string name{maxlength(1023)}; integer8 size; string19 modified; end; 
export FsLogicalFileName := string{maxlength(255)}; 
export FsLogicalFileNameRecord := record FsLogicalFileName name; end; 
export FsLogicalFileInfoRecord := record(FsLogicalFileNameRecord) boolean superfile; integer8 size; integer8 rowcount; string19 modified; string owner{maxlength(255)}; string cluster{maxlength(255)}; end; 
export FsLogicalSuperSubRecord := record string supername{maxlength(255)}; string subname{maxlength(255)}; end; 
export FsFileRelationshipRecord := record  string primaryfile   {maxlength(1023)}; string secondaryfile {maxlength(1023)}; string primaryflds   {maxlength(1023)}; string secondaryflds {maxlength(1023)}; string kind {maxlength(16)}; string cardinality   {maxlength(16)}; boolean payload; string description   {maxlength(1023)}; end; 
export integer4 RECFMV_RECSIZE := -2; // special value for SprayFixed record size 
export integer4 RECFMVB_RECSIZE := -1; // special value for SprayFixed record size 
export integer4 PREFIX_VARIABLE_RECSIZE := -3; // special value for SprayFixed record size 
export integer4 PREFIX_VARIABLE_BIGENDIAN_RECSIZE := -4; // special value for SprayFixed record size 
export FsDropZone := string; 
export FsDropZoneRecord := record FsDropZone dropzone; end; 
export FileServices := SERVICE : time
  boolean FileExists(const varstring lfn, boolean physical=false) : c,context,entrypoint=&amp;apos;fsFileExists&amp;apos;; 
  DeleteLogicalFile(const varstring lfn,boolean ifexists=false) : c,action,context,entrypoint=&amp;apos;fsDeleteLogicalFile&amp;apos;; 
  SetReadOnly(const varstring lfn, boolean ro) : c,action,context,entrypoint=&amp;apos;fsSetReadOnly&amp;apos;; 
  RenameLogicalFile(const varstring oldname, const varstring newname, boolean allowoverwrite=false) : c,action,context,entrypoint=&amp;apos;fsRenameLogicalFile_v2&amp;apos;; 
  varstring GetBuildInfo() : c,pure,entrypoint=&amp;apos;fsGetBuildInfo&amp;apos;;
  SendEmail(const varstring to, const varstring subject, const varstring body, const varstring mailServer=GETENV(&amp;apos;SMTPserver&amp;apos;), unsigned4 port=(unsigned4) GETENV(&amp;apos;SMTPport&amp;apos;, &amp;apos;25&amp;apos;), const varstring sender=GETENV(&amp;apos;emailSenderAddress&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsSendEmail&amp;apos;; 
  SendEmailAttachText(const varstring to, const varstring subject, const varstring body, const varstring attachment, const varstring mimeType, const varstring attachmentName, const varstring mailServer=GETENV(&amp;apos;SMTPserver&amp;apos;), unsigned4 port=(unsigned4) GETENV(&amp;apos;SMTPport&amp;apos;, &amp;apos;25&amp;apos;), const varstring sender=GETENV(&amp;apos;emailSenderAddress&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsSendEmailAttachText&amp;apos;; 
  SendEmailAttachData(const varstring to, const varstring subject, const varstring body, const data attachment, const varstring mimeType, const varstring attachmentName, const varstring mailServer=GETENV(&amp;apos;SMTPserver&amp;apos;), unsigned4 port=(unsigned4) GETENV(&amp;apos;SMTPport&amp;apos;, &amp;apos;25&amp;apos;), const varstring sender=GETENV(&amp;apos;emailSenderAddress&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsSendEmailAttachData&amp;apos;; 
  varstring CmdProcess(const varstring prog, const varstring src) : c,action,entrypoint=&amp;apos;fsCmdProcess&amp;apos;; 
  string CmdProcess2(const varstring prog, const string src) : c,action,entrypoint=&amp;apos;fsCmdProcess2&amp;apos;; 
  SprayFixed(const varstring sourceIP, const varstring sourcePath, integer4 recordSize, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false,boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsSprayFixed_v4&amp;apos;; 
  SprayVariable(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, const varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, const varstring sourceCsvQuote=&amp;apos;&amp;quot;&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false,boolean compress=false,const varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=false, boolean recordStructurePresent=false, boolean quotedTerminator=true, const varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsSprayVariable_v8&amp;apos;; 
  SprayXml(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceRowTag, const varstring sourceEncoding=&amp;apos;utf8&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false,boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsSprayXml_v4&amp;apos;; 
  SprayJson(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceRowPath=&amp;apos;/&amp;apos;, const varstring sourceEncoding=&amp;apos;utf8&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false,boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) : c,action,context,entrypoint=&amp;apos;fsSprayJson&amp;apos;; 
  Despray(const varstring logicalName, const varstring destinationIP, const varstring destinationPath, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false) : c,action,context,entrypoint=&amp;apos;fsDespray&amp;apos;; 
  Copy(const varstring sourceLogicalName, const varstring destinationGroup, const varstring destinationLogicalName, const varstring sourceDali=&amp;apos;&amp;apos;, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean asSuperfile=false, boolean compress=false, boolean forcePush=false, integer4 transferBufferSize=0, boolean preserveCompression=true, boolean noSplit=false, integer4 expireDays=-1) : c,action,context,entrypoint=&amp;apos;fsCopy_v3&amp;apos;; 
  Replicate(const varstring logicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsReplicate&amp;apos;; 
  CreateSuperFile(const varstring lsuperfn, boolean sequentialparts=false,boolean ifdoesnotexist=false) : c,action,context,entrypoint=&amp;apos;fsCreateSuperFile&amp;apos;; 
  boolean SuperFileExists(const varstring lsuperfn) : c,context,entrypoint=&amp;apos;fsSuperFileExists&amp;apos;; 
  DeleteSuperFile(const varstring lsuperfn,boolean deletesub=false) : c,action,context,entrypoint=&amp;apos;fsDeleteSuperFile&amp;apos;; 
  unsigned4 GetSuperFileSubCount(const varstring lsuperfn) : c,context,entrypoint=&amp;apos;fsGetSuperFileSubCount&amp;apos;; 
  varstring GetSuperFileSubName(const varstring lsuperfn,unsigned4 filenum,boolean abspath=false) : c,context,entrypoint=&amp;apos;fsGetSuperFileSubName&amp;apos;; 
  unsigned4 FindSuperFileSubName(const varstring lsuperfn,const varstring lfn) : c,context,entrypoint=&amp;apos;fsFindSuperFileSubName&amp;apos;; 
  StartSuperFileTransaction() : c,action,globalcontext,entrypoint=&amp;apos;fsStartSuperFileTransaction&amp;apos;; 
  AddSuperFile(const varstring lsuperfn,const varstring lfn,unsigned4 atpos=0,boolean addcontents=false, boolean strict=false) : c,action,globalcontext,entrypoint=&amp;apos;fsAddSuperFile&amp;apos;; 
  RemoveSuperFile(const varstring lsuperfn,const varstring lfn,boolean del=false,boolean remcontents=false) : c,action,globalcontext,entrypoint=&amp;apos;fsRemoveSuperFile&amp;apos;; 
  ClearSuperFile(const varstring lsuperfn,boolean del=false) : c,action,globalcontext,entrypoint=&amp;apos;fsClearSuperFile&amp;apos;; 
  RemoveOwnedSubFiles(const varstring lsuperfn,boolean del=false) : c,action,globalcontext,entrypoint=&amp;apos;fsRemoveOwnedSubFiles&amp;apos;; 
  DeleteOwnedSubFiles(const varstring lsuperfn) : c,action,globalcontext,entrypoint=&amp;apos;fsDeleteOwnedSubFiles&amp;apos;; // Obsolete, use RemoveOwnedSubFiles
  SwapSuperFile(const varstring lsuperfn1,const varstring lsuperfn2) : c,action,globalcontext,entrypoint=&amp;apos;fsSwapSuperFile&amp;apos;; 
  ReplaceSuperFile(const varstring lsuperfn,const varstring lfn,const varstring bylfn) : c,action,globalcontext,entrypoint=&amp;apos;fsReplaceSuperFile&amp;apos;; 
  FinishSuperFileTransaction(boolean rollback=false) : c,action,globalcontext,entrypoint=&amp;apos;fsFinishSuperFileTransaction&amp;apos;; 
  varstring ForeignLogicalFileName(const varstring name, const varstring foreigndali=&amp;apos;&amp;apos;, boolean abspath=false, boolean omitClusterPrefix=false) : c,context,entrypoint=&amp;apos;fsForeignLogicalFileName_v2&amp;apos;; 
  varstring WaitDfuWorkunit(const varstring wuid, integer4 timeOut=-1,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,globalcontext,entrypoint=&amp;apos;fsWaitDfuWorkunit&amp;apos;; 
  AbortDfuWorkunit(const varstring wuid,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,globalcontext,entrypoint=&amp;apos;fsAbortDfuWorkunit&amp;apos;; 
  MonitorLogicalFileName(const varstring event_name, const varstring name, integer4 shotcount=1,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsMonitorLogicalFileName&amp;apos;; 
  MonitorFile(const varstring event_name, const varstring ip, const varstring filename, boolean subdirs=false, integer4 shotcount=1,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsMonitorFile&amp;apos;; 
  varstring fSprayFixed(const varstring sourceIP, const varstring sourcePath, integer4 recordSize, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsfSprayFixed_v4&amp;apos;; 
  varstring fSprayVariable(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceCsvSeparate=&amp;apos;\\,&amp;apos;, const varstring sourceCsvTerminate=&amp;apos;\\n,\\r\\n&amp;apos;, const varstring sourceCsvQuote=&amp;apos;&amp;quot;&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean compress=false,const varstring sourceCsvEscape=&amp;apos;&amp;apos;, boolean failIfNoSourceFile=false, boolean recordStructurePresent=false, boolean quotedTerminator=true, varstring encoding=&amp;apos;ascii&amp;apos;, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsfSprayVariable_v8&amp;apos;; 
  varstring fSprayXml(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceRowTag, const varstring sourceEncoding=&amp;apos;utf8&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false) : c,action,context,entrypoint=&amp;apos;fsfSprayXml_v4&amp;apos;; 
  varstring fSprayJson(const varstring sourceIP, const varstring sourcePath, integer4 sourceMaxRecordSize=8192, const varstring sourceRowPath=&amp;apos;/&amp;apos;, const varstring sourceEncoding=&amp;apos;utf8&amp;apos;, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean compress=false, boolean failIfNoSourceFile=false, integer4 expireDays=-1, const varstring dfuServerQueue=&amp;apos;&amp;apos;, boolean noSplit=false, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;) : c,action,context,entrypoint=&amp;apos;fsfSprayJson&amp;apos;; 
  varstring fDespray(const varstring logicalName, const varstring destinationIP, const varstring destinationPath, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false) : c,action,context,entrypoint=&amp;apos;fsfDespray&amp;apos;; 
  varstring fCopy(const varstring sourceLogicalName, const varstring destinationGroup, const varstring destinationLogicalName, const varstring sourceDali=&amp;apos;&amp;apos;, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;), integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean asSuperfile=false, boolean compress=false, boolean forcePush=false, integer4 transferBufferSize=0, boolean preserveCompression=true, boolean noSplit=false, integer4 expireDays=-1) : c,action,context,entrypoint=&amp;apos;fsfCopy_v3&amp;apos;; 
  varstring fMonitorLogicalFileName(const varstring event_name, const varstring name, integer4 shotcount=1,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsfMonitorLogicalFileName&amp;apos;; 
  varstring fMonitorFile(const varstring event_name, const varstring ip, const varstring filename, boolean subdirs=false, integer4 shotcount=1,const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsfMonitorFile&amp;apos;; 
  varstring fReplicate(const varstring logicalName, integer4 timeOut=-1, const varstring espServerIpPort=GETENV(&amp;apos;ws_fs_server&amp;apos;)) : c,action,context,entrypoint=&amp;apos;fsfReplicate&amp;apos;; 
  varstring GetFileDescription(const varstring lfn) : c,context,entrypoint=&amp;apos;fsGetFileDescription&amp;apos;; 
  SetFileDescription(const varstring lfn,const varstring val) : c,action,context,entrypoint=&amp;apos;fsSetFileDescription&amp;apos;; 
  dataset(FsFilenameRecord) RemoteDirectory(const varstring machineIP,const varstring dir,const varstring mask=&amp;apos;*&amp;apos;,boolean sub=false) : c,entrypoint=&amp;apos;fsRemoteDirectory&amp;apos;;
  dataset(FsLogicalFileInfoRecord) LogicalFileList(const varstring namepattern=&amp;apos;*&amp;apos;,boolean includenormal=true,boolean includesuper=false,boolean unknownszero=false,const varstring foreigndali=&amp;apos;&amp;apos;) : c,context,entrypoint=&amp;apos;fsLogicalFileList&amp;apos;;
  dataset(FsLogicalFileNameRecord) SuperFileContents(const varstring lsuperfn,boolean recurse=false) : c,context,entrypoint=&amp;apos;fsSuperFileContents&amp;apos;;
  dataset(FsLogicalFileNameRecord) LogicalFileSuperOwners(const varstring lfn) : c,context,entrypoint=&amp;apos;fsLogicalFileSuperOwners&amp;apos;;
  varstring ExternalLogicalFileName(const varstring location, const varstring path,boolean abspath=true) : c,entrypoint=&amp;apos;fsExternalLogicalFileName&amp;apos;; 
  integer4 CompareFiles(const varstring lfn1, const varstring lfn2,boolean logicalonly=true,boolean usecrcs=false) : c,context,entrypoint=&amp;apos;fsCompareFiles&amp;apos;; 
  varstring VerifyFile(const varstring lfn, boolean usecrcs) : c,action,context,entrypoint=&amp;apos;fsVerifyFile&amp;apos;; 
  RemotePull( const varstring remoteEspFsURL, const varstring sourceLogicalName, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean asSuperfile=false,boolean forcePush=false, integer4 transferBufferSize=0,boolean wrap=false,boolean compress=false, boolean noSplit=false, integer4 expireDays=-1, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;): c,action,context,entrypoint=&amp;apos;fsRemotePull_v3&amp;apos;; 
  varstring fRemotePull( const varstring remoteEspFsURL, const varstring sourceLogicalName, const varstring destinationGroup, const varstring destinationLogicalName, integer4 timeOut=-1, integer4 maxConnections=-1, boolean allowoverwrite=false, boolean replicate=false, boolean asSuperfile=false,boolean forcePush=false, integer4 transferBufferSize=0,boolean wrap=false,boolean compress=false, boolean noSplit=false, integer4 expireDays=-1, const varstring username = &amp;apos;&amp;apos;, const varstring userPw = &amp;apos;&amp;apos;): c,action,context,entrypoint=&amp;apos;fsfRemotePull_v3&amp;apos;; 
  dataset(FsLogicalSuperSubRecord) LogicalFileSuperSubList() : c,context,entrypoint=&amp;apos;fsLogicalFileSuperSubList&amp;apos;;
  PromoteSuperFileList(const set of varstring lsuperfns,const varstring addhead=&amp;apos;&amp;apos;,boolean deltail=false,boolean createonlyonesuperfile=false,boolean reverse=false) : c,action,context,entrypoint=&amp;apos;fsPromoteSuperFileList&amp;apos;; 
  varstring fPromoteSuperFileList(const set of varstring lsuperfns,const varstring addhead=&amp;apos;&amp;apos;, boolean deltail=false,boolean createonlyonesuperfile=false, boolean reverse=false) : c,action,context,entrypoint=&amp;apos;fsfPromoteSuperFileList&amp;apos;; 
  unsigned8 getUniqueInteger(const varstring foreigndali=&amp;apos;&amp;apos;) : c,context,entrypoint=&amp;apos;fsGetUniqueInteger&amp;apos;; 
  AddFileRelationship(const varstring primary, const varstring secondary, const varstring primaryflds,  const varstring secondaryflds, const varstring kind=&amp;apos;link&amp;apos;, const varstring cardinality, boolean payload, const varstring description=&amp;apos;&amp;apos;) : c,action,context,entrypoint=&amp;apos;fsAddFileRelationship&amp;apos;; 
  dataset(FsFileRelationshipRecord) FileRelationshipList(const varstring primary, const varstring secondary, const varstring primflds=&amp;apos;&amp;apos;, const varstring secondaryflds=&amp;apos;&amp;apos;,  const varstring kind=&amp;apos;link&amp;apos;) : c,action,context,entrypoint=&amp;apos;fsFileRelationshipList&amp;apos;; 
  RemoveFileRelationship(const varstring primary,  const varstring secondary, const varstring primaryflds=&amp;apos;&amp;apos;, const varstring secondaryflds=&amp;apos;&amp;apos;,  const varstring kind=&amp;apos;link&amp;apos;) : c,action,context,entrypoint=&amp;apos;fsRemoveFileRelationship&amp;apos;; 
  varstring GetColumnMapping( const varstring LogicalFileName): c,context,entrypoint=&amp;apos;fsfGetColumnMapping&amp;apos;; 
  SetColumnMapping( const varstring LogicalFileName, const varstring mapping): c,context,entrypoint=&amp;apos;fsSetColumnMapping&amp;apos;; 
  varstring RfsQuery( const varstring server, const varstring query): c,entrypoint=&amp;apos;fsfRfsQuery&amp;apos;; 
  RfsAction( const varstring server, const varstring query): c,entrypoint=&amp;apos;fsRfsAction&amp;apos;; 
  varstring GetHostName( const varstring ipaddress ): c,entrypoint=&amp;apos;fsfGetHostName&amp;apos;; 
  varstring ResolveHostName( const varstring hostname ): c,entrypoint=&amp;apos;fsfResolveHostName&amp;apos;; 
  MoveExternalFile(const varstring location, const varstring frompath, const varstring topath): c,action,context,entrypoint=&amp;apos;fsMoveExternalFile&amp;apos;; 
  DeleteExternalFile(const varstring location, const varstring path): c,action,context,entrypoint=&amp;apos;fsDeleteExternalFile&amp;apos;; 
  CreateExternalDirectory(const varstring location, const varstring path): c,action,context,entrypoint=&amp;apos;fsCreateExternalDirectory&amp;apos;; 
  varstring GetLogicalFileAttribute(const varstring lfn,const varstring attrname) : c,context,entrypoint=&amp;apos;fsfGetLogicalFileAttribute&amp;apos;; 
  ProtectLogicalFile(const varstring lfn,boolean set=true) : c,context,entrypoint=&amp;apos;fsProtectLogicalFile&amp;apos;; 
  DfuPlusExec(const varstring cmdline) : c,context,entrypoint=&amp;apos;fsDfuPlusExec&amp;apos;; 
  varstring GetEspURL(const varstring username = &amp;apos;&amp;apos;, const varstring userPW = &amp;apos;&amp;apos;) : c,once,entrypoint=&amp;apos;fsGetEspURL&amp;apos;; 
  varstring GetDefaultDropZone() : c,once,entrypoint=&amp;apos;fsGetDefaultDropZone&amp;apos;; 
  dataset(FsDropZoneRecord) GetDropZones() : c,context,entrypoint=&amp;apos;fsGetDropZones&amp;apos;; 
END;&lt;/Text&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red.common.validate&quot; name=&quot;red.common.validate&quot;&gt;
  &lt;Attribute key=&quot;mac_dup_sk_validate&quot;
             name=&quot;mac_dup_sk_validate&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\validate\mac_dup_sk_validate.ecl&quot;
             ts=&quot;1615993079106460&quot;&gt;
   EXPORT mac_dup_sk_validate(in_Data, field_sk) := functionmacro
	
	tab := table(in_Data, {field_sk, is_int := (integer)field_sk, cnt := count(group)}, field_sk);

	tab_dup_cnt 	:= tab(cnt &amp;gt; 1);
	has_duplicate := max(tab_dup_cnt, cnt) &amp;gt; 1;
	
	integer_zero_sk	:= table(tab(is_int = 0), {field_sk}, field_sk);
	has_zero_non_int_sk	:= exists(integer_zero_sk) ;

	crash_dup_sk := fail(&amp;apos;Duplicates found in \t&amp;apos; + &amp;apos;\&amp;apos;&amp;apos; + #text(field_sk)+ &amp;apos;\&amp;apos;\t&amp;apos; +
											&amp;apos;[&amp;apos; +  tab_dup_cnt[1].field_sk + 
												if(tab_dup_cnt[2].field_sk = 0, &amp;apos;&amp;apos;, &amp;apos;,\t&amp;apos; +(string)tab_dup_cnt[2].field_sk) +  
												if(tab_dup_cnt[3].field_sk = 0, &amp;apos;&amp;apos;, &amp;apos;,\t&amp;apos; +(string)tab_dup_cnt[3].field_sk) + 
												if(count(tab_dup_cnt) &amp;gt; 3, &amp;apos;...&amp;apos;, &amp;apos;\&amp;apos;&amp;apos;) + &amp;apos;]&amp;apos;);

	crash_zero_non_int_sk := fail(&amp;apos;Non Integer or Zero sk found in \t&amp;apos; + &amp;apos;\&amp;apos;&amp;apos; + #text(field_sk)+ &amp;apos;\&amp;apos;\t&amp;apos; +
															&amp;apos;[&amp;apos; +  integer_zero_sk[1].field_sk + 
																if(integer_zero_sk[2].field_sk = 0, &amp;apos;&amp;apos;, &amp;apos;,\t&amp;apos; +(string)integer_zero_sk[2].field_sk) +  
																if(integer_zero_sk[3].field_sk = 0, &amp;apos;&amp;apos;, &amp;apos;,\t&amp;apos; +(string)integer_zero_sk[3].field_sk) + 
																if(count(integer_zero_sk) &amp;gt; 3, &amp;apos;...&amp;apos;, &amp;apos;\&amp;apos;&amp;apos;) + &amp;apos;]&amp;apos;);


	ok 		:= output(&amp;apos;No Duplicates/Non Integer/Zero values found in \t&amp;apos; + &amp;apos;\&amp;apos;&amp;apos; + #text(field_sk)+ &amp;apos;\&amp;apos;\t&amp;apos;);
	
	return map(has_duplicate =&amp;gt; crash_dup_sk,
							has_zero_non_int_sk =&amp;gt; crash_zero_non_int_sk,
							ok);
endmacro;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;red.common.spray&quot; name=&quot;red.common.spray&quot;&gt;
  &lt;Attribute key=&quot;fn_promotefile&quot;
             name=&quot;fn_promotefile&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\spray\fn_promotefile.ecl&quot;
             ts=&quot;1615993078996754&quot;&gt;
   IMPORT lib_fileservices, RED;
	EXPORT FN_PromoteFile(String Path, String filedate, String FileName, String SuperFileName) := FUNCTION
		
		file_date 								:= if(filedate &amp;lt;&amp;gt; &amp;apos;&amp;apos;,filedate + &amp;apos;::&amp;apos;, filedate );
		FileNameNewLogical 				:= Path + &amp;apos;::&amp;apos; + file_date +  FileName +&amp;apos;_&amp;apos; + workunit;
		FilePath									:= Path + &amp;apos;::&amp;apos; + SuperFileName;
		FileNameFather 						:= Path + &amp;apos;::&amp;apos; + &amp;apos;father&amp;apos; + &amp;apos;::&amp;apos;+ SuperFileName;
		FileNameGrandFather 			:= Path + &amp;apos;::&amp;apos; + &amp;apos;grandfather&amp;apos; + &amp;apos;::&amp;apos;+ SuperFileName;
		FileNameGreatGrandFather	:= Path + &amp;apos;::&amp;apos; + &amp;apos;greatgrandfather&amp;apos; + &amp;apos;::&amp;apos;+ SuperFileName;
		// set as 4 for non-dims, for dims number is based on the configuration at red.common.constants
		num_generations := IF(PATH NOT IN [red.dm.fact_file_prefix, red.dm.dim_file_prefix], 4, RED.common.util.getNumGenerations(fileName));

		PromotionList := CASE(num_generations,
			4 =&amp;gt; [FilePath,FileNameFather,FileNameGrandFather,FileNameGreatGrandFather],
			3 =&amp;gt; [FilePath,FileNameFather,FileNameGrandFather],
			[FilePath,FileNameFather] 
		);
		
		Return FileServices.PromoteSuperFileList(PromotionList, FileNameNewLogical, true);
	END;
  &lt;/Attribute&gt;
  &lt;Attribute key=&quot;spray_constants&quot;
             name=&quot;Spray_Constants&quot;
             sourcePath=&quot;C:\Users\slushejx\Git\FIDO\red\common\spray\spray_constants.ecl&quot;
             ts=&quot;1617240375005460&quot;&gt;
   import RED, STD;

EXPORT Spray_Constants(STRING sFileName		 	= &amp;apos;&amp;apos;,
												STRING build_date 	= &amp;apos;&amp;apos;,
												STRING SourceName 	= &amp;apos;&amp;apos;,
												STRING Frequency 		= &amp;apos;&amp;apos;,  
												STRING File_Date 		= &amp;apos;&amp;apos;, 
												STRING SrcQuote 		= &amp;apos;&amp;quot;&amp;apos;,
												STRING SrcSeparator = &amp;apos;\t&amp;apos; ) := MODULE

  EXPORT sProdID           := &amp;apos;RED&amp;apos;;
	EXPORT wuid              := WorkUnit;
	EXPORT FileSeparator		 := &amp;apos;\\&amp;apos;;
	EXPORT FileNameCov			 := &amp;apos;**&amp;apos;;
	EXPORT RecordTerminator  := [&amp;apos;\n&amp;apos;,&amp;apos;\r\n&amp;apos;,&amp;apos;\n\r&amp;apos;];
	EXPORT RecordQuote		 	 := SrcQuote;
	EXPORT FieldSeparator    := SrcSeparator;

	EXPORT devlandingzone    := &amp;apos;10.48.76.98&amp;apos;;

	EXPORT dev2landingzone    := &amp;apos;10.195.90.4&amp;apos;; // alawpsip002

	EXPORT prodLandingZone	 := CASE(STD.STR.ToLowerCase(RED.common.stored_build_hostname),
									&amp;apos;alawpfidolz301&amp;apos; =&amp;gt; &amp;apos;10.194.83.41&amp;apos;,
									&amp;apos;bctwpfidolz201&amp;apos; =&amp;gt; &amp;apos;10.173.93.41&amp;apos;,
									&amp;apos;alawpfidolz201&amp;apos; =&amp;gt; &amp;apos;10.194.83.53&amp;apos;,
									&amp;apos;10.194.83.41&amp;apos;
								); 
	EXPORT prodLandingZone_despray	 := CASE(STD.STR.ToLowerCase(RED.common.stored_build_despray_hostname),
									&amp;apos;alawpfidolz301&amp;apos; =&amp;gt; &amp;apos;10.194.83.41&amp;apos;,
									&amp;apos;bctwpfidolz201&amp;apos; =&amp;gt; &amp;apos;10.173.93.41&amp;apos;,
									&amp;apos;alawpfidolz201&amp;apos; =&amp;gt; &amp;apos;10.194.83.53&amp;apos;,
									&amp;apos;10.194.83.41&amp;apos;
								); 								
	EXPORT LandingZone			 := if(red.common.stored_env=&amp;apos;prod&amp;apos;,prodLandingZone,if(red.common.stored_env=&amp;apos;dev2&amp;apos;,dev2LandingZone,devLandingZone));
	EXPORT LandingZone_despray   := if(red.common.stored_env=&amp;apos;prod&amp;apos;,prodLandingZone_despray,if(red.common.stored_env=&amp;apos;dev2&amp;apos;,dev2LandingZone,devLandingZone));

	//EXPORT landingzone       := &amp;apos;10.29.100.66&amp;apos;;
	//EXPORT landingzone       := &amp;apos;10.195.168.193&amp;apos;;
	SHARED DIR_SourceName		 := If(TRIM(SourceName,left,right)&amp;lt;&amp;gt;&amp;apos;&amp;apos;, FileSeparator + TRIM(SourceName,left,right),&amp;apos;&amp;apos;);
	SHARED DIR_Frequency		 := If(TRIM(Frequency,left,right)&amp;lt;&amp;gt;&amp;apos;&amp;apos;,  FileSeparator + TRIM(Frequency,left,right), FileSeparator + &amp;apos;daily&amp;apos;);
	SHARED Thor_Frequency		 := If(TRIM(Frequency,left,right)&amp;lt;&amp;gt;&amp;apos;&amp;apos;,  &amp;apos;::&amp;apos; + TRIM(Frequency,left,right),&amp;apos;&amp;apos;);
	SHARED DIR_File_Date		 := If(TRIM(File_Date,left,right)&amp;lt;&amp;gt;&amp;apos;&amp;apos;,  FileSeparator + TRIM(File_Date,left,right),&amp;apos;&amp;apos;);
  
  EXPORT processDir        := TRIM(red.common.stored_inbound_drive) + &amp;apos;:\\red\\data\\inbound&amp;apos;+ DIR_SourceName + DIR_Frequency + &amp;apos;\\working&amp;apos; + DIR_File_Date;

	EXPORT processfile       := processDir + FileSeparator + TRIM(sFileName,left,right); 

	EXPORT spray_str 				 := &amp;apos;~thor::&amp;apos; + sProdID + &amp;apos;::spray::&amp;apos; + SourceName + Thor_Frequency + &amp;apos;::&amp;apos; + File_Date;
		
	EXPORT spray_file 		 	 := spray_str + &amp;apos;::&amp;apos; + sFileName;
	EXPORT spray_subfile		 := spray_file + &amp;apos;_&amp;apos;+ wuid;
END;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Module flags=&quot;5&quot;
         fullname=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\plugins\stringlib.dll&quot;
         key=&quot;lib_stringlib&quot;
         name=&quot;lib_stringlib&quot;
         plugin=&quot;stringlib.dll&quot;
         sourcePath=&quot;lib_stringlib&quot;
         ts=&quot;1616676526000000&quot;
         version=&quot;STRINGLIB 1.1.14&quot;&gt;
  &lt;Text&gt;export StringLib := SERVICE:fold
  string StringFilterOut(const string src, const string _within) : c, pure,entrypoint=&amp;apos;slStringFilterOut&amp;apos;; 
  string StringFilter(const string src, const string _within) : c, pure,entrypoint=&amp;apos;slStringFilter&amp;apos;; 
  string StringSubstituteOut(const string src, const string _within, const string _newchar) : c, pure,entrypoint=&amp;apos;slStringSubsOut&amp;apos;; 
  string StringSubstitute(const string src, const string _within, const string _newchar) : c, pure,entrypoint=&amp;apos;slStringSubs&amp;apos;; 
  string StringRepad(const string src, unsigned4 size) : c, pure,entrypoint=&amp;apos;slStringRepad&amp;apos;; 
  string StringTranslate(const string src, const string _within, const string _mapping) : c, pure,entrypoint=&amp;apos;slStringTranslate&amp;apos;; 
  unsigned integer4 StringFind(const string src, const string tofind, unsigned4 instance ) : c, pure,entrypoint=&amp;apos;slStringFind&amp;apos;; 
  unsigned integer4 StringUnboundedUnsafeFind(const string src, const string tofind ) : c,pure,nofold,entrypoint=&amp;apos;slStringFind2&amp;apos;; 
  unsigned integer4 StringFindCount(const string src, const string tofind) : c, pure,entrypoint=&amp;apos;slStringFindCount&amp;apos;; 
  unsigned integer4 EbcdicStringFind(const ebcdic string src, const ebcdic string tofind , unsigned4 instance ) : c,pure,entrypoint=&amp;apos;slStringFind&amp;apos;; 
  unsigned integer4 EbcdicStringUnboundedUnsafeFind(const ebcdic string src, const ebcdic string tofind ) : c,pure,nofold,entrypoint=&amp;apos;slStringFind2&amp;apos;; 
  string StringExtract(const string src, unsigned4 instance) : c,pure,entrypoint=&amp;apos;slStringExtract&amp;apos;; 
  string8 GetDateYYYYMMDD() : c,once,entrypoint=&amp;apos;slGetDateYYYYMMDD2&amp;apos;;
  varstring GetBuildInfo() : c,once,entrypoint=&amp;apos;slGetBuildInfo&amp;apos;;
  string Data2String(const data src) : c,pure,entrypoint=&amp;apos;slData2String&amp;apos;;
  data String2Data(const string src) : c,pure,entrypoint=&amp;apos;slString2Data&amp;apos;;
  string StringToLowerCase(const string src) : c,pure,entrypoint=&amp;apos;slStringToLowerCase&amp;apos;;
  string StringToUpperCase(const string src) : c,pure,entrypoint=&amp;apos;slStringToUpperCase&amp;apos;;
  string StringToProperCase(const string src) : c,pure,entrypoint=&amp;apos;slStringToProperCase&amp;apos;;
  string StringToCapitalCase(const string src) : c,pure,entrypoint=&amp;apos;slStringToCapitalCase&amp;apos;;
  string StringToTitleCase(const string src) : c,pure,entrypoint=&amp;apos;slStringToTitleCase&amp;apos;;
  integer4 StringCompareIgnoreCase(const string src1, const string src2) : c,pure,entrypoint=&amp;apos;slStringCompareIgnoreCase&amp;apos;;
  string StringReverse(const string src) : c,pure,entrypoint=&amp;apos;slStringReverse&amp;apos;;
  string StringFindReplace(const string src, const string stok, const string rtok) : c,pure,entrypoint=&amp;apos;slStringFindReplace&amp;apos;;
  string StringCleanSpaces(const string src) : c,pure,entrypoint=&amp;apos;slStringCleanSpaces&amp;apos;; 
  boolean StringWildMatch(const string src, const string _pattern, boolean _noCase) : c, pure,entrypoint=&amp;apos;slStringWildMatch&amp;apos;; 
  boolean StringWildExactMatch(const string src, const string _pattern, boolean _noCase) : c, pure,entrypoint=&amp;apos;slStringWildExactMatch&amp;apos;; 
  boolean StringContains(const string src, const string _pattern, boolean _noCase) : c, pure,entrypoint=&amp;apos;slStringContains&amp;apos;; 
  string StringExtractMultiple(const string src, unsigned8 mask) : c,pure,entrypoint=&amp;apos;slStringExtractMultiple&amp;apos;; 
  unsigned integer4 EditDistance(const string l, const string r) : c, time, pure,entrypoint=&amp;apos;slEditDistanceV2&amp;apos;; 
  boolean EditDistanceWithinRadius(const string l, const string r, unsigned4 radius) : c,time,pure,entrypoint=&amp;apos;slEditDistanceWithinRadiusV2&amp;apos;; 
  unsigned integer4 EditDistanceV2(const string l, const string r) : c,time,pure,entrypoint=&amp;apos;slEditDistanceV2&amp;apos;; 
  unsigned integer4 EditDistanceV3(const string l, const string r, unsigned4 radius) : c,time,pure,entrypoint=&amp;apos;slEditDistanceV3&amp;apos;; 
  boolean EditDistanceWithinRadiusV2(const string l, const string r, unsigned4 radius) : c,time,pure,entrypoint=&amp;apos;slEditDistanceWithinRadiusV2&amp;apos;; 
  string StringGetNthWord(const string src, unsigned4 n) : c, pure,entrypoint=&amp;apos;slStringGetNthWord&amp;apos;; 
  string StringExcludeLastWord(const string src) : c, pure,entrypoint=&amp;apos;slStringExcludeLastWord&amp;apos;; 
  string StringExcludeNthWord(const string src, unsigned4 n) : c, pure,entrypoint=&amp;apos;slStringExcludeNthWord&amp;apos;; 
  unsigned4 StringWordCount(const string src) : c, pure,entrypoint=&amp;apos;slStringWordCount&amp;apos;; 
  unsigned4 CountWords(const string src, const string _separator, BOOLEAN allow_blanks) : c, pure,entrypoint=&amp;apos;slCountWords&amp;apos;; 
  SET OF STRING SplitWords(const string src, const string _separator, BOOLEAN allow_blanks) : c, pure,entrypoint=&amp;apos;slSplitWords&amp;apos;; 
  STRING CombineWords(set of string src, const string _separator) : c, pure,entrypoint=&amp;apos;slCombineWords&amp;apos;; 
  UNSIGNED4 StringToDate(const string src, const varstring format) : c, pure,entrypoint=&amp;apos;slStringToDate&amp;apos;; 
  UNSIGNED4 StringToTimeOfDay(const string src, const varstring format) : c, pure,entrypoint=&amp;apos;slStringToTimeOfDay&amp;apos;; 
  UNSIGNED4 MatchDate(const string src, set of varstring formats) : c, pure,entrypoint=&amp;apos;slMatchDate&amp;apos;; 
  UNSIGNED4 MatchTimeOfDay(const string src, set of varstring formats) : c, pure,entrypoint=&amp;apos;slMatchTimeOfDay&amp;apos;; 
  STRING FormatDate(UNSIGNED4 date, const varstring format) : c, pure,entrypoint=&amp;apos;slFormatDate&amp;apos;; 
  STRING StringRepeat(const string src, unsigned4 n) : c, pure,entrypoint=&amp;apos;slStringRepeat&amp;apos;; 
END;&lt;/Text&gt;
 &lt;/Module&gt;
 &lt;Module flags=&quot;5&quot;
         fullname=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\plugins\timelib.dll&quot;
         key=&quot;lib_timelib&quot;
         name=&quot;lib_timelib&quot;
         plugin=&quot;timelib.dll&quot;
         sourcePath=&quot;lib_timelib&quot;
         ts=&quot;1616676550000000&quot;
         version=&quot;TIMELIB 1.0.0&quot;&gt;
  &lt;Text&gt;EXPORT TMPartsRec := RECORD 
  INTEGER4 sec; 
  INTEGER4 min; 
  INTEGER4 hour; 
  INTEGER4 mday; 
  INTEGER4 mon; 
  INTEGER4 year; 
  INTEGER4 wday; 
END;EXPORT TMDateRangeRec := RECORD 
  UNSIGNED4 startDate; 
  UNSIGNED4 endDate; 
END;EXPORT TimeLib := SERVICE : fold
  INTEGER8 SecondsFromParts(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day, UNSIGNED1 hour, UNSIGNED1 minute, UNSIGNED1 second, BOOLEAN is_local_time) : c,pure,entrypoint=&amp;apos;tlSecondsFromParts&amp;apos;; 
  TRANSFORM(TMPartsRec) SecondsToParts(INTEGER8 seconds, BOOLEAN is_local_time = FALSE) : c,pure,entrypoint=&amp;apos;tlSecondsToParts&amp;apos;; 
  UNSIGNED2 GetDayOfYear(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) : c,pure,entrypoint=&amp;apos;tlGetDayOfYear&amp;apos;; 
  UNSIGNED1 GetDayOfWeek(INTEGER2 year, UNSIGNED1 month, UNSIGNED1 day) : c,pure,entrypoint=&amp;apos;tlGetDayOfWeek&amp;apos;; 
  STRING DateToString(UNSIGNED4 date, CONST VARSTRING format) : c,pure,entrypoint=&amp;apos;tlDateToString&amp;apos;; 
  STRING TimeToString(UNSIGNED3 time, CONST VARSTRING format) : c,pure,entrypoint=&amp;apos;tlTimeToString&amp;apos;; 
  STRING SecondsToString(INTEGER8 seconds, CONST VARSTRING format) : c,pure,entrypoint=&amp;apos;tlSecondsToString&amp;apos;; 
  INTEGER8 StringToSeconds(CONST STRING src, CONST VARSTRING format, BOOLEAN is_local_time) : c,pure,entrypoint=&amp;apos;tlStringToSeconds&amp;apos;; 
  UNSIGNED4 AdjustDate(UNSIGNED4 date, INTEGER2 year_delta, INTEGER4 month_delta, INTEGER4 day_delta) : c,pure,entrypoint=&amp;apos;tlAdjustDate&amp;apos;; 
  UNSIGNED4 AdjustDateBySeconds(UNSIGNED4 date, INTEGER4 seconds_delta) : c,pure,entrypoint=&amp;apos;tlAdjustDateBySeconds&amp;apos;; 
  UNSIGNED4 AdjustTime(UNSIGNED3 time, INTEGER2 hour_delta, INTEGER4 minute_delta, INTEGER4 second_delta) : c,pure,entrypoint=&amp;apos;tlAdjustTime&amp;apos;; 
  UNSIGNED4 AdjustTimeBySeconds(UNSIGNED3 time, INTEGER4 seconds_delta) : c,pure,entrypoint=&amp;apos;tlAdjustTimeBySeconds&amp;apos;; 
  INTEGER4 AdjustSeconds(INTEGER8 seconds, INTEGER2 year_delta, INTEGER4 month_delta, INTEGER4 day_delta, INTEGER2 hour_delta, INTEGER4 minute_delta, INTEGER4 second_delta) : c,pure,entrypoint=&amp;apos;tlAdjustSeconds&amp;apos;; 
  UNSIGNED4 AdjustCalendar(UNSIGNED4 date, INTEGER2 year_delta, INTEGER4 month_delta, INTEGER4 day_delta) : c,pure,entrypoint=&amp;apos;tlAdjustCalendar&amp;apos;; 
  BOOLEAN IsLocalDaylightSavingsInEffect() : c,pure,entrypoint=&amp;apos;tlIsLocalDaylightSavingsInEffect&amp;apos;; 
  UNSIGNED4 GetLastDayOfMonth(UNSIGNED4 date) : c,pure,entrypoint=&amp;apos;tlGetLastDayOfMonth&amp;apos;; 
  TRANSFORM(TMDateRangeRec) DatesForWeek(UNSIGNED4 date) : c,pure,entrypoint=&amp;apos;tlDatesForWeek&amp;apos;; 
  INTEGER4 LocalTimeZoneOffset() : c,once,entrypoint=&amp;apos;tlLocalTimeZoneOffset&amp;apos;; 
  UNSIGNED4 CurrentDate(BOOLEAN in_local_time) : c,once,entrypoint=&amp;apos;tlCurrentDate&amp;apos;; 
  UNSIGNED4 CurrentTime(BOOLEAN in_local_time) : c,entrypoint=&amp;apos;tlCurrentTime&amp;apos;; 
  INTEGER8 CurrentSeconds(BOOLEAN in_local_time) : c,entrypoint=&amp;apos;tlCurrentSeconds&amp;apos;; 
  INTEGER8 CurrentTimestamp(BOOLEAN in_local_time) : c,entrypoint=&amp;apos;tlCurrentTimestamp&amp;apos;; 
END;&lt;/Text&gt;
 &lt;/Module&gt;
 &lt;Module key=&quot;std.system&quot; name=&quot;std.system&quot;&gt;
  &lt;Attribute key=&quot;thorlib&quot;
             name=&quot;Thorlib&quot;
             sourcePath=&quot;C:\Program Files\HPCCSystems\7.12.38\clienttools\share\ecllibrary\std\system\Thorlib.ecl&quot;
             ts=&quot;1616674834000000&quot;&gt;
   /*##############################################################################
## HPCC SYSTEMS software Copyright (C) 2012 HPCC Systems.  All rights reserved.
############################################################################## */

/*
 * Internal functions for accessing system information relating to execution on the thor engine.
 *
 * This module is currently treated as internal, and subject to change without notice.
 */
 
externals := 
    SERVICE
unsigned integer4 node() : ctxmethod, entrypoint=&amp;apos;getNodeNum&amp;apos;;
unsigned integer4 nodes() : ctxmethod, entrypoint=&amp;apos;getNodes&amp;apos;;
varstring l2p(const varstring name, boolean create=false) : ctxmethod, entrypoint=&amp;apos;getFilePart&amp;apos;;
unsigned integer getFileOffset(const varstring lfname) : ctxmethod, entrypoint=&amp;apos;getFileOffset&amp;apos;;
varstring daliServer() : once, ctxmethod, entrypoint=&amp;apos;getDaliServers&amp;apos;;
varstring cluster() : once, ctxmethod, entrypoint=&amp;apos;getClusterName&amp;apos;;
varstring getExpandLogicalName(const varstring name) : pure, ctxmethod, entrypoint=&amp;apos;getExpandLogicalName&amp;apos;;
varstring group() : once, ctxmethod, entrypoint=&amp;apos;getGroupName&amp;apos;;
varstring platform() : pure ,ctxmethod, entrypoint=&amp;apos;getPlatform&amp;apos;;
    END;

RETURN MODULE

/*
 * Returns the index of the slave node this piece of code is executing on.  Zero based.
 */
 
export node() := externals.node();

/*
 * Converts a logical filename to a physical filename.
 * 
 * @param name          The logical filename to be converted.
 * @param create        True if creating a new file, false if reading an existing file.
 */
 
export logicalToPhysical(const varstring name, boolean create=false) := externals.l2p(name, create);

/*
 * How many nodes in the cluster that this code will be executed on.
 */
 
export nodes() := CLUSTERSIZE;

/*
 * Returns the dali server this thor is connected to.
 */
 
export daliServer() := externals.daliServer();

/*
 * Returns which thor group the job is currently executing on.
 */
 
export group() := externals.group();

/*
 * Converts a logical filename to a physical filename.
 */

export getExpandLogicalName(const varstring name) := externals.getExpandLogicalName(name);

/*
 * Returns the name of the cluster the query is currently executing on.
 */

export cluster() := externals.cluster();

/*
 * Returns the platform the query is currently executing on.
 */

export platform() := externals.platform();

/*
 * The following are either unused, or should be replaced with a different syntax.
 
export getenv(const varstring name, const varstring defaultValue) := externals.getenv(name, defaultValue);
- use getenv() built in command instead.
export getFileOffset(const varstring lfname) := externals.getFileOffset(lfname);

*/

END;&amp;#13;&amp;#10;
  &lt;/Attribute&gt;
 &lt;/Module&gt;
 &lt;Option name=&quot;eclcc_compiler_version&quot; value=&quot;7.12.38&quot;/&gt;
&lt;/Archive&gt;&#10;</Text>
 </Query>
 <resultLimit>100</resultLimit>
 <Results>
  <Result activity="27"
          graph="graph1"
          name="dim_fact_counts"
          sequence="0"
          status="calculated">
   <rowCount>1</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    ZGltX2ZhY3RfY291bnRzAATx////AWFzY2lpAAFhc2NpaQAAGAAAAAA=   </SchemaRaw>
   <totalRowCount>1</totalRowCount>
   <Value xsi:type="SOAP-ENC:base64">
    UAAAAGRpbSBhcHA6IDYKZGltIGNvbnRyaWI6IDc5CmRpbSBmaWVsZCBkZWY6IDQ4NgpmYWN0
IGZpbGU6IDQ4MTIKZmFjdCBmaWVsZDogNDE0NTg5   </Value>
  </Result>
  <Result activity="39"
          graph="graph1"
          name="stg_counts"
          sequence="1"
          status="calculated">
   <rowCount>1</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    c3RnX2NvdW50cwAE8f///wFhc2NpaQABYXNjaWkAABgAAAAA   </SchemaRaw>
   <totalRowCount>1</totalRowCount>
   <Value xsi:type="SOAP-ENC:base64">
    OwAAAHN0ZyBhcHA6IDEwCnN0ZyBmaWVsZCBkZWY6IDQ4MwpzdGcgZmlsZTogMjUKc3RnIGZp
ZWxkOiAyMDM1   </Value>
  </Result>
  <Result isScalar="0"
          name="dim_app_empty"
          recordSizeEntry="mf6"
          rowLimit="-1"
          sequence="2"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    YXBwbGljYXRpb25fc2sAAQQBYXBwbGljYXRpb25faWQABAQAAAABYXNjaWkAAWFzY2lpAGFw
cGxpY2F0aW9uX25hbWUABBkAAAABYXNjaWkAAWFzY2lpAGVudmlyb25tZW50AAQKAAAAAWFz
Y2lpAAFhc2NpaQAAGHcAAABSRUNPUkQKICBpbnRlZ2VyNCBhcHBsaWNhdGlvbl9zazsKICBz
dHJpbmc0IGFwcGxpY2F0aW9uX2lkOwogIHN0cmluZzI1IGFwcGxpY2F0aW9uX25hbWU7CiAg
c3RyaW5nMTAgZW52aXJvbm1lbnQ7CiBFTkQ7Cg==   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
  <Result isScalar="0"
          name="dim_contrib_empty"
          recordSizeEntry="mf1"
          rowLimit="-1"
          sequence="3"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    Y29udHJpYnV0b3Jfc2sAAQQBY29udHJpYnV0b3JpZAAECgAAAAFhc2NpaQABYXNjaWkAY29u
dHJpYnV0b3JuYW1lAAQyAAAAAWFzY2lpAAFhc2NpaQBjb250cmlidXRvcl9mcmVxdWVuY3kA
BMgAAAABYXNjaWkAAWFzY2lpAGVudmlyb25tZW50AAQKAAAAAWFzY2lpAAFhc2NpaQAAGJkA
AABSRUNPUkQKICBpbnRlZ2VyNCBjb250cmlidXRvcl9zazsKICBzdHJpbmcxMCBjb250cmli
dXRvcmlkOwogIHN0cmluZzUwIGNvbnRyaWJ1dG9ybmFtZTsKICBzdHJpbmcyMDAgY29udHJp
YnV0b3JfZnJlcXVlbmN5OwogIHN0cmluZzEwIGVudmlyb25tZW50OwogRU5EOwo=   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
  <Result isScalar="0"
          name="dim_field_def_empty"
          recordSizeEntry="mf3"
          rowLimit="-1"
          sequence="4"
          status="calculated">
   <rowCount>2</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    ZmllbGRfZGVmX3NrAAEEAWZpZWxkX25hbWUABGQAAAABYXNjaWkAAWFzY2lpAGJhdGNodmVy
c2lvbgAEBQAAAAFhc2NpaQABYXNjaWkAZmllbGRfY2F0ZWdvcnkABB4AAAABYXNjaWkAAWFz
Y2lpAGZpZWxkX2Rlc2MABPQBAAABYXNjaWkAAWFzY2lpAGZpZWxkX3dlaWdodAABBAFmaWVs
ZF90eXBlAAQMAAAAAWFzY2lpAAFhc2NpaQBmaWVsZF9ncm91cAAEBwAAAAFhc2NpaQABYXNj
aWkAYXBwbGljYXRpb25faWQABAQAAAABYXNjaWkAAWFzY2lpAGVudmlyb25tZW50AAQKAAAA
AWFzY2lpAAFhc2NpaQAAGAIBAABSRUNPUkQKICBpbnRlZ2VyNCBmaWVsZF9kZWZfc2s7CiAg
c3RyaW5nMTAwIGZpZWxkX25hbWU7CiAgc3RyaW5nNSBiYXRjaHZlcnNpb247CiAgc3RyaW5n
MzAgZmllbGRfY2F0ZWdvcnk7CiAgc3RyaW5nNTAwIGZpZWxkX2Rlc2M7CiAgaW50ZWdlcjQg
ZmllbGRfd2VpZ2h0OwogIHN0cmluZzEyIGZpZWxkX3R5cGU7CiAgc3RyaW5nNyBmaWVsZF9n
cm91cDsKICBzdHJpbmc0IGFwcGxpY2F0aW9uX2lkOwogIHN0cmluZzEwIGVudmlyb25tZW50
OwogRU5EOwo=   </SchemaRaw>
   <totalRowCount>2</totalRowCount>
   <Value xsi:type="SOAP-ENC:base64">
    /v///05BICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICBOQSAg
IE5vdCBBcHBsaWNhYmxlICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgAAAAACAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgIP////9VQSAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgVUEgICBVbmFzc2lnbmVkICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAgICAgICAgICAgICAgICAgIAAAAAAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICA=   </Value>
  </Result>
  <Result isScalar="0"
          name="fact_file_empty"
          recordSizeEntry="mf4"
          rowLimit="-1"
          sequence="5"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    d3VpZAAEEwAAAAFhc2NpaQABYXNjaWkAYmF0Y2hudW1iZXIABA4AAAABYXNjaWkAAWFzY2lp
AGJhdGNodmVyc2lvbgAEBQAAAAFhc2NpaQABYXNjaWkAZW52aXJvbm1lbnQABAoAAAABYXNj
aWkAAWFzY2lpAGJhdGNoc3RhdGUABAoAAAABYXNjaWkAAWFzY2lpAGRhdGVfc2sAAQQBYXBw
bGljYXRpb25fc2sAAQQBY29udHJpYnV0b3Jfc2sAAQQBc2NvcmUAAQgBcmVjb3JkcwABCAFj
b21wb3NpdGVfaGFzaAABCAEAGAgBAABSRUNPUkQKICBzdHJpbmcxOSB3dWlkOwogIHN0cmlu
ZzE0IGJhdGNobnVtYmVyOwogIHN0cmluZzUgYmF0Y2h2ZXJzaW9uOwogIHN0cmluZzEwIGVu
dmlyb25tZW50OwogIHN0cmluZzEwIGJhdGNoc3RhdGU7CiAgaW50ZWdlcjQgZGF0ZV9zazsK
ICBpbnRlZ2VyNCBhcHBsaWNhdGlvbl9zazsKICBpbnRlZ2VyNCBjb250cmlidXRvcl9zazsK
ICBpbnRlZ2VyOCBzY29yZTsKICBpbnRlZ2VyOCByZWNvcmRzOwogIGludGVnZXI4IGNvbXBv
c2l0ZV9oYXNoOwogRU5EOwo=   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
  <Result isScalar="0"
          name="fact_field_empty"
          recordSizeEntry="mf5"
          rowLimit="-1"
          sequence="6"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    d3VpZAAEEwAAAAFhc2NpaQABYXNjaWkAYmF0Y2hudW1iZXIABA4AAAABYXNjaWkAAWFzY2lp
AGJhdGNodmVyc2lvbgAEBQAAAAFhc2NpaQABYXNjaWkAZW52aXJvbm1lbnQABAoAAAABYXNj
aWkAAWFzY2lpAGRhdGVfc2sAAQQBYXBwbGljYXRpb25fc2sAAQQBZmllbGRfZGVmX3NrAAEE
AXNjb3JlX21heAABCAFzY29yZV9hdmcAAQgBc2NvcmVfbWluAAEIAXNjb3JlX3N1bQABCAFz
Y29yZV92YXIAAwIMAXJlY19lbXB0eQABCAFyZWNfcG9wdWxhdGVkAAEIAWNvbXBvc2l0ZV9o
YXNoAAEIAQAYagEAAFJFQ09SRAogIHN0cmluZzE5IHd1aWQ7CiAgc3RyaW5nMTQgYmF0Y2hu
dW1iZXI7CiAgc3RyaW5nNSBiYXRjaHZlcnNpb247CiAgc3RyaW5nMTAgZW52aXJvbm1lbnQ7
CiAgaW50ZWdlcjQgZGF0ZV9zazsKICBpbnRlZ2VyNCBhcHBsaWNhdGlvbl9zazsKICBpbnRl
Z2VyNCBmaWVsZF9kZWZfc2s7CiAgaW50ZWdlcjggc2NvcmVfbWF4OwogIGludGVnZXI4IHNj
b3JlX2F2ZzsKICBpbnRlZ2VyOCBzY29yZV9taW47CiAgaW50ZWdlcjggc2NvcmVfc3VtOwog
IGRlY2ltYWwxMl8yIHNjb3JlX3ZhcjsKICBpbnRlZ2VyOCByZWNfZW1wdHk7CiAgaW50ZWdl
cjggcmVjX3BvcHVsYXRlZDsKICBpbnRlZ2VyOCBjb21wb3NpdGVfaGFzaDsKIEVORDsK   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
  <Result isScalar="0"
          name="fact_file_neg1"
          recordSizeEntry="mf4"
          rowLimit="-1"
          sequence="7"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    d3VpZAAEEwAAAAFhc2NpaQABYXNjaWkAYmF0Y2hudW1iZXIABA4AAAABYXNjaWkAAWFzY2lp
AGJhdGNodmVyc2lvbgAEBQAAAAFhc2NpaQABYXNjaWkAZW52aXJvbm1lbnQABAoAAAABYXNj
aWkAAWFzY2lpAGJhdGNoc3RhdGUABAoAAAABYXNjaWkAAWFzY2lpAGRhdGVfc2sAAQQBYXBw
bGljYXRpb25fc2sAAQQBY29udHJpYnV0b3Jfc2sAAQQBc2NvcmUAAQgBcmVjb3JkcwABCAFj
b21wb3NpdGVfaGFzaAABCAEAGAgBAABSRUNPUkQKICBzdHJpbmcxOSB3dWlkOwogIHN0cmlu
ZzE0IGJhdGNobnVtYmVyOwogIHN0cmluZzUgYmF0Y2h2ZXJzaW9uOwogIHN0cmluZzEwIGVu
dmlyb25tZW50OwogIHN0cmluZzEwIGJhdGNoc3RhdGU7CiAgaW50ZWdlcjQgZGF0ZV9zazsK
ICBpbnRlZ2VyNCBhcHBsaWNhdGlvbl9zazsKICBpbnRlZ2VyNCBjb250cmlidXRvcl9zazsK
ICBpbnRlZ2VyOCBzY29yZTsKICBpbnRlZ2VyOCByZWNvcmRzOwogIGludGVnZXI4IGNvbXBv
c2l0ZV9oYXNoOwogRU5EOwo=   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
  <Result isScalar="0"
          name="fact_field_neg1"
          recordSizeEntry="mf5"
          rowLimit="-1"
          sequence="8"
          status="calculated">
   <rowCount>0</rowCount>
   <SchemaRaw xsi:type="SOAP-ENC:base64">
    d3VpZAAEEwAAAAFhc2NpaQABYXNjaWkAYmF0Y2hudW1iZXIABA4AAAABYXNjaWkAAWFzY2lp
AGJhdGNodmVyc2lvbgAEBQAAAAFhc2NpaQABYXNjaWkAZW52aXJvbm1lbnQABAoAAAABYXNj
aWkAAWFzY2lpAGRhdGVfc2sAAQQBYXBwbGljYXRpb25fc2sAAQQBZmllbGRfZGVmX3NrAAEE
AXNjb3JlX21heAABCAFzY29yZV9hdmcAAQgBc2NvcmVfbWluAAEIAXNjb3JlX3N1bQABCAFz
Y29yZV92YXIAAwIMAXJlY19lbXB0eQABCAFyZWNfcG9wdWxhdGVkAAEIAWNvbXBvc2l0ZV9o
YXNoAAEIAQAYagEAAFJFQ09SRAogIHN0cmluZzE5IHd1aWQ7CiAgc3RyaW5nMTQgYmF0Y2hu
dW1iZXI7CiAgc3RyaW5nNSBiYXRjaHZlcnNpb247CiAgc3RyaW5nMTAgZW52aXJvbm1lbnQ7
CiAgaW50ZWdlcjQgZGF0ZV9zazsKICBpbnRlZ2VyNCBhcHBsaWNhdGlvbl9zazsKICBpbnRl
Z2VyNCBmaWVsZF9kZWZfc2s7CiAgaW50ZWdlcjggc2NvcmVfbWF4OwogIGludGVnZXI4IHNj
b3JlX2F2ZzsKICBpbnRlZ2VyOCBzY29yZV9taW47CiAgaW50ZWdlcjggc2NvcmVfc3VtOwog
IGRlY2ltYWwxMl8yIHNjb3JlX3ZhcjsKICBpbnRlZ2VyOCByZWNfZW1wdHk7CiAgaW50ZWdl
cjggcmVjX3BvcHVsYXRlZDsKICBpbnRlZ2VyOCBjb21wb3NpdGVfaGFzaDsKIEVORDsK   </SchemaRaw>
   <totalRowCount>0</totalRowCount>
   <Value/>
  </Result>
 </Results>
 <State>completed</State>
 <Statistics>
  <Statistic c="esp"
             count="1"
             creator="esp@10.194.93.3"
             kind="WhenCreated"
             s="global"
             scope=""
             ts="1619789638385919"
             unit="ts"
             value="1619789638385911"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenCompiled"
             s="global"
             scope=""
             ts="1619789639546788"
             unit="ts"
             value="1619789639546063"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenStarted"
             s="compile"
             scope="compile"
             ts="1619789642061644"
             unit="ts"
             value="1619789640431038"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="SizePeakMemory"
             s="compile"
             scope="compile"
             ts="1619789642062414"
             unit="sz"
             value="124329984"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeElapsed"
             s="compile"
             scope="compile"
             ts="1619789642062443"
             unit="ns"
             value="1629923496"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="NumSysContextSwitches"
             s="compile"
             scope="compile"
             ts="1619789642062478"
             unit="cnt"
             value="798"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeOsUser"
             s="compile"
             scope="compile"
             ts="1619789642062510"
             unit="ns"
             value="1200000000"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeOsSystem"
             s="compile"
             scope="compile"
             ts="1619789642062552"
             unit="ns"
             value="230000000"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeOsTotal"
             s="compile"
             scope="compile"
             ts="1619789642062592"
             unit="ns"
             value="39080000000"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeUser"
             s="compile"
             scope="compile"
             ts="1619789642062631"
             unit="ns"
             value="1200000000"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeSystem"
             s="compile"
             scope="compile"
             ts="1619789642062679"
             unit="ns"
             value="230000000"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenStarted"
             s="compile"
             scope="compile:compile c++"
             ts="1619789642062720"
             unit="ts"
             value="1619789640768931"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeElapsed"
             s="compile"
             scope="compile:compile c++"
             ts="1619789642062764"
             unit="ns"
             value="1291503120"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenStarted"
             s="compile"
             scope="compile:generate"
             ts="1619789642062807"
             unit="ts"
             value="1619789640698667"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeElapsed"
             s="compile"
             scope="compile:generate"
             ts="1619789642062850"
             unit="ns"
             value="66331405"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenStarted"
             s="compile"
             scope="compile:parse"
             ts="1619789642062894"
             unit="ts"
             value="1619789640431095"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeElapsed"
             s="compile"
             scope="compile:parse"
             ts="1619789642062949"
             unit="ns"
             value="266419873"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="WhenStarted"
             s="compile"
             scope="compile:write c++"
             ts="1619789642062999"
             unit="ts"
             value="1619789640764026"/>
  <Statistic c="eclcc"
             count="1"
             creator="eclccserver@10.194.93.5"
             kind="TimeElapsed"
             s="compile"
             scope="compile:write c++"
             ts="1619789642063049"
             unit="ns"
             value="935724"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="global"
             scope=""
             ts="1619789642210278"
             unit="ts"
             value="1619789642209628"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="graph"
             scope="w1:graph1"
             ts="1619789642298053"
             unit="ts"
             value="1619789642298039"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg1"
             ts="1619789646591884"
             unit="ts"
             value="1619789642298258"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg1"
             ts="1619789646591916"
             unit="ns"
             value="4293440277"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg8"
             ts="1619789649173439"
             unit="ts"
             value="1619789646594138"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg8"
             ts="1619789649173489"
             unit="ns"
             value="2578961114"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg15"
             ts="1619789649214706"
             unit="ts"
             value="1619789649175961"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg15"
             ts="1619789649214752"
             unit="ns"
             value="38145168"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg18"
             ts="1619789649255455"
             unit="ts"
             value="1619789649217005"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg18"
             ts="1619789649255508"
             unit="ns"
             value="37819987"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg21"
             ts="1619789650346452"
             unit="ts"
             value="1619789649258029"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg21"
             ts="1619789650346507"
             unit="ns"
             value="1087983101"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg28"
             ts="1619789650367415"
             unit="ts"
             value="1619789650348765"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg28"
             ts="1619789650367473"
             unit="ns"
             value="18054618"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg31"
             ts="1619789650387783"
             unit="ts"
             value="1619789650369871"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg31"
             ts="1619789650387838"
             unit="ns"
             value="17292053"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg34"
             ts="1619789650408312"
             unit="ts"
             value="1619789650390178"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg34"
             ts="1619789650408369"
             unit="ns"
             value="17531514"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg37"
             ts="1619789650432066"
             unit="ts"
             value="1619789650410691"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg37"
             ts="1619789650432127"
             unit="ns"
             value="20781353"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg40"
             ts="1619789650436606"
             unit="ts"
             value="1619789650434514"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg40"
             ts="1619789650436670"
             unit="ns"
             value="1482851"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg44"
             ts="1619789650441201"
             unit="ts"
             value="1619789650439107"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg44"
             ts="1619789650441267"
             unit="ns"
             value="1497330"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg48"
             ts="1619789650446245"
             unit="ts"
             value="1619789650443691"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg48"
             ts="1619789650446315"
             unit="ns"
             value="1934137"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg52"
             ts="1619789651701649"
             unit="ts"
             value="1619789650448688"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg52"
             ts="1619789651701723"
             unit="ns"
             value="1252450233"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg56"
             ts="1619789654879038"
             unit="ts"
             value="1619789651704311"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg56"
             ts="1619789654879115"
             unit="ns"
             value="3174392263"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg60"
             ts="1619789654949789"
             unit="ts"
             value="1619789654881734"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg60"
             ts="1619789654949869"
             unit="ns"
             value="67427527"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="subgraph"
             scope="w1:graph1:sg64"
             ts="1619789655679860"
             unit="ts"
             value="1619789654952423"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="subgraph"
             scope="w1:graph1:sg64"
             ts="1619789655679944"
             unit="ns"
             value="726795151"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             desc="Graph graph1"
             kind="TimeElapsed"
             s="graph"
             scope="w1:graph1"
             ts="1619789655683227"
             unit="ns"
             value="13385000000"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenStarted"
             s="workflow"
             scope="w1"
             ts="1619789655684805"
             unit="ts"
             value="1619789642273901"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="workflow"
             scope="w1"
             ts="1619789655684887"
             unit="ns"
             value="13412293410"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="SizePeakMemory"
             s="global"
             scope=""
             ts="1619789655687125"
             unit="sz"
             value="1572864"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="WhenFinished"
             s="global"
             scope=""
             ts="1619789655688271"
             unit="ts"
             value="1619789655688264"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeElapsed"
             s="global"
             scope=""
             ts="1619789655688360"
             unit="ns"
             value="13480814689"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeTotalExecute"
             max="8312785"
             s="section"
             scope="SDS_Initialize"
             ts="1619789655688459"
             unit="ns"
             value="8312785"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeTotalExecute"
             max="6750981"
             s="section"
             scope="Environment_Initialize"
             ts="1619789655688551"
             unit="ns"
             value="6750981"/>
  <Statistic c="hthor"
             count="1"
             creator="eclagent@10.194.93.2"
             kind="TimeTotalExecute"
             max="13478003206"
             s="section"
             scope="Process"
             ts="1619789655688650"
             unit="ns"
             value="13478003206"/>
 </Statistics>
 <Tracing>
  <EclAgentBuild>internal_7.6.70-1</EclAgentBuild>
 </Tracing>
 <Workflow>
  <Item mode="normal"
        state="done"
        type="normal"
        wfid="1">
   <Schedule/>
  </Item>
 </Workflow>
</W20210430-093358>